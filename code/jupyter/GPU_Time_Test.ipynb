{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU vs. CPU Running Time Test\n",
    "\n",
    "We investigate the running time of GPytorch on CPU and GPU for training (60 iterations) and computing predictive distributions. For predictive distribution we also investigate the effect of LOVE approximation, so the scenarios are:\n",
    "- CPU Exact\n",
    "- GPU Exact\n",
    "- CPU with LOVE without cache\n",
    "- GPU with LOVE without cache\n",
    "- CPU with LOVE with cache\n",
    "- GPU with LOVE with cache\n",
    "\n",
    "We use a customized Multitask Kernel with variable number of Kronecker Product, the same Kernel as used in Targeted Adaptive Design. We use 4 dimensional input and output.\n",
    "\n",
    "The training and testing data are generated using sin and cos functions, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import caffeine\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "# from Data_Gen_Script import VField\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from gpytorch.kernels import MultitaskKernel\n",
    "from gpytorch.constraints import Positive\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TensorProductKernel(MultitaskKernel):\n",
    "    \"\"\"\n",
    "    Class to get the tensorproduct kernel\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_covar_module,  num_tasks, rank=1, pos_constraint = None, tri_constaint = None, task_covar_prior=None, **kwargs):\n",
    "        super().__init__(data_covar_module, num_tasks, rank, task_covar_prior = None, **kwargs)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x1, x2, diag=False, last_dim_is_batch=False, add_jitter = False, **params):\n",
    "        if last_dim_is_batch:\n",
    "            raise RuntimeError(\"MultitaskKernel does not accept the last_dim_is_batch argument.\")\n",
    "        covar_i = self.task_covar_module.covar_matrix #.evaluate()\n",
    "            \n",
    "        covar_i = covar_i.evaluate()\n",
    "        if len(x1.shape[:-2]):\n",
    "            covar_i = covar_i.repeat(*x1.shape[:-2], 1, 1)\n",
    "        covar_x = gpytorch.lazy.lazify(self.data_covar_module.forward(x1, x2, **params))#(self.data_covar_module.forward(x1, x2, **params))#\n",
    "        if (add_jitter == True):\n",
    "            covar_x = covar_x #+ (1e-6) * torch.eye(covar_x.shape[0])\n",
    "        res=gpytorch.lazy.KroneckerProductLazyTensor(covar_x, covar_i) #gpytorch.lazy.lazify(torch.kron(covar_x, covar_i))\n",
    "\n",
    "        return res.diag() if diag else res\n",
    "        \n",
    "        \n",
    "from copy import deepcopy\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "from gpytorch.priors import Prior\n",
    "from gpytorch.kernels import Kernel\n",
    "from gpytorch.kernels import IndexKernel\n",
    "from gpytorch.constraints import Positive\n",
    "\n",
    "# This is the main Kernel to use\n",
    "\n",
    "class SepTensorProductKernel(Kernel):\n",
    "    \"\"\"\n",
    "    Class to get the tensorproduct kernel\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, base_kernels: List, num_tasks: int, rank: Union[int, List] = 1, \n",
    "        task_covar_prior: Optional[Prior] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_kernels (:type: list of `Kernel` objects): A list of base kernels.\n",
    "            num_tasks (int): The number of output tasks to fit.\n",
    "            rank (int): Rank of index kernel to use for task covariance matrix for each\n",
    "                        of the base kernels.\n",
    "            task_covar_prior (:obj:`gpytorch.priors.Prior`): Prior to use for each\n",
    "                task kernel. See :class:`gpytorch.kernels.IndexKernel` for details.\n",
    "        \"\"\"\n",
    "        if len(base_kernels) < 1:\n",
    "            raise ValueError(\"At least one base kernel must be provided.\")\n",
    "        for k in base_kernels:\n",
    "            if not isinstance(k, Kernel):\n",
    "                raise ValueError(\"base_kernels must only contain Kernel objects\")\n",
    "        if not isinstance(rank, list):\n",
    "            rank = [rank] * len(base_kernels)\n",
    "\n",
    "        super(SepTensorProductKernel, self).__init__()\n",
    "        self.covar_module_list = ModuleList(\n",
    "            [\n",
    "                TensorProductKernel(base_kernel, num_tasks=num_tasks, rank=r, task_covar_prior=task_covar_prior)\n",
    "                for base_kernel, r in zip(base_kernels, rank)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        res = self.covar_module_list[0].forward(x1, x2, **params)\n",
    "        for m in self.covar_module_list[1:]:\n",
    "            res += m.forward(x1, x2, **params)\n",
    "        return res\n",
    "\n",
    "    def num_outputs_per_input(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Given `n` data points `x1` and `m` datapoints `x2`, this multitask kernel\n",
    "        returns an `(n*num_tasks) x (m*num_tasks)` covariance matrix.\n",
    "        \"\"\"\n",
    "        return self.covar_module_list[0].num_outputs_per_input(x1, x2)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        new_kernel = deepcopy(self)\n",
    "        new_kernel.covar_module_list = ModuleList(\n",
    "            [base_kernel.__getitem__(index) for base_kernel in self.covar_module_list]\n",
    "        )\n",
    "        return new_kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Initialization\n",
    "\"\"\"\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_base_kernels):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        \n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "              gpytorch.means.ConstantMean(), num_tasks=Dval\n",
    "        )\n",
    "        \n",
    "        base_kernels = []\n",
    "        for i in range(num_base_kernels):\n",
    "            base_kernels.append(gpytorch.kernels.ScaleKernel(( gpytorch.kernels.RBFKernel() ))) \n",
    "            #gpytorch.kernels.PolynomialKernel(4)  ##gpytorch.kernels.MaternKernel()# (vvk_rbf.vvkRBFKernel())\n",
    " \n",
    "            \n",
    "        self.covar_module = SepTensorProductKernel(base_kernels,num_tasks = Dval)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_base_kernels = 8\n",
    "cpu_training_time = []\n",
    "cpu_exact_meancovar = []\n",
    "cpu_love_meancovar = []\n",
    "cpu_love_meancovar_cache = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: 100\n",
      "Iter 1/60 - Loss: 1.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grand/datascience/tiany/python_venv/lib/python3.8/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  /lus/theta-fs0/software/thetagpu/conda/2022-07-01/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2/60 - Loss: 1.318\n",
      "Iter 3/60 - Loss: 1.274\n",
      "Iter 4/60 - Loss: 1.233\n",
      "Iter 5/60 - Loss: 1.195\n",
      "Iter 6/60 - Loss: 1.155\n",
      "Iter 7/60 - Loss: 1.113\n",
      "Iter 8/60 - Loss: 1.072\n",
      "Iter 9/60 - Loss: 1.031\n",
      "Iter 10/60 - Loss: 0.991\n",
      "Iter 11/60 - Loss: 0.951\n",
      "Iter 12/60 - Loss: 0.912\n",
      "Iter 13/60 - Loss: 0.871\n",
      "Iter 14/60 - Loss: 0.830\n",
      "Iter 15/60 - Loss: 0.788\n",
      "Iter 16/60 - Loss: 0.745\n",
      "Iter 17/60 - Loss: 0.703\n",
      "Iter 18/60 - Loss: 0.662\n",
      "Iter 19/60 - Loss: 0.621\n",
      "Iter 20/60 - Loss: 0.580\n",
      "Iter 21/60 - Loss: 0.540\n",
      "Iter 22/60 - Loss: 0.500\n",
      "Iter 23/60 - Loss: 0.461\n",
      "Iter 24/60 - Loss: 0.422\n",
      "Iter 25/60 - Loss: 0.384\n",
      "Iter 26/60 - Loss: 0.347\n",
      "Iter 27/60 - Loss: 0.310\n",
      "Iter 28/60 - Loss: 0.274\n",
      "Iter 29/60 - Loss: 0.239\n",
      "Iter 30/60 - Loss: 0.205\n",
      "Iter 31/60 - Loss: 0.172\n",
      "Iter 32/60 - Loss: 0.140\n",
      "Iter 33/60 - Loss: 0.108\n",
      "Iter 34/60 - Loss: 0.077\n",
      "Iter 35/60 - Loss: 0.046\n",
      "Iter 36/60 - Loss: 0.014\n",
      "Iter 37/60 - Loss: -0.017\n",
      "Iter 38/60 - Loss: -0.049\n",
      "Iter 39/60 - Loss: -0.081\n",
      "Iter 40/60 - Loss: -0.114\n",
      "Iter 41/60 - Loss: -0.148\n",
      "Iter 42/60 - Loss: -0.182\n",
      "Iter 43/60 - Loss: -0.216\n",
      "Iter 44/60 - Loss: -0.250\n",
      "Iter 45/60 - Loss: -0.283\n",
      "Iter 46/60 - Loss: -0.317\n",
      "Iter 47/60 - Loss: -0.350\n",
      "Iter 48/60 - Loss: -0.381\n",
      "Iter 49/60 - Loss: -0.413\n",
      "Iter 50/60 - Loss: -0.444\n",
      "Iter 51/60 - Loss: -0.475\n",
      "Iter 52/60 - Loss: -0.505\n",
      "Iter 53/60 - Loss: -0.535\n",
      "Iter 54/60 - Loss: -0.564\n",
      "Iter 55/60 - Loss: -0.595\n",
      "Iter 56/60 - Loss: -0.625\n",
      "Iter 57/60 - Loss: -0.654\n",
      "Iter 58/60 - Loss: -0.683\n",
      "Iter 59/60 - Loss: -0.712\n",
      "Iter 60/60 - Loss: -0.741\n",
      "\n",
      "data size: 300\n",
      "Iter 1/60 - Loss: 1.215\n",
      "Iter 2/60 - Loss: 1.180\n",
      "Iter 3/60 - Loss: 1.144\n",
      "Iter 4/60 - Loss: 1.107\n",
      "Iter 5/60 - Loss: 1.062\n",
      "Iter 6/60 - Loss: 1.019\n",
      "Iter 7/60 - Loss: 0.978\n",
      "Iter 8/60 - Loss: 0.941\n",
      "Iter 9/60 - Loss: 0.905\n",
      "Iter 10/60 - Loss: 0.875\n",
      "Iter 11/60 - Loss: 0.825\n",
      "Iter 12/60 - Loss: 0.770\n",
      "Iter 13/60 - Loss: 0.730\n",
      "Iter 14/60 - Loss: 0.708\n",
      "Iter 15/60 - Loss: 0.669\n",
      "Iter 16/60 - Loss: 0.610\n",
      "Iter 17/60 - Loss: 0.569\n",
      "Iter 18/60 - Loss: 0.536\n",
      "Iter 19/60 - Loss: 0.496\n",
      "Iter 20/60 - Loss: 0.445\n",
      "Iter 21/60 - Loss: 0.410\n",
      "Iter 22/60 - Loss: 0.363\n",
      "Iter 23/60 - Loss: 0.309\n",
      "Iter 24/60 - Loss: 0.271\n",
      "Iter 25/60 - Loss: 0.236\n",
      "Iter 26/60 - Loss: 0.194\n",
      "Iter 27/60 - Loss: 0.150\n",
      "Iter 28/60 - Loss: 0.103\n",
      "Iter 29/60 - Loss: 0.056\n",
      "Iter 30/60 - Loss: -0.007\n",
      "Iter 31/60 - Loss: -0.054\n",
      "Iter 32/60 - Loss: -0.101\n",
      "Iter 33/60 - Loss: -0.144\n",
      "Iter 34/60 - Loss: -0.186\n",
      "Iter 35/60 - Loss: -0.250\n",
      "Iter 36/60 - Loss: -0.308\n",
      "Iter 37/60 - Loss: -0.345\n",
      "Iter 38/60 - Loss: -0.398\n",
      "Iter 39/60 - Loss: -0.454\n",
      "Iter 40/60 - Loss: -0.477\n",
      "Iter 41/60 - Loss: -0.527\n",
      "Iter 42/60 - Loss: -0.593\n",
      "Iter 43/60 - Loss: -0.623\n",
      "Iter 44/60 - Loss: -0.684\n",
      "Iter 45/60 - Loss: -0.708\n",
      "Iter 46/60 - Loss: -0.768\n",
      "Iter 47/60 - Loss: -0.824\n",
      "Iter 48/60 - Loss: -0.856\n",
      "Iter 49/60 - Loss: -0.889\n",
      "Iter 50/60 - Loss: -0.941\n",
      "Iter 51/60 - Loss: -0.970\n",
      "Iter 52/60 - Loss: -1.008\n",
      "Iter 53/60 - Loss: -1.055\n",
      "Iter 54/60 - Loss: -1.069\n",
      "Iter 55/60 - Loss: -1.121\n",
      "Iter 56/60 - Loss: -1.158\n",
      "Iter 57/60 - Loss: -1.241\n",
      "Iter 58/60 - Loss: -1.197\n",
      "Iter 59/60 - Loss: -1.282\n",
      "Iter 60/60 - Loss: -1.282\n",
      "\n",
      "data size: 500\n",
      "Iter 1/60 - Loss: 1.163\n",
      "Iter 2/60 - Loss: 1.136\n",
      "Iter 3/60 - Loss: 1.097\n",
      "Iter 4/60 - Loss: 1.054\n",
      "Iter 5/60 - Loss: 1.016\n",
      "Iter 6/60 - Loss: 0.975\n",
      "Iter 7/60 - Loss: 0.934\n",
      "Iter 8/60 - Loss: 0.901\n",
      "Iter 9/60 - Loss: 0.862\n",
      "Iter 10/60 - Loss: 0.823\n",
      "Iter 11/60 - Loss: 0.774\n",
      "Iter 12/60 - Loss: 0.734\n",
      "Iter 13/60 - Loss: 0.695\n",
      "Iter 14/60 - Loss: 0.647\n",
      "Iter 15/60 - Loss: 0.612\n",
      "Iter 16/60 - Loss: 0.566\n",
      "Iter 17/60 - Loss: 0.521\n",
      "Iter 18/60 - Loss: 0.480\n",
      "Iter 19/60 - Loss: 0.438\n",
      "Iter 20/60 - Loss: 0.396\n",
      "Iter 21/60 - Loss: 0.356\n",
      "Iter 22/60 - Loss: 0.311\n",
      "Iter 23/60 - Loss: 0.270\n",
      "Iter 24/60 - Loss: 0.229\n",
      "Iter 25/60 - Loss: 0.185\n",
      "Iter 26/60 - Loss: 0.140\n",
      "Iter 27/60 - Loss: 0.104\n",
      "Iter 28/60 - Loss: 0.062\n",
      "Iter 29/60 - Loss: 0.027\n",
      "Iter 30/60 - Loss: -0.030\n",
      "Iter 31/60 - Loss: -0.064\n",
      "Iter 32/60 - Loss: -0.133\n",
      "Iter 33/60 - Loss: -0.182\n",
      "Iter 34/60 - Loss: -0.242\n",
      "Iter 35/60 - Loss: -0.299\n",
      "Iter 36/60 - Loss: -0.348\n",
      "Iter 37/60 - Loss: -0.387\n",
      "Iter 38/60 - Loss: -0.429\n",
      "Iter 39/60 - Loss: -0.476\n",
      "Iter 40/60 - Loss: -0.528\n",
      "Iter 41/60 - Loss: -0.591\n",
      "Iter 42/60 - Loss: -0.649\n",
      "Iter 43/60 - Loss: -0.672\n",
      "Iter 44/60 - Loss: -0.742\n",
      "Iter 45/60 - Loss: -0.792\n",
      "Iter 46/60 - Loss: -0.835\n",
      "Iter 47/60 - Loss: -0.892\n",
      "Iter 48/60 - Loss: -0.940\n",
      "Iter 49/60 - Loss: -0.989\n",
      "Iter 50/60 - Loss: -1.037\n",
      "Iter 51/60 - Loss: -1.078\n",
      "Iter 52/60 - Loss: -1.097\n",
      "Iter 53/60 - Loss: -1.143\n",
      "Iter 54/60 - Loss: -1.184\n",
      "Iter 55/60 - Loss: -1.192\n",
      "Iter 56/60 - Loss: -1.237\n",
      "Iter 57/60 - Loss: -1.275\n",
      "Iter 58/60 - Loss: -1.293\n",
      "Iter 59/60 - Loss: -1.330\n",
      "Iter 60/60 - Loss: -1.318\n",
      "\n",
      "data size: 700\n",
      "Iter 1/60 - Loss: 1.155\n",
      "Iter 2/60 - Loss: 1.147\n",
      "Iter 3/60 - Loss: 1.111\n",
      "Iter 4/60 - Loss: 1.076\n",
      "Iter 5/60 - Loss: 1.044\n",
      "Iter 6/60 - Loss: 1.009\n",
      "Iter 7/60 - Loss: 0.968\n",
      "Iter 8/60 - Loss: 0.933\n",
      "Iter 9/60 - Loss: 0.899\n",
      "Iter 10/60 - Loss: 0.857\n",
      "Iter 11/60 - Loss: 0.817\n",
      "Iter 12/60 - Loss: 0.777\n",
      "Iter 13/60 - Loss: 0.741\n",
      "Iter 14/60 - Loss: 0.697\n",
      "Iter 15/60 - Loss: 0.654\n",
      "Iter 16/60 - Loss: 0.613\n",
      "Iter 17/60 - Loss: 0.576\n",
      "Iter 18/60 - Loss: 0.533\n",
      "Iter 19/60 - Loss: 0.489\n",
      "Iter 20/60 - Loss: 0.452\n",
      "Iter 21/60 - Loss: 0.411\n",
      "Iter 22/60 - Loss: 0.374\n",
      "Iter 23/60 - Loss: 0.326\n",
      "Iter 24/60 - Loss: 0.284\n",
      "Iter 25/60 - Loss: 0.247\n",
      "Iter 26/60 - Loss: 0.202\n",
      "Iter 27/60 - Loss: 0.166\n",
      "Iter 28/60 - Loss: 0.122\n",
      "Iter 29/60 - Loss: 0.083\n",
      "Iter 30/60 - Loss: 0.030\n",
      "Iter 31/60 - Loss: -0.023\n",
      "Iter 32/60 - Loss: -0.077\n",
      "Iter 33/60 - Loss: -0.143\n",
      "Iter 34/60 - Loss: -0.205\n",
      "Iter 35/60 - Loss: -0.256\n",
      "Iter 36/60 - Loss: -0.308\n",
      "Iter 37/60 - Loss: -0.353\n",
      "Iter 38/60 - Loss: -0.404\n",
      "Iter 39/60 - Loss: -0.450\n",
      "Iter 40/60 - Loss: -0.499\n",
      "Iter 41/60 - Loss: -0.538\n",
      "Iter 42/60 - Loss: -0.600\n",
      "Iter 43/60 - Loss: -0.663\n",
      "Iter 44/60 - Loss: -0.704\n",
      "Iter 45/60 - Loss: -0.757\n",
      "Iter 46/60 - Loss: -0.810\n",
      "Iter 47/60 - Loss: -0.870\n",
      "Iter 48/60 - Loss: -0.926\n",
      "Iter 49/60 - Loss: -0.968\n",
      "Iter 50/60 - Loss: -1.015\n",
      "Iter 51/60 - Loss: -1.073\n",
      "Iter 52/60 - Loss: -1.113\n",
      "Iter 53/60 - Loss: -1.171\n",
      "Iter 54/60 - Loss: -1.217\n",
      "Iter 55/60 - Loss: -1.271\n",
      "Iter 56/60 - Loss: -1.319\n",
      "Iter 57/60 - Loss: -1.356\n",
      "Iter 58/60 - Loss: -1.407\n",
      "Iter 59/60 - Loss: -1.450\n",
      "Iter 60/60 - Loss: -1.502\n",
      "\n",
      "data size: 1000\n",
      "Iter 1/60 - Loss: 1.136\n",
      "Iter 2/60 - Loss: 1.128\n",
      "Iter 3/60 - Loss: 1.096\n",
      "Iter 4/60 - Loss: 1.064\n",
      "Iter 5/60 - Loss: 1.029\n",
      "Iter 6/60 - Loss: 0.994\n",
      "Iter 7/60 - Loss: 0.956\n",
      "Iter 8/60 - Loss: 0.919\n",
      "Iter 9/60 - Loss: 0.882\n",
      "Iter 10/60 - Loss: 0.848\n",
      "Iter 11/60 - Loss: 0.805\n",
      "Iter 12/60 - Loss: 0.765\n",
      "Iter 13/60 - Loss: 0.722\n",
      "Iter 14/60 - Loss: 0.680\n",
      "Iter 15/60 - Loss: 0.635\n",
      "Iter 16/60 - Loss: 0.588\n",
      "Iter 17/60 - Loss: 0.543\n",
      "Iter 18/60 - Loss: 0.494\n",
      "Iter 19/60 - Loss: 0.451\n",
      "Iter 20/60 - Loss: 0.412\n",
      "Iter 21/60 - Loss: 0.363\n",
      "Iter 22/60 - Loss: 0.314\n",
      "Iter 23/60 - Loss: 0.266\n",
      "Iter 24/60 - Loss: 0.214\n",
      "Iter 25/60 - Loss: 0.172\n",
      "Iter 26/60 - Loss: 0.117\n",
      "Iter 27/60 - Loss: 0.075\n",
      "Iter 28/60 - Loss: 0.020\n",
      "Iter 29/60 - Loss: -0.029\n",
      "Iter 30/60 - Loss: -0.073\n",
      "Iter 31/60 - Loss: -0.126\n",
      "Iter 32/60 - Loss: -0.174\n",
      "Iter 33/60 - Loss: -0.230\n",
      "Iter 34/60 - Loss: -0.273\n",
      "Iter 35/60 - Loss: -0.329\n",
      "Iter 36/60 - Loss: -0.376\n",
      "Iter 37/60 - Loss: -0.427\n",
      "Iter 38/60 - Loss: -0.482\n",
      "Iter 39/60 - Loss: -0.533\n",
      "Iter 40/60 - Loss: -0.579\n",
      "Iter 41/60 - Loss: -0.632\n",
      "Iter 42/60 - Loss: -0.684\n",
      "Iter 43/60 - Loss: -0.735\n",
      "Iter 44/60 - Loss: -0.782\n",
      "Iter 45/60 - Loss: -0.833\n",
      "Iter 46/60 - Loss: -0.885\n",
      "Iter 47/60 - Loss: -0.935\n",
      "Iter 48/60 - Loss: -0.984\n",
      "Iter 49/60 - Loss: -1.030\n",
      "Iter 50/60 - Loss: -1.086\n",
      "Iter 51/60 - Loss: -1.140\n",
      "Iter 52/60 - Loss: -1.189\n",
      "Iter 53/60 - Loss: -1.228\n",
      "Iter 54/60 - Loss: -1.277\n",
      "Iter 55/60 - Loss: -1.325\n",
      "Iter 56/60 - Loss: -1.367\n",
      "Iter 57/60 - Loss: -1.428\n",
      "Iter 58/60 - Loss: -1.479\n",
      "Iter 59/60 - Loss: -1.513\n",
      "Iter 60/60 - Loss: -1.565\n",
      "\n",
      "data size: 1500\n",
      "Iter 1/60 - Loss: 1.124\n",
      "Iter 2/60 - Loss: 1.113\n",
      "Iter 3/60 - Loss: 1.081\n",
      "Iter 4/60 - Loss: 1.047\n",
      "Iter 5/60 - Loss: 1.010\n",
      "Iter 6/60 - Loss: 0.977\n",
      "Iter 7/60 - Loss: 0.937\n",
      "Iter 8/60 - Loss: 0.899\n",
      "Iter 9/60 - Loss: 0.861\n",
      "Iter 10/60 - Loss: 0.822\n",
      "Iter 11/60 - Loss: 0.781\n",
      "Iter 12/60 - Loss: 0.739\n",
      "Iter 13/60 - Loss: 0.699\n",
      "Iter 14/60 - Loss: 0.654\n",
      "Iter 15/60 - Loss: 0.611\n",
      "Iter 16/60 - Loss: 0.566\n",
      "Iter 17/60 - Loss: 0.520\n",
      "Iter 18/60 - Loss: 0.477\n",
      "Iter 19/60 - Loss: 0.429\n",
      "Iter 20/60 - Loss: 0.384\n",
      "Iter 21/60 - Loss: 0.338\n",
      "Iter 22/60 - Loss: 0.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 23/60 - Loss: 0.242\n",
      "Iter 24/60 - Loss: 0.196\n",
      "Iter 25/60 - Loss: 0.146\n",
      "Iter 26/60 - Loss: 0.096\n",
      "Iter 27/60 - Loss: 0.046\n",
      "Iter 28/60 - Loss: -0.002\n",
      "Iter 29/60 - Loss: -0.052\n",
      "Iter 30/60 - Loss: -0.105\n",
      "Iter 31/60 - Loss: -0.149\n",
      "Iter 32/60 - Loss: -0.202\n",
      "Iter 33/60 - Loss: -0.254\n",
      "Iter 34/60 - Loss: -0.296\n",
      "Iter 35/60 - Loss: -0.352\n",
      "Iter 36/60 - Loss: -0.405\n",
      "Iter 37/60 - Loss: -0.452\n",
      "Iter 38/60 - Loss: -0.504\n",
      "Iter 39/60 - Loss: -0.552\n",
      "Iter 40/60 - Loss: -0.599\n",
      "Iter 41/60 - Loss: -0.655\n",
      "Iter 42/60 - Loss: -0.703\n",
      "Iter 43/60 - Loss: -0.754\n",
      "Iter 44/60 - Loss: -0.803\n",
      "Iter 45/60 - Loss: -0.852\n",
      "Iter 46/60 - Loss: -0.908\n",
      "Iter 47/60 - Loss: -0.957\n",
      "Iter 48/60 - Loss: -1.005\n",
      "Iter 49/60 - Loss: -1.053\n",
      "Iter 50/60 - Loss: -1.106\n",
      "Iter 51/60 - Loss: -1.148\n",
      "Iter 52/60 - Loss: -1.197\n",
      "Iter 53/60 - Loss: -1.240\n",
      "Iter 54/60 - Loss: -1.291\n",
      "Iter 55/60 - Loss: -1.339\n",
      "Iter 56/60 - Loss: -1.383\n",
      "Iter 57/60 - Loss: -1.432\n",
      "Iter 58/60 - Loss: -1.487\n",
      "Iter 59/60 - Loss: -1.524\n",
      "Iter 60/60 - Loss: -1.577\n",
      "\n",
      "data size: 2000\n",
      "Iter 1/60 - Loss: 1.119\n",
      "Iter 2/60 - Loss: 1.108\n",
      "Iter 3/60 - Loss: 1.074\n",
      "Iter 4/60 - Loss: 1.040\n",
      "Iter 5/60 - Loss: 1.001\n",
      "Iter 6/60 - Loss: 0.969\n",
      "Iter 7/60 - Loss: 0.929\n",
      "Iter 8/60 - Loss: 0.893\n",
      "Iter 9/60 - Loss: 0.853\n",
      "Iter 10/60 - Loss: 0.814\n",
      "Iter 11/60 - Loss: 0.773\n",
      "Iter 12/60 - Loss: 0.732\n",
      "Iter 13/60 - Loss: 0.687\n",
      "Iter 14/60 - Loss: 0.646\n",
      "Iter 15/60 - Loss: 0.603\n",
      "Iter 16/60 - Loss: 0.559\n",
      "Iter 17/60 - Loss: 0.518\n",
      "Iter 18/60 - Loss: 0.468\n",
      "Iter 19/60 - Loss: 0.423\n",
      "Iter 20/60 - Loss: 0.376\n",
      "Iter 21/60 - Loss: 0.331\n",
      "Iter 22/60 - Loss: 0.284\n",
      "Iter 23/60 - Loss: 0.234\n",
      "Iter 24/60 - Loss: 0.188\n",
      "Iter 25/60 - Loss: 0.139\n",
      "Iter 26/60 - Loss: 0.090\n",
      "Iter 27/60 - Loss: 0.042\n",
      "Iter 28/60 - Loss: -0.006\n",
      "Iter 29/60 - Loss: -0.059\n",
      "Iter 30/60 - Loss: -0.109\n",
      "Iter 31/60 - Loss: -0.159\n",
      "Iter 32/60 - Loss: -0.209\n",
      "Iter 33/60 - Loss: -0.256\n",
      "Iter 34/60 - Loss: -0.309\n",
      "Iter 35/60 - Loss: -0.361\n",
      "Iter 36/60 - Loss: -0.408\n",
      "Iter 37/60 - Loss: -0.458\n",
      "Iter 38/60 - Loss: -0.510\n",
      "Iter 39/60 - Loss: -0.562\n",
      "Iter 40/60 - Loss: -0.610\n",
      "Iter 41/60 - Loss: -0.664\n",
      "Iter 42/60 - Loss: -0.712\n",
      "Iter 43/60 - Loss: -0.759\n",
      "Iter 44/60 - Loss: -0.806\n",
      "Iter 45/60 - Loss: -0.859\n",
      "Iter 46/60 - Loss: -0.908\n",
      "Iter 47/60 - Loss: -0.958\n",
      "Iter 48/60 - Loss: -1.002\n",
      "Iter 49/60 - Loss: -1.058\n",
      "Iter 50/60 - Loss: -1.105\n",
      "Iter 51/60 - Loss: -1.157\n",
      "Iter 52/60 - Loss: -1.199\n",
      "Iter 53/60 - Loss: -1.240\n",
      "Iter 54/60 - Loss: -1.290\n",
      "Iter 55/60 - Loss: -1.349\n",
      "Iter 56/60 - Loss: -1.383\n",
      "Iter 57/60 - Loss: -1.433\n",
      "Iter 58/60 - Loss: -1.480\n",
      "Iter 59/60 - Loss: -1.533\n",
      "Iter 60/60 - Loss: -1.577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cpu_size_vec = [100,300,500,700,1000,1500,2000]\n",
    "Nval = 4\n",
    "Dval = 4\n",
    "\n",
    "for size in cpu_size_vec:\n",
    "    print(f\"data size: {size}\")\n",
    "    \"\"\"Set up the training and testing data\"\"\"\n",
    "    n = size # input size\n",
    "\n",
    "    x = torch.stack([\n",
    "        torch.linspace(0, 5, n),\n",
    "        torch.linspace(0, 5, n),\n",
    "        torch.linspace(0, 5, n),\n",
    "        torch.linspace(0, 5, n),\n",
    "    ], -1)\n",
    "\n",
    "    \"\"\" \n",
    "    loc=np.array([0, 6, 2, 4])\n",
    "    vec=np.array([0, 5, -2, 10])\n",
    "\n",
    "    vfield = VField(N=Nval, D=Dval, tgt_loc=loc, tgt_vec=vec, polynomial_order=3)\n",
    "    y = vfield(x)\n",
    "    \"\"\"\n",
    "\n",
    "    y = torch.stack([\n",
    "        torch.sin(x[:, 0] * (2 * math.pi)) + torch.randn(n) * 0.02,\n",
    "        torch.cos(x[:, 1] * (2 * math.pi)) + torch.randn(n) * 0.02,\n",
    "        torch.sin(x[:, 2] * (2 * math.pi)) + torch.cos(x[:, 1] * (2 * math.pi)) + torch.randn(n) * 0.02,\n",
    "        (torch.cos(x[:, 3] * (2 * math.pi)))* (torch.sin(x[:, 0] * (2 * math.pi))) + torch.randn(n) * 0.02,\n",
    "    ], -1)\n",
    "\n",
    "    train_x = torch.Tensor(x[:int(0.8*n), :])\n",
    "    train_y = y[:int(0.8*n), :]\n",
    "\n",
    "    test_x = torch.Tensor(x[int(0.8*n):, :])\n",
    "\n",
    "    test_y = torch.Tensor(y[int(0.8*n):, :])\n",
    "\n",
    "#     # normalize features\n",
    "#     mean = train_x.mean(dim=-2, keepdim=True)\n",
    "#     std = train_x.std(dim=-2, keepdim=True) # + 1e-6 # prevent dividing by 0\n",
    "#     train_x = (train_x - mean) / std\n",
    "#     test_x = (test_x - mean) / std\n",
    "\n",
    "#     # normalize labels\n",
    "#     mean, std = train_y.mean(),train_y.std()\n",
    "#     train_y = (train_y - mean) / std\n",
    "#     test_y = (test_y - mean) / std\n",
    "\n",
    "#     norm_vec = (vec - mean) / std\n",
    "    \n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=Dval)\n",
    "    model = MultitaskGPModel(train_x, train_y, likelihood, num_base_kernels)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    \"\"\"train the model hyperparameters\"\"\"\n",
    "    import os\n",
    "    smoke_test = ('CI' in os.environ)\n",
    "    training_iterations = 2 if smoke_test else 60\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    with gpytorch.settings.max_cg_iterations(1000):\n",
    "        for i in range(training_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "#           if(i > training_iterations*0.8):\n",
    "            print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "            optimizer.step()\n",
    "    \n",
    "    cpu_training_time.append(time.time() - start_time)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \"\"\" Making predictions with the model\"\"\"\n",
    "    # Set into eval mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Exact predictions\n",
    "    with torch.no_grad(): #, gpytorch.settings.fast_pred_var():\n",
    "        start_time = time.time()\n",
    "        preds = model(test_x) # no noise\n",
    "        covar = preds.covariance_matrix\n",
    "        cpu_exact_meancovar.append(time.time() - start_time)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LOVE without cache\n",
    "        # Clear the cache from the previous computations\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    # Set into eval mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        start_time = time.time()\n",
    "        preds = model(test_x)\n",
    "        fast_covar = preds.covariance_matrix\n",
    "        cpu_love_meancovar.append(time.time() - start_time)\n",
    "    \n",
    "    # LOVE with cache\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        start_time = time.time()\n",
    "        preds = model(test_x)\n",
    "        fast_covar = preds.covariance_matrix\n",
    "        cpu_love_meancovar_cache.append(time.time() - start_time)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7215499877929688, 9.794497728347778, 14.904312372207642, 21.27997350692749, 32.48446846008301, 53.88267135620117, 81.62078332901001]\n",
      "[0.09543967247009277, 4.492389917373657, 18.700906991958618, 20.917333364486694, 65.99183177947998, 246.90132880210876, 582.1835989952087]\n",
      "[0.08900070190429688, 0.7966694831848145, 1.2842626571655273, 1.385444164276123, 3.100579023361206, 6.697657585144043, 15.783673286437988]\n",
      "[0.014788627624511719, 0.0886070728302002, 0.11827206611633301, 0.20630216598510742, 0.39751195907592773, 0.8935346603393555, 1.9156162738800049]\n"
     ]
    }
   ],
   "source": [
    "print(cpu_training_time)\n",
    "print(cpu_exact_meancovar)\n",
    "print(cpu_love_meancovar)\n",
    "print(cpu_love_meancovar_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize plots\n",
    "# f, (y1_ax, y2_ax) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "# # This contains predictions for both tasks, flattened out\n",
    "# # The first half of the predictions is for the first task\n",
    "# # The second half is for the second task\n",
    "\n",
    "# # Plot training data as black stars\n",
    "# y1_ax.plot(train_x[:, 0].detach().numpy(), train_y[:, 0].detach().numpy(), 'k*')\n",
    "# # Predictive mean as blue line\n",
    "# y1_ax.plot(test_x[:, 0].numpy(), preds.mean[:, 0].numpy(), 'b')\n",
    "# # Shade in confidence\n",
    "# # y1_ax.fill_between(test_x[:, 0].numpy(), lower[:, 0].numpy(), upper[:, 0].numpy(), alpha=0.5)\n",
    "# # y1_ax.set_ylim([-3, 3])\n",
    "# y1_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "# y1_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# # Plot training data as black stars\n",
    "# y2_ax.plot(train_x[:, 1].detach().numpy(), train_y[:, 1].detach().numpy(), 'k*')\n",
    "# # Predictive mean as blue line\n",
    "# y2_ax.plot(test_x[:, 1].numpy(), preds.mean[:, 1].numpy(), 'b')\n",
    "# # Shade in confidence\n",
    "# # y2_ax.fill_between(test_x[:, 1].numpy(), lower[:, 1].numpy(), upper[:, 1].numpy(), alpha=0.5)\n",
    "# # y2_ax.set_ylim([-3, 3])\n",
    "# y2_ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "# y2_ax.set_title('Observed Values (Likelihood)')\n",
    "\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_training_time = []\n",
    "gpu_exact_meancovar = []\n",
    "gpu_love_meancovar = []\n",
    "gpu_love_meancovar_cache = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: 100\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.345\n",
      "Iter 2/60 - Loss: 1.297\n",
      "Iter 3/60 - Loss: 1.254\n",
      "Iter 4/60 - Loss: 1.216\n",
      "Iter 5/60 - Loss: 1.177\n",
      "Iter 6/60 - Loss: 1.137\n",
      "Iter 7/60 - Loss: 1.095\n",
      "Iter 8/60 - Loss: 1.053\n",
      "Iter 9/60 - Loss: 1.011\n",
      "Iter 10/60 - Loss: 0.970\n",
      "Iter 11/60 - Loss: 0.929\n",
      "Iter 12/60 - Loss: 0.887\n",
      "Iter 13/60 - Loss: 0.843\n",
      "Iter 14/60 - Loss: 0.799\n",
      "Iter 15/60 - Loss: 0.755\n",
      "Iter 16/60 - Loss: 0.710\n",
      "Iter 17/60 - Loss: 0.665\n",
      "Iter 18/60 - Loss: 0.620\n",
      "Iter 19/60 - Loss: 0.574\n",
      "Iter 20/60 - Loss: 0.528\n",
      "Iter 21/60 - Loss: 0.481\n",
      "Iter 22/60 - Loss: 0.434\n",
      "Iter 23/60 - Loss: 0.387\n",
      "Iter 24/60 - Loss: 0.340\n",
      "Iter 25/60 - Loss: 0.293\n",
      "Iter 26/60 - Loss: 0.246\n",
      "Iter 27/60 - Loss: 0.198\n",
      "Iter 28/60 - Loss: 0.150\n",
      "Iter 29/60 - Loss: 0.102\n",
      "Iter 30/60 - Loss: 0.054\n",
      "Iter 31/60 - Loss: 0.007\n",
      "Iter 32/60 - Loss: -0.041\n",
      "Iter 33/60 - Loss: -0.089\n",
      "Iter 34/60 - Loss: -0.137\n",
      "Iter 35/60 - Loss: -0.185\n",
      "Iter 36/60 - Loss: -0.233\n",
      "Iter 37/60 - Loss: -0.280\n",
      "Iter 38/60 - Loss: -0.328\n",
      "Iter 39/60 - Loss: -0.376\n",
      "Iter 40/60 - Loss: -0.423\n",
      "Iter 41/60 - Loss: -0.470\n",
      "Iter 42/60 - Loss: -0.518\n",
      "Iter 43/60 - Loss: -0.565\n",
      "Iter 44/60 - Loss: -0.612\n",
      "Iter 45/60 - Loss: -0.658\n",
      "Iter 46/60 - Loss: -0.705\n",
      "Iter 47/60 - Loss: -0.751\n",
      "Iter 48/60 - Loss: -0.797\n",
      "Iter 49/60 - Loss: -0.842\n",
      "Iter 50/60 - Loss: -0.887\n",
      "Iter 51/60 - Loss: -0.932\n",
      "Iter 52/60 - Loss: -0.977\n",
      "Iter 53/60 - Loss: -1.021\n",
      "Iter 54/60 - Loss: -1.064\n",
      "Iter 55/60 - Loss: -1.108\n",
      "Iter 56/60 - Loss: -1.152\n",
      "Iter 57/60 - Loss: -1.193\n",
      "Iter 58/60 - Loss: -1.232\n",
      "Iter 59/60 - Loss: -1.274\n",
      "Iter 60/60 - Loss: -1.317\n",
      "\n",
      "data size: 300\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.196\n",
      "Iter 2/60 - Loss: 1.163\n",
      "Iter 3/60 - Loss: 1.132\n",
      "Iter 4/60 - Loss: 1.077\n",
      "Iter 5/60 - Loss: 1.040\n",
      "Iter 6/60 - Loss: 1.001\n",
      "Iter 7/60 - Loss: 0.968\n",
      "Iter 8/60 - Loss: 0.924\n",
      "Iter 9/60 - Loss: 0.880\n",
      "Iter 10/60 - Loss: 0.829\n",
      "Iter 11/60 - Loss: 0.790\n",
      "Iter 12/60 - Loss: 0.754\n",
      "Iter 13/60 - Loss: 0.705\n",
      "Iter 14/60 - Loss: 0.662\n",
      "Iter 15/60 - Loss: 0.619\n",
      "Iter 16/60 - Loss: 0.566\n",
      "Iter 17/60 - Loss: 0.522\n",
      "Iter 18/60 - Loss: 0.487\n",
      "Iter 19/60 - Loss: 0.435\n",
      "Iter 20/60 - Loss: 0.379\n",
      "Iter 21/60 - Loss: 0.344\n",
      "Iter 22/60 - Loss: 0.286\n",
      "Iter 23/60 - Loss: 0.242\n",
      "Iter 24/60 - Loss: 0.191\n",
      "Iter 25/60 - Loss: 0.143\n",
      "Iter 26/60 - Loss: 0.086\n",
      "Iter 27/60 - Loss: 0.048\n",
      "Iter 28/60 - Loss: -0.007\n",
      "Iter 29/60 - Loss: -0.057\n",
      "Iter 30/60 - Loss: -0.106\n",
      "Iter 31/60 - Loss: -0.164\n",
      "Iter 32/60 - Loss: -0.204\n",
      "Iter 33/60 - Loss: -0.266\n",
      "Iter 34/60 - Loss: -0.314\n",
      "Iter 35/60 - Loss: -0.358\n",
      "Iter 36/60 - Loss: -0.405\n",
      "Iter 37/60 - Loss: -0.466\n",
      "Iter 38/60 - Loss: -0.515\n",
      "Iter 39/60 - Loss: -0.556\n",
      "Iter 40/60 - Loss: -0.586\n",
      "Iter 41/60 - Loss: -0.636\n",
      "Iter 42/60 - Loss: -0.679\n",
      "Iter 43/60 - Loss: -0.724\n",
      "Iter 44/60 - Loss: -0.769\n",
      "Iter 45/60 - Loss: -0.834\n",
      "Iter 46/60 - Loss: -0.876\n",
      "Iter 47/60 - Loss: -0.944\n",
      "Iter 48/60 - Loss: -0.981\n",
      "Iter 49/60 - Loss: -0.992\n",
      "Iter 50/60 - Loss: -1.008\n",
      "Iter 51/60 - Loss: -1.051\n",
      "Iter 52/60 - Loss: -1.097\n",
      "Iter 53/60 - Loss: -1.106\n",
      "Iter 54/60 - Loss: -1.122\n",
      "Iter 55/60 - Loss: -1.150\n",
      "Iter 56/60 - Loss: -1.131\n",
      "Iter 57/60 - Loss: -1.088\n",
      "Iter 58/60 - Loss: -1.131\n",
      "Iter 59/60 - Loss: -1.121\n",
      "Iter 60/60 - Loss: -1.099\n",
      "\n",
      "data size: 500\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.164\n",
      "Iter 2/60 - Loss: 1.121\n",
      "Iter 3/60 - Loss: 1.079\n",
      "Iter 4/60 - Loss: 1.053\n",
      "Iter 5/60 - Loss: 1.009\n",
      "Iter 6/60 - Loss: 0.963\n",
      "Iter 7/60 - Loss: 0.930\n",
      "Iter 8/60 - Loss: 0.887\n",
      "Iter 9/60 - Loss: 0.842\n",
      "Iter 10/60 - Loss: 0.801\n",
      "Iter 11/60 - Loss: 0.760\n",
      "Iter 12/60 - Loss: 0.711\n",
      "Iter 13/60 - Loss: 0.671\n",
      "Iter 14/60 - Loss: 0.623\n",
      "Iter 15/60 - Loss: 0.580\n",
      "Iter 16/60 - Loss: 0.540\n",
      "Iter 17/60 - Loss: 0.498\n",
      "Iter 18/60 - Loss: 0.439\n",
      "Iter 19/60 - Loss: 0.391\n",
      "Iter 20/60 - Loss: 0.348\n",
      "Iter 21/60 - Loss: 0.301\n",
      "Iter 22/60 - Loss: 0.257\n",
      "Iter 23/60 - Loss: 0.201\n",
      "Iter 24/60 - Loss: 0.147\n",
      "Iter 25/60 - Loss: 0.111\n",
      "Iter 26/60 - Loss: 0.058\n",
      "Iter 27/60 - Loss: 0.015\n",
      "Iter 28/60 - Loss: -0.048\n",
      "Iter 29/60 - Loss: -0.094\n",
      "Iter 30/60 - Loss: -0.145\n",
      "Iter 31/60 - Loss: -0.198\n",
      "Iter 32/60 - Loss: -0.239\n",
      "Iter 33/60 - Loss: -0.302\n",
      "Iter 34/60 - Loss: -0.338\n",
      "Iter 35/60 - Loss: -0.391\n",
      "Iter 36/60 - Loss: -0.438\n",
      "Iter 37/60 - Loss: -0.494\n",
      "Iter 38/60 - Loss: -0.544\n",
      "Iter 39/60 - Loss: -0.598\n",
      "Iter 40/60 - Loss: -0.631\n",
      "Iter 41/60 - Loss: -0.685\n",
      "Iter 42/60 - Loss: -0.712\n",
      "Iter 43/60 - Loss: -0.761\n",
      "Iter 44/60 - Loss: -0.823\n",
      "Iter 45/60 - Loss: -0.885\n",
      "Iter 46/60 - Loss: -0.914\n",
      "Iter 47/60 - Loss: -0.945\n",
      "Iter 48/60 - Loss: -1.002\n",
      "Iter 49/60 - Loss: -1.052\n",
      "Iter 50/60 - Loss: -1.093\n",
      "Iter 51/60 - Loss: -1.127\n",
      "Iter 52/60 - Loss: -1.172\n",
      "Iter 53/60 - Loss: -1.189\n",
      "Iter 54/60 - Loss: -1.200\n",
      "Iter 55/60 - Loss: -1.251\n",
      "Iter 56/60 - Loss: -1.263\n",
      "Iter 57/60 - Loss: -1.283\n",
      "Iter 58/60 - Loss: -1.279\n",
      "Iter 59/60 - Loss: -1.301\n",
      "Iter 60/60 - Loss: -1.356\n",
      "\n",
      "data size: 700\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.144\n",
      "Iter 2/60 - Loss: 1.130\n",
      "Iter 3/60 - Loss: 1.100\n",
      "Iter 4/60 - Loss: 1.067\n",
      "Iter 5/60 - Loss: 1.029\n",
      "Iter 6/60 - Loss: 0.998\n",
      "Iter 7/60 - Loss: 0.956\n",
      "Iter 8/60 - Loss: 0.922\n",
      "Iter 9/60 - Loss: 0.879\n",
      "Iter 10/60 - Loss: 0.833\n",
      "Iter 11/60 - Loss: 0.795\n",
      "Iter 12/60 - Loss: 0.756\n",
      "Iter 13/60 - Loss: 0.717\n",
      "Iter 14/60 - Loss: 0.672\n",
      "Iter 15/60 - Loss: 0.629\n",
      "Iter 16/60 - Loss: 0.589\n",
      "Iter 17/60 - Loss: 0.540\n",
      "Iter 18/60 - Loss: 0.499\n",
      "Iter 19/60 - Loss: 0.450\n",
      "Iter 20/60 - Loss: 0.404\n",
      "Iter 21/60 - Loss: 0.356\n",
      "Iter 22/60 - Loss: 0.311\n",
      "Iter 23/60 - Loss: 0.261\n",
      "Iter 24/60 - Loss: 0.213\n",
      "Iter 25/60 - Loss: 0.166\n",
      "Iter 26/60 - Loss: 0.118\n",
      "Iter 27/60 - Loss: 0.067\n",
      "Iter 28/60 - Loss: 0.016\n",
      "Iter 29/60 - Loss: -0.030\n",
      "Iter 30/60 - Loss: -0.075\n",
      "Iter 31/60 - Loss: -0.130\n",
      "Iter 32/60 - Loss: -0.182\n",
      "Iter 33/60 - Loss: -0.233\n",
      "Iter 34/60 - Loss: -0.281\n",
      "Iter 35/60 - Loss: -0.337\n",
      "Iter 36/60 - Loss: -0.382\n",
      "Iter 37/60 - Loss: -0.429\n",
      "Iter 38/60 - Loss: -0.483\n",
      "Iter 39/60 - Loss: -0.533\n",
      "Iter 40/60 - Loss: -0.583\n",
      "Iter 41/60 - Loss: -0.638\n",
      "Iter 42/60 - Loss: -0.684\n",
      "Iter 43/60 - Loss: -0.727\n",
      "Iter 44/60 - Loss: -0.783\n",
      "Iter 45/60 - Loss: -0.838\n",
      "Iter 46/60 - Loss: -0.891\n",
      "Iter 47/60 - Loss: -0.938\n",
      "Iter 48/60 - Loss: -0.990\n",
      "Iter 49/60 - Loss: -1.039\n",
      "Iter 50/60 - Loss: -1.096\n",
      "Iter 51/60 - Loss: -1.133\n",
      "Iter 52/60 - Loss: -1.185\n",
      "Iter 53/60 - Loss: -1.236\n",
      "Iter 54/60 - Loss: -1.287\n",
      "Iter 55/60 - Loss: -1.337\n",
      "Iter 56/60 - Loss: -1.382\n",
      "Iter 57/60 - Loss: -1.425\n",
      "Iter 58/60 - Loss: -1.454\n",
      "Iter 59/60 - Loss: -1.516\n",
      "Iter 60/60 - Loss: -1.570\n",
      "\n",
      "data size: 1000\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.128\n",
      "Iter 2/60 - Loss: 1.117\n",
      "Iter 3/60 - Loss: 1.084\n",
      "Iter 4/60 - Loss: 1.048\n",
      "Iter 5/60 - Loss: 1.015\n",
      "Iter 6/60 - Loss: 0.977\n",
      "Iter 7/60 - Loss: 0.941\n",
      "Iter 8/60 - Loss: 0.905\n",
      "Iter 9/60 - Loss: 0.862\n",
      "Iter 10/60 - Loss: 0.826\n",
      "Iter 11/60 - Loss: 0.782\n",
      "Iter 12/60 - Loss: 0.742\n",
      "Iter 13/60 - Loss: 0.701\n",
      "Iter 14/60 - Loss: 0.656\n",
      "Iter 15/60 - Loss: 0.614\n",
      "Iter 16/60 - Loss: 0.571\n",
      "Iter 17/60 - Loss: 0.523\n",
      "Iter 18/60 - Loss: 0.478\n",
      "Iter 19/60 - Loss: 0.435\n",
      "Iter 20/60 - Loss: 0.387\n",
      "Iter 21/60 - Loss: 0.340\n",
      "Iter 22/60 - Loss: 0.297\n",
      "Iter 23/60 - Loss: 0.247\n",
      "Iter 24/60 - Loss: 0.198\n",
      "Iter 25/60 - Loss: 0.148\n",
      "Iter 26/60 - Loss: 0.102\n",
      "Iter 27/60 - Loss: 0.049\n",
      "Iter 28/60 - Loss: 0.001\n",
      "Iter 29/60 - Loss: -0.046\n",
      "Iter 30/60 - Loss: -0.097\n",
      "Iter 31/60 - Loss: -0.148\n",
      "Iter 32/60 - Loss: -0.197\n",
      "Iter 33/60 - Loss: -0.249\n",
      "Iter 34/60 - Loss: -0.298\n",
      "Iter 35/60 - Loss: -0.349\n",
      "Iter 36/60 - Loss: -0.400\n",
      "Iter 37/60 - Loss: -0.450\n",
      "Iter 38/60 - Loss: -0.504\n",
      "Iter 39/60 - Loss: -0.552\n",
      "Iter 40/60 - Loss: -0.605\n",
      "Iter 41/60 - Loss: -0.660\n",
      "Iter 42/60 - Loss: -0.705\n",
      "Iter 43/60 - Loss: -0.757\n",
      "Iter 44/60 - Loss: -0.806\n",
      "Iter 45/60 - Loss: -0.856\n",
      "Iter 46/60 - Loss: -0.912\n",
      "Iter 47/60 - Loss: -0.958\n",
      "Iter 48/60 - Loss: -1.009\n",
      "Iter 49/60 - Loss: -1.059\n",
      "Iter 50/60 - Loss: -1.108\n",
      "Iter 51/60 - Loss: -1.155\n",
      "Iter 52/60 - Loss: -1.206\n",
      "Iter 53/60 - Loss: -1.253\n",
      "Iter 54/60 - Loss: -1.308\n",
      "Iter 55/60 - Loss: -1.359\n",
      "Iter 56/60 - Loss: -1.404\n",
      "Iter 57/60 - Loss: -1.450\n",
      "Iter 58/60 - Loss: -1.500\n",
      "Iter 59/60 - Loss: -1.546\n",
      "Iter 60/60 - Loss: -1.588\n",
      "\n",
      "data size: 1500\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.116\n",
      "Iter 2/60 - Loss: 1.107\n",
      "Iter 3/60 - Loss: 1.072\n",
      "Iter 4/60 - Loss: 1.040\n",
      "Iter 5/60 - Loss: 1.002\n",
      "Iter 6/60 - Loss: 0.965\n",
      "Iter 7/60 - Loss: 0.929\n",
      "Iter 8/60 - Loss: 0.892\n",
      "Iter 9/60 - Loss: 0.852\n",
      "Iter 10/60 - Loss: 0.812\n",
      "Iter 11/60 - Loss: 0.772\n",
      "Iter 12/60 - Loss: 0.732\n",
      "Iter 13/60 - Loss: 0.687\n",
      "Iter 14/60 - Loss: 0.646\n",
      "Iter 15/60 - Loss: 0.602\n",
      "Iter 16/60 - Loss: 0.559\n",
      "Iter 17/60 - Loss: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 18/60 - Loss: 0.470\n",
      "Iter 19/60 - Loss: 0.425\n",
      "Iter 20/60 - Loss: 0.376\n",
      "Iter 21/60 - Loss: 0.329\n",
      "Iter 22/60 - Loss: 0.281\n",
      "Iter 23/60 - Loss: 0.234\n",
      "Iter 24/60 - Loss: 0.185\n",
      "Iter 25/60 - Loss: 0.135\n",
      "Iter 26/60 - Loss: 0.086\n",
      "Iter 27/60 - Loss: 0.039\n",
      "Iter 28/60 - Loss: -0.009\n",
      "Iter 29/60 - Loss: -0.059\n",
      "Iter 30/60 - Loss: -0.112\n",
      "Iter 31/60 - Loss: -0.160\n",
      "Iter 32/60 - Loss: -0.211\n",
      "Iter 33/60 - Loss: -0.263\n",
      "Iter 34/60 - Loss: -0.312\n",
      "Iter 35/60 - Loss: -0.364\n",
      "Iter 36/60 - Loss: -0.415\n",
      "Iter 37/60 - Loss: -0.465\n",
      "Iter 38/60 - Loss: -0.517\n",
      "Iter 39/60 - Loss: -0.567\n",
      "Iter 40/60 - Loss: -0.618\n",
      "Iter 41/60 - Loss: -0.668\n",
      "Iter 42/60 - Loss: -0.723\n",
      "Iter 43/60 - Loss: -0.770\n",
      "Iter 44/60 - Loss: -0.823\n",
      "Iter 45/60 - Loss: -0.877\n",
      "Iter 46/60 - Loss: -0.925\n",
      "Iter 47/60 - Loss: -0.978\n",
      "Iter 48/60 - Loss: -1.028\n",
      "Iter 49/60 - Loss: -1.080\n",
      "Iter 50/60 - Loss: -1.132\n",
      "Iter 51/60 - Loss: -1.182\n",
      "Iter 52/60 - Loss: -1.230\n",
      "Iter 53/60 - Loss: -1.277\n",
      "Iter 54/60 - Loss: -1.328\n",
      "Iter 55/60 - Loss: -1.378\n",
      "Iter 56/60 - Loss: -1.424\n",
      "Iter 57/60 - Loss: -1.477\n",
      "Iter 58/60 - Loss: -1.521\n",
      "Iter 59/60 - Loss: -1.575\n",
      "Iter 60/60 - Loss: -1.625\n",
      "\n",
      "data size: 2000\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.110\n",
      "Iter 2/60 - Loss: 1.100\n",
      "Iter 3/60 - Loss: 1.067\n",
      "Iter 4/60 - Loss: 1.031\n",
      "Iter 5/60 - Loss: 0.997\n",
      "Iter 6/60 - Loss: 0.961\n",
      "Iter 7/60 - Loss: 0.922\n",
      "Iter 8/60 - Loss: 0.885\n",
      "Iter 9/60 - Loss: 0.845\n",
      "Iter 10/60 - Loss: 0.807\n",
      "Iter 11/60 - Loss: 0.766\n",
      "Iter 12/60 - Loss: 0.725\n",
      "Iter 13/60 - Loss: 0.682\n",
      "Iter 14/60 - Loss: 0.639\n",
      "Iter 15/60 - Loss: 0.595\n",
      "Iter 16/60 - Loss: 0.552\n",
      "Iter 17/60 - Loss: 0.507\n",
      "Iter 18/60 - Loss: 0.461\n",
      "Iter 19/60 - Loss: 0.414\n",
      "Iter 20/60 - Loss: 0.368\n",
      "Iter 21/60 - Loss: 0.321\n",
      "Iter 22/60 - Loss: 0.276\n",
      "Iter 23/60 - Loss: 0.227\n",
      "Iter 24/60 - Loss: 0.177\n",
      "Iter 25/60 - Loss: 0.127\n",
      "Iter 26/60 - Loss: 0.081\n",
      "Iter 27/60 - Loss: 0.031\n",
      "Iter 28/60 - Loss: -0.018\n",
      "Iter 29/60 - Loss: -0.068\n",
      "Iter 30/60 - Loss: -0.117\n",
      "Iter 31/60 - Loss: -0.169\n",
      "Iter 32/60 - Loss: -0.220\n",
      "Iter 33/60 - Loss: -0.269\n",
      "Iter 34/60 - Loss: -0.322\n",
      "Iter 35/60 - Loss: -0.372\n",
      "Iter 36/60 - Loss: -0.421\n",
      "Iter 37/60 - Loss: -0.476\n",
      "Iter 38/60 - Loss: -0.528\n",
      "Iter 39/60 - Loss: -0.579\n",
      "Iter 40/60 - Loss: -0.626\n",
      "Iter 41/60 - Loss: -0.681\n",
      "Iter 42/60 - Loss: -0.731\n",
      "Iter 43/60 - Loss: -0.784\n",
      "Iter 44/60 - Loss: -0.833\n",
      "Iter 45/60 - Loss: -0.885\n",
      "Iter 46/60 - Loss: -0.938\n",
      "Iter 47/60 - Loss: -0.988\n",
      "Iter 48/60 - Loss: -1.038\n",
      "Iter 49/60 - Loss: -1.092\n",
      "Iter 50/60 - Loss: -1.141\n",
      "Iter 51/60 - Loss: -1.189\n",
      "Iter 52/60 - Loss: -1.240\n",
      "Iter 53/60 - Loss: -1.282\n",
      "Iter 54/60 - Loss: -1.332\n",
      "Iter 55/60 - Loss: -1.385\n",
      "Iter 56/60 - Loss: -1.436\n",
      "Iter 57/60 - Loss: -1.484\n",
      "Iter 58/60 - Loss: -1.533\n",
      "Iter 59/60 - Loss: -1.580\n",
      "Iter 60/60 - Loss: -1.636\n",
      "\n",
      "data size: 3000\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.101\n",
      "Iter 2/60 - Loss: 1.092\n",
      "Iter 3/60 - Loss: 1.060\n",
      "Iter 4/60 - Loss: 1.027\n",
      "Iter 5/60 - Loss: 0.991\n",
      "Iter 6/60 - Loss: 0.954\n",
      "Iter 7/60 - Loss: 0.917\n",
      "Iter 8/60 - Loss: 0.879\n",
      "Iter 9/60 - Loss: 0.839\n",
      "Iter 10/60 - Loss: 0.799\n",
      "Iter 11/60 - Loss: 0.757\n",
      "Iter 12/60 - Loss: 0.716\n",
      "Iter 13/60 - Loss: 0.674\n",
      "Iter 14/60 - Loss: 0.631\n",
      "Iter 15/60 - Loss: 0.588\n",
      "Iter 16/60 - Loss: 0.544\n",
      "Iter 17/60 - Loss: 0.499\n",
      "Iter 18/60 - Loss: 0.453\n",
      "Iter 19/60 - Loss: 0.408\n",
      "Iter 20/60 - Loss: 0.360\n",
      "Iter 21/60 - Loss: 0.313\n",
      "Iter 22/60 - Loss: 0.266\n",
      "Iter 23/60 - Loss: 0.218\n",
      "Iter 24/60 - Loss: 0.170\n",
      "Iter 25/60 - Loss: 0.119\n",
      "Iter 26/60 - Loss: 0.071\n",
      "Iter 27/60 - Loss: 0.022\n",
      "Iter 28/60 - Loss: -0.027\n",
      "Iter 29/60 - Loss: -0.077\n",
      "Iter 30/60 - Loss: -0.126\n",
      "Iter 31/60 - Loss: -0.178\n",
      "Iter 32/60 - Loss: -0.228\n",
      "Iter 33/60 - Loss: -0.277\n",
      "Iter 34/60 - Loss: -0.330\n",
      "Iter 35/60 - Loss: -0.382\n",
      "Iter 36/60 - Loss: -0.432\n",
      "Iter 37/60 - Loss: -0.483\n",
      "Iter 38/60 - Loss: -0.535\n",
      "Iter 39/60 - Loss: -0.588\n",
      "Iter 40/60 - Loss: -0.638\n",
      "Iter 41/60 - Loss: -0.688\n",
      "Iter 42/60 - Loss: -0.740\n",
      "Iter 43/60 - Loss: -0.792\n",
      "Iter 44/60 - Loss: -0.842\n",
      "Iter 45/60 - Loss: -0.894\n",
      "Iter 46/60 - Loss: -0.947\n",
      "Iter 47/60 - Loss: -0.998\n",
      "Iter 48/60 - Loss: -1.047\n",
      "Iter 49/60 - Loss: -1.100\n",
      "Iter 50/60 - Loss: -1.152\n",
      "Iter 51/60 - Loss: -1.203\n",
      "Iter 52/60 - Loss: -1.253\n",
      "Iter 53/60 - Loss: -1.304\n",
      "Iter 54/60 - Loss: -1.357\n",
      "Iter 55/60 - Loss: -1.404\n",
      "Iter 56/60 - Loss: -1.452\n",
      "Iter 57/60 - Loss: -1.505\n",
      "Iter 58/60 - Loss: -1.550\n",
      "Iter 59/60 - Loss: -1.601\n",
      "Iter 60/60 - Loss: -1.646\n",
      "\n",
      "data size: 4000\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.099\n",
      "Iter 2/60 - Loss: 1.088\n",
      "Iter 3/60 - Loss: 1.055\n",
      "Iter 4/60 - Loss: 1.021\n",
      "Iter 5/60 - Loss: 0.987\n",
      "Iter 6/60 - Loss: 0.952\n",
      "Iter 7/60 - Loss: 0.913\n",
      "Iter 8/60 - Loss: 0.875\n",
      "Iter 9/60 - Loss: 0.835\n",
      "Iter 10/60 - Loss: 0.794\n",
      "Iter 11/60 - Loss: 0.754\n",
      "Iter 12/60 - Loss: 0.713\n",
      "Iter 13/60 - Loss: 0.672\n",
      "Iter 14/60 - Loss: 0.629\n",
      "Iter 15/60 - Loss: 0.583\n",
      "Iter 16/60 - Loss: 0.541\n",
      "Iter 17/60 - Loss: 0.494\n",
      "Iter 18/60 - Loss: 0.450\n",
      "Iter 19/60 - Loss: 0.404\n",
      "Iter 20/60 - Loss: 0.358\n",
      "Iter 21/60 - Loss: 0.311\n",
      "Iter 22/60 - Loss: 0.261\n",
      "Iter 23/60 - Loss: 0.214\n",
      "Iter 24/60 - Loss: 0.165\n",
      "Iter 25/60 - Loss: 0.117\n",
      "Iter 26/60 - Loss: 0.067\n",
      "Iter 27/60 - Loss: 0.019\n",
      "Iter 28/60 - Loss: -0.032\n",
      "Iter 29/60 - Loss: -0.081\n",
      "Iter 30/60 - Loss: -0.132\n",
      "Iter 31/60 - Loss: -0.183\n",
      "Iter 32/60 - Loss: -0.231\n",
      "Iter 33/60 - Loss: -0.283\n",
      "Iter 34/60 - Loss: -0.332\n",
      "Iter 35/60 - Loss: -0.385\n",
      "Iter 36/60 - Loss: -0.436\n",
      "Iter 37/60 - Loss: -0.487\n",
      "Iter 38/60 - Loss: -0.540\n",
      "Iter 39/60 - Loss: -0.590\n",
      "Iter 40/60 - Loss: -0.643\n",
      "Iter 41/60 - Loss: -0.694\n",
      "Iter 42/60 - Loss: -0.745\n",
      "Iter 43/60 - Loss: -0.797\n",
      "Iter 44/60 - Loss: -0.847\n",
      "Iter 45/60 - Loss: -0.899\n",
      "Iter 46/60 - Loss: -0.948\n",
      "Iter 47/60 - Loss: -1.001\n",
      "Iter 48/60 - Loss: -1.051\n",
      "Iter 49/60 - Loss: -1.102\n",
      "Iter 50/60 - Loss: -1.156\n",
      "Iter 51/60 - Loss: -1.203\n",
      "Iter 52/60 - Loss: -1.257\n",
      "Iter 53/60 - Loss: -1.306\n",
      "Iter 54/60 - Loss: -1.353\n",
      "Iter 55/60 - Loss: -1.408\n",
      "Iter 56/60 - Loss: -1.454\n",
      "Iter 57/60 - Loss: -1.500\n",
      "Iter 58/60 - Loss: -1.543\n",
      "Iter 59/60 - Loss: -1.596\n",
      "Iter 60/60 - Loss: -1.649\n",
      "\n",
      "data size: 5000\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.095\n",
      "Iter 2/60 - Loss: 1.085\n",
      "Iter 3/60 - Loss: 1.053\n",
      "Iter 4/60 - Loss: 1.018\n",
      "Iter 5/60 - Loss: 0.984\n",
      "Iter 6/60 - Loss: 0.947\n",
      "Iter 7/60 - Loss: 0.911\n",
      "Iter 8/60 - Loss: 0.873\n",
      "Iter 9/60 - Loss: 0.833\n",
      "Iter 10/60 - Loss: 0.793\n",
      "Iter 11/60 - Loss: 0.752\n",
      "Iter 12/60 - Loss: 0.711\n",
      "Iter 13/60 - Loss: 0.667\n",
      "Iter 14/60 - Loss: 0.625\n",
      "Iter 15/60 - Loss: 0.582\n",
      "Iter 16/60 - Loss: 0.537\n",
      "Iter 17/60 - Loss: 0.493\n",
      "Iter 18/60 - Loss: 0.447\n",
      "Iter 19/60 - Loss: 0.401\n",
      "Iter 20/60 - Loss: 0.355\n",
      "Iter 21/60 - Loss: 0.308\n",
      "Iter 22/60 - Loss: 0.259\n",
      "Iter 23/60 - Loss: 0.212\n",
      "Iter 24/60 - Loss: 0.163\n",
      "Iter 25/60 - Loss: 0.114\n",
      "Iter 26/60 - Loss: 0.065\n",
      "Iter 27/60 - Loss: 0.016\n",
      "Iter 28/60 - Loss: -0.034\n",
      "Iter 29/60 - Loss: -0.085\n",
      "Iter 30/60 - Loss: -0.135\n",
      "Iter 31/60 - Loss: -0.185\n",
      "Iter 32/60 - Loss: -0.235\n",
      "Iter 33/60 - Loss: -0.286\n",
      "Iter 34/60 - Loss: -0.337\n",
      "Iter 35/60 - Loss: -0.387\n",
      "Iter 36/60 - Loss: -0.439\n",
      "Iter 37/60 - Loss: -0.490\n",
      "Iter 38/60 - Loss: -0.541\n",
      "Iter 39/60 - Loss: -0.593\n",
      "Iter 40/60 - Loss: -0.644\n",
      "Iter 41/60 - Loss: -0.697\n",
      "Iter 42/60 - Loss: -0.749\n",
      "Iter 43/60 - Loss: -0.800\n",
      "Iter 44/60 - Loss: -0.850\n",
      "Iter 45/60 - Loss: -0.903\n",
      "Iter 46/60 - Loss: -0.954\n",
      "Iter 47/60 - Loss: -1.005\n",
      "Iter 48/60 - Loss: -1.058\n",
      "Iter 49/60 - Loss: -1.108\n",
      "Iter 50/60 - Loss: -1.160\n",
      "Iter 51/60 - Loss: -1.211\n",
      "Iter 52/60 - Loss: -1.264\n",
      "Iter 53/60 - Loss: -1.311\n",
      "Iter 54/60 - Loss: -1.364\n",
      "Iter 55/60 - Loss: -1.416\n",
      "Iter 56/60 - Loss: -1.464\n",
      "Iter 57/60 - Loss: -1.514\n",
      "Iter 58/60 - Loss: -1.561\n",
      "Iter 59/60 - Loss: -1.611\n",
      "Iter 60/60 - Loss: -1.661\n",
      "\n",
      "data size: 6000\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.093\n",
      "Iter 2/60 - Loss: 1.084\n",
      "Iter 3/60 - Loss: 1.051\n",
      "Iter 4/60 - Loss: 1.018\n",
      "Iter 5/60 - Loss: 0.983\n",
      "Iter 6/60 - Loss: 0.946\n",
      "Iter 7/60 - Loss: 0.909\n",
      "Iter 8/60 - Loss: 0.871\n",
      "Iter 9/60 - Loss: 0.830\n",
      "Iter 10/60 - Loss: 0.791\n",
      "Iter 11/60 - Loss: 0.751\n",
      "Iter 12/60 - Loss: 0.709\n",
      "Iter 13/60 - Loss: 0.667\n",
      "Iter 14/60 - Loss: 0.622\n",
      "Iter 15/60 - Loss: 0.580\n",
      "Iter 16/60 - Loss: 0.535\n",
      "Iter 17/60 - Loss: 0.490\n",
      "Iter 18/60 - Loss: 0.445\n",
      "Iter 19/60 - Loss: 0.399\n",
      "Iter 20/60 - Loss: 0.353\n",
      "Iter 21/60 - Loss: 0.305\n",
      "Iter 22/60 - Loss: 0.257\n",
      "Iter 23/60 - Loss: 0.209\n",
      "Iter 24/60 - Loss: 0.162\n",
      "Iter 25/60 - Loss: 0.113\n",
      "Iter 26/60 - Loss: 0.062\n",
      "Iter 27/60 - Loss: 0.014\n",
      "Iter 28/60 - Loss: -0.036\n",
      "Iter 29/60 - Loss: -0.086\n",
      "Iter 30/60 - Loss: -0.137\n",
      "Iter 31/60 - Loss: -0.187\n",
      "Iter 32/60 - Loss: -0.237\n",
      "Iter 33/60 - Loss: -0.289\n",
      "Iter 34/60 - Loss: -0.339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 35/60 - Loss: -0.391\n",
      "Iter 36/60 - Loss: -0.441\n",
      "Iter 37/60 - Loss: -0.494\n",
      "Iter 38/60 - Loss: -0.545\n",
      "Iter 39/60 - Loss: -0.597\n",
      "Iter 40/60 - Loss: -0.649\n",
      "Iter 41/60 - Loss: -0.700\n",
      "Iter 42/60 - Loss: -0.750\n",
      "Iter 43/60 - Loss: -0.803\n",
      "Iter 44/60 - Loss: -0.855\n",
      "Iter 45/60 - Loss: -0.905\n",
      "Iter 46/60 - Loss: -0.957\n",
      "Iter 47/60 - Loss: -1.009\n",
      "Iter 48/60 - Loss: -1.061\n",
      "Iter 49/60 - Loss: -1.113\n",
      "Iter 50/60 - Loss: -1.164\n",
      "Iter 51/60 - Loss: -1.215\n",
      "Iter 52/60 - Loss: -1.264\n",
      "Iter 53/60 - Loss: -1.316\n",
      "Iter 54/60 - Loss: -1.364\n",
      "Iter 55/60 - Loss: -1.411\n",
      "Iter 56/60 - Loss: -1.461\n",
      "Iter 57/60 - Loss: -1.510\n",
      "Iter 58/60 - Loss: -1.562\n",
      "Iter 59/60 - Loss: -1.614\n",
      "Iter 60/60 - Loss: -1.663\n",
      "\n",
      "data size: 7000\n",
      "Use Cuda: True\n",
      "Iter 1/60 - Loss: 1.092\n",
      "Iter 2/60 - Loss: 1.083\n",
      "Iter 3/60 - Loss: 1.051\n",
      "Iter 4/60 - Loss: 1.017\n",
      "Iter 5/60 - Loss: 0.982\n",
      "Iter 6/60 - Loss: 0.946\n",
      "Iter 7/60 - Loss: 0.908\n",
      "Iter 8/60 - Loss: 0.871\n",
      "Iter 9/60 - Loss: 0.830\n",
      "Iter 10/60 - Loss: 0.791\n",
      "Iter 11/60 - Loss: 0.750\n",
      "Iter 12/60 - Loss: 0.708\n",
      "Iter 13/60 - Loss: 0.666\n",
      "Iter 14/60 - Loss: 0.622\n",
      "Iter 15/60 - Loss: 0.579\n",
      "Iter 16/60 - Loss: 0.534\n",
      "Iter 17/60 - Loss: 0.490\n",
      "Iter 18/60 - Loss: 0.444\n",
      "Iter 19/60 - Loss: 0.398\n",
      "Iter 20/60 - Loss: 0.351\n",
      "Iter 21/60 - Loss: 0.305\n",
      "Iter 22/60 - Loss: 0.257\n",
      "Iter 23/60 - Loss: 0.210\n",
      "Iter 24/60 - Loss: 0.161\n",
      "Iter 25/60 - Loss: 0.113\n",
      "Iter 26/60 - Loss: 0.062\n",
      "Iter 27/60 - Loss: 0.014\n",
      "Iter 28/60 - Loss: -0.037\n",
      "Iter 29/60 - Loss: -0.086\n",
      "Iter 30/60 - Loss: -0.136\n",
      "Iter 31/60 - Loss: -0.187\n",
      "Iter 32/60 - Loss: -0.237\n",
      "Iter 33/60 - Loss: -0.287\n",
      "Iter 34/60 - Loss: -0.339\n",
      "Iter 35/60 - Loss: -0.388\n",
      "Iter 36/60 - Loss: -0.441\n",
      "Iter 37/60 - Loss: -0.491\n",
      "Iter 38/60 - Loss: -0.544\n",
      "Iter 39/60 - Loss: -0.596\n",
      "Iter 40/60 - Loss: -0.647\n",
      "Iter 41/60 - Loss: -0.698\n",
      "Iter 42/60 - Loss: -0.750\n",
      "Iter 43/60 - Loss: -0.801\n",
      "Iter 44/60 - Loss: -0.853\n",
      "Iter 45/60 - Loss: -0.902\n",
      "Iter 46/60 - Loss: -0.955\n",
      "Iter 47/60 - Loss: -1.008\n",
      "Iter 48/60 - Loss: -1.059\n",
      "Iter 49/60 - Loss: -1.111\n",
      "Iter 50/60 - Loss: -1.161\n",
      "Iter 51/60 - Loss: -1.212\n",
      "Iter 52/60 - Loss: -1.263\n",
      "Iter 53/60 - Loss: -1.313\n",
      "Iter 54/60 - Loss: -1.364\n",
      "Iter 55/60 - Loss: -1.415\n",
      "Iter 56/60 - Loss: -1.467\n",
      "Iter 57/60 - Loss: -1.516\n",
      "Iter 58/60 - Loss: -1.565\n",
      "Iter 59/60 - Loss: -1.614\n",
      "Iter 60/60 - Loss: -1.659\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grand/datascience/tiany/python_venv/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:321: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.22459891438484192 which is larger than the tolerance of 0.01 specified by gpytorch.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a gpytorch.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gpu_size_vec = [100,300,500,700,1000,1500,2000,3000,4000,5000,6000,7000]\n",
    "Nval = 4\n",
    "Dval = 4\n",
    "\n",
    "for size in gpu_size_vec:\n",
    "    print(f\"data size: {size}\")\n",
    "    \"\"\"Set up the training and testing data\"\"\"\n",
    "    n = size # input size\n",
    "\n",
    "    x = torch.stack([\n",
    "        torch.linspace(0, 5, n),\n",
    "        torch.linspace(0, 5, n),\n",
    "        torch.linspace(0, 5, n),\n",
    "        torch.linspace(0, 5, n),\n",
    "    ], -1)\n",
    "\n",
    "    \"\"\" \n",
    "    loc=np.array([0, 6, 2, 4])\n",
    "    vec=np.array([0, 5, -2, 10])\n",
    "\n",
    "    vfield = VField(N=Nval, D=Dval, tgt_loc=loc, tgt_vec=vec, polynomial_order=3)\n",
    "    y = vfield(x)\n",
    "    \"\"\"\n",
    "\n",
    "    y = torch.stack([\n",
    "        torch.sin(x[:, 0] * (2 * math.pi)) + torch.randn(n) * 0.02,\n",
    "        torch.cos(x[:, 1] * (2 * math.pi)) + torch.randn(n) * 0.02,\n",
    "        torch.sin(x[:, 2] * (2 * math.pi)) + torch.randn(n) * 0.02,\n",
    "        torch.cos(x[:, 3] * (2 * math.pi)) + torch.randn(n) * 0.02,\n",
    "    ], -1)\n",
    "\n",
    "    train_x = torch.Tensor(x[:int(0.8*n), :])\n",
    "    train_y = y[:int(0.8*n), :]\n",
    "\n",
    "    test_x = torch.Tensor(x[int(0.8*n):, :])\n",
    "\n",
    "    test_y = torch.Tensor(y[int(0.8*n):, :])\n",
    "\n",
    "#     # normalize features\n",
    "#     mean = train_x.mean(dim=-2, keepdim=True)\n",
    "#     std = train_x.std(dim=-2, keepdim=True) # + 1e-6 # prevent dividing by 0\n",
    "#     train_x = (train_x - mean) / std\n",
    "#     test_x = (test_x - mean) / std\n",
    "\n",
    "#     # normalize labels\n",
    "#     mean, std = train_y.mean(),train_y.std()\n",
    "#     train_y = (train_y - mean) / std\n",
    "#     test_y = (test_y - mean) / std\n",
    "\n",
    "#     norm_vec = (vec - mean) / std\n",
    "    \n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=Dval)\n",
    "    model = MultitaskGPModel(train_x, train_y, likelihood, num_base_kernels)\n",
    "    \n",
    "    start_time = time.time() # include the time of copying values onto gpu\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    print(f\"Use Cuda: {use_cuda}\")\n",
    "    if(use_cuda):\n",
    "        train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()\n",
    "        model, likelihood = model.cuda(), likelihood.cuda()\n",
    "    \n",
    "    \"\"\"train the model hyperparameters\"\"\"\n",
    "    import os\n",
    "    smoke_test = ('CI' in os.environ)\n",
    "    training_iterations = 2 if smoke_test else 60\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    with gpytorch.settings.max_cg_iterations(1000):\n",
    "        for i in range(training_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "#           if(i > training_iterations*0.8):\n",
    "            print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "            optimizer.step()\n",
    "    \n",
    "    gpu_training_time.append(time.time() - start_time)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \"\"\" Making predictions with the model\"\"\"\n",
    "    # Set into eval mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Exact predictions\n",
    "    with torch.no_grad(): #, gpytorch.settings.fast_pred_var():\n",
    "        start_time = time.time()\n",
    "        preds = model(test_x) # no noise\n",
    "        covar = preds.covariance_matrix\n",
    "        gpu_exact_meancovar.append(time.time() - start_time)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LOVE without cache\n",
    "        # Clear the cache from the previous computations\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    # Set into eval mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        start_time = time.time()\n",
    "        preds = model(test_x)\n",
    "        fast_covar = preds.covariance_matrix\n",
    "        gpu_love_meancovar.append(time.time() - start_time)\n",
    "    \n",
    "    # LOVE with cache\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        start_time = time.time()\n",
    "        preds = model(test_x)\n",
    "        fast_covar = preds.covariance_matrix\n",
    "        gpu_love_meancovar_cache.append(time.time() - start_time)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1458351612091064, 3.7927017211914062, 3.786275863647461, 6.021966218948364, 6.551958799362183, 7.098454475402832, 7.526453733444214, 8.59511399269104, 9.536357879638672, 11.618726968765259, 13.954174518585205, 15.526504516601562]\n",
      "[0.3653292655944824, 0.6142899990081787, 0.6227104663848877, 0.4550042152404785, 0.7036929130554199, 2.3196699619293213, 5.288795232772827, 16.791099548339844, 53.61664700508118, 126.55413103103638, 219.55472016334534, 551.2603468894958]\n",
      "[0.03246808052062988, 0.38523292541503906, 0.4070422649383545, 0.33737707138061523, 0.34267425537109375, 0.4143664836883545, 0.4390983581542969, 0.6811835765838623, 0.8329904079437256, 1.1819615364074707, 1.6758544445037842, 2.9778125286102295]\n",
      "[0.01569986343383789, 0.03600311279296875, 0.03662705421447754, 0.041841745376586914, 0.039226531982421875, 0.04852437973022461, 0.0659933090209961, 0.1307201385498047, 0.2516911029815674, 0.44244813919067383, 0.7251169681549072, 1.1042866706848145]\n"
     ]
    }
   ],
   "source": [
    "print(gpu_training_time)\n",
    "print(gpu_exact_meancovar)\n",
    "print(gpu_love_meancovar)\n",
    "print(gpu_love_meancovar_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # plot with various axes scales\n",
    "# plt.figure()\n",
    "\n",
    "# CPU vs GPU training\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(cpu_size_vec, cpu_training_time, 'r-', label='cpu training time')\n",
    "plt.plot(gpu_size_vec, gpu_training_time, 'b-', label='gpu training time')\n",
    "plt.ylabel('Time (second)')\n",
    "plt.xlabel('Input Size')\n",
    "plt.title('CPU vs. GPU Training Time')\n",
    "# plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictive Distribution Computation Time\n",
    "\n",
    "# # Initialize plots\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 6), sharey=True)\n",
    "\n",
    "plt.suptitle('Predictive Distribution Computation Time', fontweight='bold')\n",
    "\n",
    "ax1.plot(cpu_size_vec, cpu_exact_meancovar, 'r-', label='cpu exact')\n",
    "ax1.plot(gpu_size_vec, gpu_exact_meancovar, 'b-', label='gpu exact')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "plt.subplot(132)\n",
    "ax2.plot(cpu_size_vec, cpu_love_meancovar, 'g-', label='cpu love no cache')\n",
    "ax2.plot(gpu_size_vec, gpu_love_meancovar, 'c-', label='gpu love no cache')\n",
    "ax2.legend()\n",
    "# plt.ylabel('Time')\n",
    "# plt.xlabel('Input Size')\n",
    "\n",
    "plt.subplot(133)\n",
    "ax3.plot(cpu_size_vec, cpu_love_meancovar_cache, 'y-', label='cpu love with cache')\n",
    "ax3.plot(gpu_size_vec, gpu_love_meancovar_cache, 'm-', label='gpu love with cache')\n",
    "ax3.legend()\n",
    "\n",
    "plt.setp([ax1,ax2,ax3], xlabel='Input Size')\n",
    "plt.setp(ax1, ylabel='Time (Second)')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python_venv",
   "language": "python",
   "name": "python_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
