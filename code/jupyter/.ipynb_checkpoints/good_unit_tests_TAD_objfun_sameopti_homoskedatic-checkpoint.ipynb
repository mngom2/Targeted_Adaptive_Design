{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn  import functional as F\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import sys\n",
    "from decimal import Decimal\n",
    "from IPython.display import clear_output\n",
    "sys.path.append(\"..\")\n",
    "from kernels import vvkernels as vvk, sep_vvkernels as svvk, vvk_rbfkernel as vvk_rbf\n",
    "from means import vvmeans as vvm\n",
    "from likelihood import vvlikelihood as vvll\n",
    "from utils import ObjFun, get_vertices, stopping_criteria\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4513,  1.9878],\n",
      "        [-1.6694,  1.3212],\n",
      "        [-1.5836,  0.4902],\n",
      "        [-1.0389,  1.7766],\n",
      "        [ 1.1892, -2.8302],\n",
      "        [ 2.9415, -2.8469],\n",
      "        [-0.4454,  2.2172],\n",
      "        [ 2.9486, -1.7210],\n",
      "        [ 0.2235,  0.6594],\n",
      "        [-1.8842, -2.3654],\n",
      "        [-1.0029,  1.1089],\n",
      "        [-2.5372,  2.3258],\n",
      "        [ 0.7672, -2.4980],\n",
      "        [-0.0448, -2.5434],\n",
      "        [-1.3798, -1.6206],\n",
      "        [ 2.2574,  1.6800],\n",
      "        [-2.8317,  1.9281],\n",
      "        [ 2.6981, -1.6228],\n",
      "        [ 0.6043,  0.9323],\n",
      "        [-2.5753,  1.5576],\n",
      "        [-0.8845,  1.3193],\n",
      "        [ 0.8409, -1.9919],\n",
      "        [ 1.7046,  2.7775],\n",
      "        [ 1.9538,  0.5244]])\n",
      "tensor([[ 0.0162, -0.0365],\n",
      "        [-0.1664,  0.1093],\n",
      "        [-0.6329,  0.7411],\n",
      "        [ 0.2541, -0.2111],\n",
      "        [-0.0476, -0.0060],\n",
      "        [ 0.1712,  0.0094],\n",
      "        [ 0.4301, -0.3288],\n",
      "        [ 0.2600,  0.0100],\n",
      "        [ 0.1510,  0.1945],\n",
      "        [-0.3607, -0.0109],\n",
      "        [ 0.0335, -0.0341],\n",
      "        [-0.1784,  0.0147],\n",
      "        [-0.1828,  0.0017],\n",
      "        [-0.3066,  0.0120],\n",
      "        [-0.2540,  0.0824],\n",
      "        [ 0.3640,  0.0194],\n",
      "        [-0.2159, -0.0131],\n",
      "        [ 0.2249, -0.0086],\n",
      "        [ 0.3712,  0.1351],\n",
      "        [-0.2094,  0.0029],\n",
      "        [ 0.2885, -0.2473],\n",
      "        [-0.3405,  0.0759],\n",
      "        [ 0.3379, -0.0046],\n",
      "        [ 0.4151, -0.3199]])\n",
      "tensor([0.3380, 0.3502])\n"
     ]
    }
   ],
   "source": [
    "vf = ObjFun()\n",
    "f_target = vf.tgt_vec\n",
    "sample_size = 24\n",
    "D = vf.D\n",
    "N = vf.N\n",
    "\n",
    "vf.low = -3.\n",
    "vf.high = 3.\n",
    "\n",
    "high_minus_low = vf.high- vf.low\n",
    "def g_theta(sample_size, D):\n",
    "    loc = high_minus_low  * np.random.random_sample((sample_size,2)) + vf.low#(np.random.uniform(low=vf.low, high=vf.high, size=(sample_size, D)))\n",
    "    return Tensor(loc)\n",
    "train_x = g_theta(sample_size, D)\n",
    "noise_value= 0.0002 #4 #0.04 #0004 #4\n",
    "def vfield_(x):\n",
    "    x = x.reshape(x.shape[0],D)\n",
    "    out = torch.zeros(x.shape[0], N)\n",
    "    out = vf(x[:,0], x[:,1]) + torch.randn(Tensor(vf(x[:,0], x[:,1])).size()) * math.sqrt(noise_value)\n",
    "    return out #/torch.max(out)\n",
    "\n",
    "train_y = vfield_(train_x)\n",
    "print(train_x)\n",
    "\n",
    "\n",
    "print(train_y)\n",
    "\n",
    "print(f_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective function\n",
    "\n",
    "We sample from $$V_1(x_1, x_2) = 3(1 - x_1)^2 e^{-x_1^2 - (x_2 +1)^2} - 10 (x_1/5 - x_1 ^3 - x_2^5) e^{-x_1^2 - x_2 ^2} - 3 e^{- (x_1 + 2) ^2 - x_2^2} + 0.5(2x_1 + x_2)$$\n",
    "$$V_2(x_1, x_2) = 3(1 +x_2)^2 e^{-x_2^2 - (x_1 +1)^2} - 10 (-x_2/5 + x_2 ^3 + x_1^5) e^{-x_1^2 - x_2 ^2} - 3 e^{- ( 2- x_2) ^2 - x_1^2} + 0.5(2x_1 + x_2)$$\n",
    "\n",
    "where $(x_1, x_2) \\in [-3, 3]^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_x #loc #torch.linspace(0, 1, 10)\n",
    "y_train = train_y #v  #torch.stack([torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,], -1)\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood,num_base_kernels):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        a = torch.ones(2,2)\n",
    "        chol_q = torch.tril(a)\n",
    "        self.mean_module = vvm.TensorProductSubMean(gpytorch.means.LinearMean(2), num_tasks = 2)  #vvm.TensorProductSubMean(gpytorch.means.LinearMean(2), num_tasks = 2)#vvm.TensorProductSubMean(gpytorch.means.ConstantMean(), num_tasks = 2)  # \n",
    "        base_kernels = []\n",
    "        for i in range(num_base_kernels):\n",
    "            base_kernels.append(( gpytorch.kernels.RBFKernel() )) #gpytorch.kernels.PolynomialKernel(4)  ##gpytorch.kernels.MaternKernel()# (vvk_rbf.vvkRBFKernel())\n",
    "#         base_kernels2 = []\n",
    "#         for i in range(num_base_kernels):\n",
    "#             base_kernels2.append(gpytorch.kernels.PolynomialKernel(5))  \n",
    "            \n",
    "        self.covar_module = svvk.SepTensorProductKernel(base_kernels,num_tasks = 2)\n",
    "        #self.covar_module = gpytorch.kernels.LCMKernel(base_kernels,num_tasks = 2)\n",
    "\n",
    "#\\         self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "#             gpytorch.kernels.RBFKernel(), num_tasks=2, rank=1\n",
    "#         )\n",
    "       # self.covar_module = vvk.TensorProductKernel(vvk_rbf.vvkRBFKernel(), a[0,0], a[1,0], a[1,1], num_tasks = 2, rank =1,  task_covar_prior=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ###hyperparameters optimization###\n",
    "def hyper_opti(g_theta1, agg_data, training_iter,num_base_kernels,noise_value, current_model = None, current_likelihood = None):\n",
    "    noises = torch.ones(agg_data.shape[0]) * (noise_value) #  torch.zeros(agg_data.shape[0]) # \n",
    "    noises = noises.reshape(g_theta1.shape[0], 2)\n",
    "    \n",
    "#     if (current_model is not None):\n",
    "#         likelihood = current_likelihood #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises)  #\n",
    "\n",
    "#         model = current_model#.get_fantasy_model(g_theta1, agg_data) #MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "#         model.set_train_data(g_theta1, agg_data,  strict=False)\n",
    "#     else:\n",
    "#         likelihood = vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.TensorProductLikelihood(num_tasks = 2)#vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #\n",
    "#         model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "        \n",
    "    likelihood =  vvll.FixedNoiseMultitaskGaussianLikelihood(noises) #vvll.TensorProductLikelihood(num_tasks = 2) #\n",
    "    model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)    \n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  lr=0.08) #, weight_decay=0.001)  # Includes GaussianLikelihood parameters\n",
    "    #mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    for i in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "        loss, inv_quad = likelihood.get_mll(agg_data,g_theta1, model, likelihood, noise_value)\n",
    "        loss = -loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class design_opti(nn.Module):\n",
    "    def __init__(self, sample, x):\n",
    "        super(design_opti, self).__init__()\n",
    "        #loc = np.random.random_sample((loc_size,2))\n",
    "        self.g_theta2 = nn.Parameter(Tensor(sample))\n",
    "        self.x_design = nn.Parameter(Tensor(x))\n",
    "    def forward(self):\n",
    "       \n",
    "        g_theta2_new = self.g_theta2 #filter_sample(self.g_theta2, 0.009)\n",
    "        \n",
    "        return (g_theta2_new), self.x_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_design_opti(x0,loc_sample, f_target, g_theta1, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new,noise_value):\n",
    "    design = design_opti(loc_sample,x0)\n",
    "    loc_sample0 = loc_sample\n",
    "    \n",
    "    g_theta2, x_d = design.forward()\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss2, pf1, Qf12 = likelihood.get_ell(agg_data,f_target,x_d, g_theta1, g_theta2, model, likelihood, noise_value)\n",
    "        \n",
    "        loss2 = -1. * loss2\n",
    "\n",
    "        loss2.backward()\n",
    "\n",
    "       \n",
    "        return loss2\n",
    "        \n",
    "        \n",
    "        \n",
    "    optimizer = torch.optim.LBFGS(design.parameters(), lr=lr_new, history_size=100, max_iter=100, line_search_fn=\"strong_wolfe\")\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "\n",
    "    g_theta2, x_d = design.forward()\n",
    "    loss2, pf1, Qf12 = likelihood.get_ell(agg_data,f_target,x_d, g_theta1, g_theta2, model, likelihood, noise_value)\n",
    "    loss2 = -1. * loss2\n",
    "    print('Loss design: %.3f' % ( loss2))\n",
    "    #print(x_d)\n",
    "    return x_d, g_theta2, loss2, pf1, Qf12\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -2.927\n",
      "Parameter containing:\n",
      "tensor([[1.2916, 1.5758]], requires_grad=True)\n",
      "Lower bound 0: 0.314751774072647\n",
      "Lower bound 1: -0.060674518346786\n",
      "Upper bound 0: 0.578975796699524\n",
      "Upper bound 1: 0.261780828237534\n",
      "tensor([[0.3280],\n",
      "        [0.3402]])\n",
      "tensor([[0.3480],\n",
      "        [0.3602]])\n",
      "tensor(0.0265)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: 3.840\n",
      "Parameter containing:\n",
      "tensor([[0.9156, 0.5342]], requires_grad=True)\n",
      "Lower bound 0: 0.156167447566986\n",
      "Lower bound 1: -0.018827058374882\n",
      "Upper bound 0: 0.364815056324005\n",
      "Upper bound 1: 0.223566621541977\n",
      "tensor([[0.3280],\n",
      "        [0.3402]])\n",
      "tensor([[0.3480],\n",
      "        [0.3602]])\n",
      "tensor(0.0145)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -6.921\n",
      "Parameter containing:\n",
      "tensor([[0.8768, 0.4680]], requires_grad=True)\n",
      "Lower bound 0: 0.308193147182465\n",
      "Lower bound 1: 0.310519695281982\n",
      "Upper bound 0: 0.342272579669952\n",
      "Upper bound 1: 0.347639918327332\n",
      "tensor([[0.3280],\n",
      "        [0.3402]])\n",
      "tensor([[0.3480],\n",
      "        [0.3602]])\n",
      "tensor(0.4659)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAHWCAYAAABXF6HSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASBUlEQVR4nO3dX4jl91nH8c/TpPFPWlsxa5XsxkTcWpcqtA6xImilVZIImwu1JFC0ErqgRkSrEKlUiTf+FwrRdsVS/2Bj9EIWuhJBUwJiSrZUQ5MSWWNtNtom1poLS5tGHy/mVKfj7s7ZzZmZZ/e8XjBw/nznnIdvhnnv75wzv1R3BwCY60X7PQAAcH5iDQDDiTUADCfWADCcWAPAcGINAMPtGOuqek9VPV1VHznH/VVV76yq01X1SFW9dvVjAsD6WubI+r1JbjrP/TcnObz4Opbkd174WADAF+wY6+5+MMm/n2fJrUn+oDc9lOTlVfW1qxoQANbdKt6zvjbJk1uun1ncBgCswJV7+WRVdSybL5Xn6quv/tZXvepVe/n0ALBvPvShD/1bdx+4mO9dRayfSnJoy/WDi9v+n+4+nuR4kmxsbPSpU6dW8PQAMF9V/fPFfu8qXgY/keSHFp8Kf12SZ7v7X1fwuABAljiyrqr3JXl9kmuq6kySX0jy4iTp7nclOZnkliSnk3wmyY/s1rAAsI52jHV3377D/Z3kx1c2EQDwRZzBDACGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYbqlYV9VNVfV4VZ2uqrvOcv91VfVAVX24qh6pqltWPyoArKcdY11VVyS5J8nNSY4kub2qjmxb9vNJ7uvu1yS5Lclvr3pQAFhXyxxZ35jkdHc/0d3PJbk3ya3b1nSSr1hcflmSf1ndiACw3q5cYs21SZ7ccv1Mkm/btuYXk/xlVf1EkquTvHEl0wEAK/uA2e1J3tvdB5PckuQPq+r/PXZVHauqU1V16plnnlnRUwPA5W2ZWD+V5NCW6wcXt211R5L7kqS7/zbJlya5ZvsDdffx7t7o7o0DBw5c3MQAsGaWifXDSQ5X1Q1VdVU2P0B2Ytuajyd5Q5JU1TdlM9YOnQFgBXaMdXc/n+TOJPcn+Wg2P/X9aFXdXVVHF8veluStVfX3Sd6X5C3d3bs1NACsk2U+YJbuPpnk5Lbb3rHl8mNJvmO1owEAiTOYAcB4Yg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDLRXrqrqpqh6vqtNVddc51rypqh6rqker6o9XOyYArK8rd1pQVVckuSfJ9yQ5k+ThqjrR3Y9tWXM4yc8l+Y7u/nRVffVuDQwA62aZI+sbk5zu7ie6+7kk9ya5dduatya5p7s/nSTd/fRqxwSA9bVMrK9N8uSW62cWt231yiSvrKq/qaqHquqmVQ0IAOtux5fBL+BxDid5fZKDSR6sqm/u7v/YuqiqjiU5liTXXXfdip4aAC5vyxxZP5Xk0JbrBxe3bXUmyYnu/nx3/1OSf8hmvL9Idx/v7o3u3jhw4MDFzgwAa2WZWD+c5HBV3VBVVyW5LcmJbWv+PJtH1amqa7L5svgTK5wTANbWjrHu7ueT3Jnk/iQfTXJfdz9aVXdX1dHFsvuTfKqqHkvyQJKf7e5P7dbQALBOqrv35Yk3Njb61KlT+/LcALDXqupD3b1xMd/rDGYAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBLxbqqbqqqx6vqdFXddZ51319VXVUbqxsRANbbjrGuqiuS3JPk5iRHktxeVUfOsu6lSX4yyQdXPSQArLNljqxvTHK6u5/o7ueS3Jvk1rOs+6Ukv5LksyucDwDW3jKxvjbJk1uun1nc9r+q6rVJDnX3+1c4GwCQFXzArKpelOQ3k7xtibXHqupUVZ165plnXuhTA8BaWCbWTyU5tOX6wcVtX/DSJK9O8oGq+liS1yU5cbYPmXX38e7e6O6NAwcOXPzUALBGlon1w0kOV9UNVXVVktuSnPjCnd39bHdf093Xd/f1SR5KcrS7T+3KxACwZnaMdXc/n+TOJPcn+WiS+7r70aq6u6qO7vaAALDurlxmUXefTHJy223vOMfa17/wsQCAL3AGMwAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIZb6n/kAVN9za9/TT75n58875pXXP2KfOJnPrFHEwGsniNrLmk7hXrZNQCTiTUADCfWADCcWAPAcGINAMP5NDijXX/X+8+/4Mv2Zg6A/eTIGgCGE2sAGE6suaS9qF++45pXXP2KPZgEYPd4z5pL2qHP/tE57/vYL3/fHk4CsHscWQPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADOfc4Izm/N4AjqwBYDyxBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGWyrWVXVTVT1eVaer6q6z3P/TVfVYVT1SVX9VVV+3+lEBYD3tGOuquiLJPUluTnIkye1VdWTbsg8n2ejub0nyZ0l+ddWDAsC6WubI+sYkp7v7ie5+Lsm9SW7duqC7H+juzyyuPpTk4GrHBID1tUysr03y5JbrZxa3ncsdSf7ihQwFAPyfK1f5YFX15iQbSb7rHPcfS3IsSa677rpVPjUAXLaWObJ+KsmhLdcPLm77IlX1xiRvT3K0uz93tgfq7uPdvdHdGwcOHLiYeQFg7SwT64eTHK6qG6rqqiS3JTmxdUFVvSbJu7MZ6qdXPyYArK8dY93dzye5M8n9ST6a5L7ufrSq7q6qo4tlv5bkJUn+tKr+rqpOnOPhAIALtNR71t19MsnJbbe9Y8vlN654LgBgwRnMAGA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhlop1Vd1UVY9X1emquuss939JVf3J4v4PVtX1qx4UANbVjrGuqiuS3JPk5iRHktxeVUe2Lbsjyae7+xuS/FaSX1n1oACwrpY5sr4xyenufqK7n0tyb5Jbt625NcnvLy7/WZI3VFWtbkwAWF/LxPraJE9uuX5mcdtZ13T380meTfJVqxgQANbdlXv5ZFV1LMmxxdXPVdVH9vL519A1Sf5tv4dYA/Z599nj3WePd983Xuw3LhPrp5Ic2nL94OK2s605U1VXJnlZkk9tf6DuPp7keJJU1anu3riYoVmOPd4b9nn32ePdZ493X1WdutjvXeZl8IeTHK6qG6rqqiS3JTmxbc2JJD+8uPwDSf66u/tihwIA/s+OR9bd/XxV3Znk/iRXJHlPdz9aVXcnOdXdJ5L8XpI/rKrTSf49m0EHAFZgqfesu/tkkpPbbnvHlsufTfKDF/jcxy9wPRfOHu8N+7z77PHus8e776L3uLxaDQCzOd0oAAy367F2qtLdt8Qe/3RVPVZVj1TVX1XV1+3HnJeynfZ4y7rvr6quKp+qvQjL7HNVvWnx8/xoVf3xXs94qVvi98V1VfVAVX148Tvjlv2Y81JWVe+pqqfP9efJtemdi/8Gj1TVa3d80O7eta9sfiDtH5N8fZKrkvx9kiPb1vxYknctLt+W5E92c6bL7WvJPf7uJF++uPyj9nj1e7xY99IkDyZ5KMnGfs99qX0t+bN8OMmHk3zl4vpX7/fcl9LXknt8PMmPLi4fSfKx/Z77UvtK8p1JXpvkI+e4/5Ykf5GkkrwuyQd3eszdPrJ2qtLdt+Med/cD3f2ZxdWHsvm38ixvmZ/jJPmlbJ4X/7N7OdxlZJl9fmuSe7r700nS3U/v8YyXumX2uJN8xeLyy5L8yx7Od1no7gez+ZdR53Jrkj/oTQ8leXlVfe35HnO3Y+1UpbtvmT3e6o5s/ouO5e24x4uXsQ519/v3crDLzDI/y69M8sqq+puqeqiqbtqz6S4Py+zxLyZ5c1WdyeZfAf3E3oy2Vi709/benm6U/VVVb06ykeS79nuWy0lVvSjJbyZ5yz6Psg6uzOZL4a/P5itED1bVN3f3f+zrVJeX25O8t7t/o6q+PZvn0Hh1d//3fg+2znb7yPpCTlWa852qlHNaZo9TVW9M8vYkR7v7c3s02+Vipz1+aZJXJ/lAVX0sm+9BnfAhswu2zM/ymSQnuvvz3f1PSf4hm/FmOcvs8R1J7kuS7v7bJF+azfOGszpL/d7eardj7VSlu2/HPa6q1yR5dzZD7T2+C3fePe7uZ7v7mu6+vruvz+bnAo5290WfB3hNLfP74s+zeVSdqrommy+LP7GXQ17iltnjjyd5Q5JU1TdlM9bP7OmUl78TSX5o8anw1yV5trv/9XzfsKsvg7dTle66Jff415K8JMmfLj679/HuPrpvQ19iltxjXqAl9/n+JN9bVY8l+a8kP9vdXolb0pJ7/LYkv1tVP5XND5u9xQHUhamq92XzH5XXLN77/4UkL06S7n5XNj8LcEuS00k+k+RHdnxM/w0AYDZnMAOA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFguP8BbRDEUyS9FScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -9.003\n",
      "Parameter containing:\n",
      "tensor([[0.8655, 0.5009]], requires_grad=True)\n",
      "Lower bound 0: 0.332356214523315\n",
      "Lower bound 1: 0.342088788747787\n",
      "Upper bound 0: 0.352775633335114\n",
      "Upper bound 1: 0.363158792257309\n",
      "tensor([[0.3280],\n",
      "        [0.3402]])\n",
      "tensor([[0.3480],\n",
      "        [0.3602]])\n",
      "tensor(0.0004)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -9.492\n",
      "Parameter containing:\n",
      "tensor([[0.8662, 0.5117]], requires_grad=True)\n",
      "Lower bound 0: 0.332772850990295\n",
      "Lower bound 1: 0.343581646680832\n",
      "Upper bound 0: 0.348939836025238\n",
      "Upper bound 1: 0.360037356615067\n",
      "tensor([[0.3280],\n",
      "        [0.3402]])\n",
      "tensor([[0.3480],\n",
      "        [0.3602]])\n",
      "tensor(0.6819)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -9.853\n",
      "Parameter containing:\n",
      "tensor([[0.8780, 0.4973]], requires_grad=True)\n",
      "Lower bound 0: 0.329589784145355\n",
      "Lower bound 1: 0.341877222061157\n",
      "Upper bound 0: 0.343879997730255\n",
      "Upper bound 1: 0.356170058250427\n",
      "tensor([[0.3280],\n",
      "        [0.3402]])\n",
      "tensor([[0.3480],\n",
      "        [0.3602]])\n",
      "tensor(0.0012)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"bool\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vd/tt7x9mbn35b5wxq8_t6p0mt80000gn/T/ipykernel_43011/3260271034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Success is '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSUCCESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"bool\") to str"
     ]
    }
   ],
   "source": [
    "iter_hp = 50\n",
    "iter_design = 40 \n",
    "iter_param = 50\n",
    "num_base_kernels = 5\n",
    "max_iter = 50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_target = f_target.reshape(2,1) \n",
    "tol_vector = 0.01 * torch.ones(f_target.shape)\n",
    "\n",
    "plot_freq = 1\n",
    "\n",
    "loc_size = 4\n",
    "loc_sample = high_minus_low  * np.random.random_sample((loc_size,2)) + vf.low #np.random.random_sample((loc_size,2))\n",
    "loc_sample = Tensor(loc_sample)\n",
    "\n",
    "\n",
    "\n",
    "g_theta2_vec = (Tensor(loc_sample).clone()).flatten()\n",
    "\n",
    "g_theta1 = x_train\n",
    "agg_data = y_train.flatten()\n",
    "\n",
    "\n",
    "x0 = Tensor(np.array([0.0,0.0])) \n",
    "x0 = x0.reshape(1,2)\n",
    "vec_x = Tensor(np.array([0.0,0.0])) \n",
    "vec_x = vec_x.reshape(1,2)\n",
    "var_vec = torch.zeros([max_iter, 1])\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    "iter = 0 \n",
    "\n",
    "while(SUCCESS == False and FAILURE == False):\n",
    "    print(iter)\n",
    "    print('START HYPERPARAMETERS optimization')\n",
    "    if (iter == 0):\n",
    "        cur_model = None\n",
    "        cur_likelihood = None\n",
    "    \n",
    "        \n",
    "        \n",
    "    model, likelihood = hyper_opti(g_theta1,agg_data,iter_hp,num_base_kernels,noise_value, current_model = cur_model, current_likelihood = cur_likelihood)\n",
    "\n",
    "    print('END HYPERPARAMETERS optimization')\n",
    "    \n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    #with gpytorch.settings.fast_pred_var():\n",
    "    #print(g_theta1)\n",
    "    x0_new,g_theta2, loss, pf1, Qf12 = conduct_design_opti(x0, loc_sample, f_target, g_theta1, agg_data, model, likelihood, iter_design,iter_param, lr_new,noise_value)\n",
    "    \n",
    "    cur_model = model\n",
    "    cur_likelihood = likelihood\n",
    "    \n",
    "    tol_drop = 0.009 #* var\n",
    "    \n",
    "    #var_vec[iter] = var\n",
    "        \n",
    "    g_theta2_vec = torch.cat([g_theta2_vec, g_theta2.detach().flatten()], 0)\n",
    "    g_theta2_vec = torch.cat([g_theta2_vec, x0_new.flatten()], 0)\n",
    "    \n",
    "    print(( x0_new))\n",
    "    loc_sample = Tensor(high_minus_low  * np.random.random_sample((loc_size,2)) + vf.low) #np.random.random_sample((loc_size,2))\n",
    "    \n",
    "    vec_x = torch.cat([vec_x, x0_new.detach()])\n",
    "    \n",
    "    new_data = vfield_(g_theta2.detach())  \n",
    "    agg_data12 = torch.cat([agg_data, new_data.flatten()], 0)\n",
    "    g_theta12= torch.cat([g_theta1, g_theta2.detach()], 0)\n",
    "    new_data_x = vfield_(x0_new.detach() )    \n",
    "    agg_data = torch.cat([agg_data12, new_data_x.flatten()], 0)\n",
    "    g_theta1= torch.cat([g_theta12, x0_new.detach()], 0)\n",
    "\n",
    "#initialize target candidate\n",
    "    x0 = Tensor(np.array([0.0,0.0])) \n",
    "    x0 = x0.reshape(1,2)\n",
    "    \n",
    "    lower_bound = torch.zeros(pf1.shape)\n",
    "    upper_bound = torch.zeros(pf1.shape)\n",
    "        \n",
    "    for i in range(pf1.shape[0]):\n",
    "        lower_bound[i] = pf1[i] -  torch.sqrt(Qf12[i,i])\n",
    "        upper_bound[i] = pf1[i] +  torch.sqrt(Qf12[i,i])\n",
    "\n",
    "    iter = iter + 1\n",
    "\n",
    "    print('Lower bound 0: %.15f'% (lower_bound[0]))\n",
    "    print('Lower bound 1: %.15f'% (lower_bound[1]))\n",
    "    print('Upper bound 0: %.15f'% (upper_bound[0]))\n",
    "    print('Upper bound 1: %.15f'% (upper_bound[1]))\n",
    "    print(f_target-tol_vector)\n",
    "    print(f_target+tol_vector)\n",
    "\n",
    "    SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "    #var_vec_out = var_vec.detach()[0:iter - 1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        v1,v2,v3,v4 = get_vertices(pf1,Qf12[0,0], Qf12[1,1])\n",
    "        data_2 = new_data.flatten()\n",
    "        p_value_ftgt_v1 = likelihood.get_inv_quad(Qf12, v1, g_theta12, agg_data12,x0_new.detach() , model, noise_value) #gpytorch.inv_quad(Qf12, f_target, x0_new.detach(),noise_value ) #\n",
    "        p_value_ftgt_v2 = likelihood.get_inv_quad(Qf12, v2,g_theta12, agg_data12,x0_new.detach() , model, noise_value)\n",
    "        p_value_ftgt_v3 = likelihood.get_inv_quad(Qf12, v3,  g_theta12, agg_data12, x0_new.detach() , model, noise_value)\n",
    "        p_value_ftgt_v4 = likelihood.get_inv_quad(Qf12, v4,  g_theta12, agg_data12,x0_new.detach() , model, noise_value)\n",
    "        p_value_ftgt = torch.min(Tensor([p_value_ftgt_v1, p_value_ftgt_v2, p_value_ftgt_v3, p_value_ftgt_v4]))\n",
    "        print(p_value_ftgt)\n",
    "        if (p_value_ftgt > 13.816):\n",
    "            FAILURE = True\n",
    "            \n",
    "        f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        width = 2 * torch.sqrt(Qf12[0,0])\n",
    "        height = 2 * torch.sqrt(Qf12[1,1])\n",
    "        ax.add_patch(patches.Rectangle((pf1[0]-torch.sqrt(Qf12[0,0]) , pf1[1] - torch.sqrt(Qf12[1,1])), width, height))\n",
    "        # Plot predictive means as blue line\n",
    "        width = 2 * 0.01\n",
    "        height = 2 * 0.01\n",
    "        #print(f_target[0])\n",
    "        ax.add_patch(patches.Rectangle((f_target[0] - 0.01, f_target[1] - 0.01), width, height, color = 'g'))\n",
    "        plt.show()\n",
    "        #clear_output(wait=False)\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "print('Success is ' + str(SUCCESS) + ' and failure is' + str(FAILURE))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3404, 0.3476]], grad_fn=<CatBackward0>)\n",
      "tensor([[0.8779, 0.5555]], grad_fn=<ReshapeAliasBackward0>)\n",
      "(tensor([[-0.2176, -0.3914]]), tensor([[0.8068, 0.7181]]))\n",
      "tensor([[0.2946, 0.1633]])\n"
     ]
    }
   ],
   "source": [
    "#x0 = Tensor(np.array([0.1937, 0.1257]))\n",
    "#x0 = Tensor(np.array([0.1885, 0.1038]))\n",
    "\n",
    "x0 = x0_new #Tensor(np.array([0.8734, 0.5585]))\n",
    "#x0_new = Tensor(np.array([0.8731, 0.5664]))\n",
    "x0 = x0_new.reshape(1,2)\n",
    "\n",
    "print(vf(x0[:,0], x0[:,1]))\n",
    "x0 = x0.reshape(1,2)\n",
    "print(x0)\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "# for param in model.named_parameters():\n",
    "#         print(param)\n",
    "noises = torch.ones(x0.shape) * (noise_value) \n",
    "with torch.no_grad():\n",
    "\n",
    "    pr = model(x0) #likelihood(model(x0), noise = noises) #\n",
    "    print(pr.confidence_region())\n",
    "    print(pr.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(SUCCESS)\n",
    "print(FAILURE)\n",
    "print(iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [-0.3224, -0.7576],\n",
      "        [ 0.0825, -0.4873],\n",
      "        [ 0.8606,  0.5409],\n",
      "        [ 0.8450,  0.6167],\n",
      "        [ 0.8284,  0.6588],\n",
      "        [ 0.9541,  0.5070],\n",
      "        [ 0.8779,  0.5555]])\n",
      "tensor([[-1.4513,  1.9878],\n",
      "        [-1.6694,  1.3212],\n",
      "        [-1.5836,  0.4902],\n",
      "        [-1.0389,  1.7766],\n",
      "        [ 1.1892, -2.8302],\n",
      "        [ 2.9415, -2.8469],\n",
      "        [-0.4454,  2.2172],\n",
      "        [ 2.9486, -1.7210],\n",
      "        [ 0.2235,  0.6594],\n",
      "        [-1.8842, -2.3654],\n",
      "        [-1.0029,  1.1089],\n",
      "        [-2.5372,  2.3258],\n",
      "        [ 0.7672, -2.4980],\n",
      "        [-0.0448, -2.5434],\n",
      "        [-1.3798, -1.6206],\n",
      "        [ 2.2574,  1.6800],\n",
      "        [-2.8317,  1.9281],\n",
      "        [ 2.6981, -1.6228],\n",
      "        [ 0.6043,  0.9323],\n",
      "        [-2.5753,  1.5576],\n",
      "        [-0.8845,  1.3193],\n",
      "        [ 0.8409, -1.9919],\n",
      "        [ 1.7046,  2.7775],\n",
      "        [ 1.9538,  0.5244],\n",
      "        [ 2.1801,  6.1314],\n",
      "        [-0.5207,  2.1079],\n",
      "        [ 2.5289, -3.2173],\n",
      "        [-0.8573, -2.1382],\n",
      "        [-0.3224, -0.7576],\n",
      "        [-0.3817,  0.1374],\n",
      "        [-2.5406,  0.6180],\n",
      "        [ 1.5641,  2.8321],\n",
      "        [ 1.8704,  1.0389],\n",
      "        [ 0.0825, -0.4873],\n",
      "        [ 0.9731, -2.0906],\n",
      "        [-2.7374,  1.9040],\n",
      "        [-2.6626, -0.6580],\n",
      "        [ 1.6700,  1.4742],\n",
      "        [ 0.8606,  0.5409],\n",
      "        [ 2.3886, -1.3942],\n",
      "        [ 2.9589,  1.1612],\n",
      "        [ 0.8333,  1.2104],\n",
      "        [ 2.1641,  2.5233],\n",
      "        [ 0.8450,  0.6167],\n",
      "        [ 2.1872,  2.3487],\n",
      "        [-2.4388,  1.4809],\n",
      "        [ 2.9401, -1.8367],\n",
      "        [ 1.4038,  1.6444],\n",
      "        [ 0.8284,  0.6588],\n",
      "        [-1.5233,  1.3555],\n",
      "        [-2.6997,  2.1274],\n",
      "        [ 0.1746, -1.0314],\n",
      "        [-1.8883, -2.2827],\n",
      "        [ 0.9541,  0.5070],\n",
      "        [-1.4277, -0.2348],\n",
      "        [-1.1659, -1.7424],\n",
      "        [-1.1660, -1.3987],\n",
      "        [-2.1065, -1.1376],\n",
      "        [ 0.8779,  0.5555]])\n"
     ]
    }
   ],
   "source": [
    "v2 = g_theta2_vec.reshape((iter)*(loc_size+1) + loc_size,2)\n",
    "print(iter)\n",
    "print(vec_x)\n",
    "print(g_theta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class design_opti_pll(nn.Module):\n",
    "    def __init__(self, x):\n",
    "        super(design_opti_pll, self).__init__()\n",
    "        #loc = np.random.random_sample((loc_size,2))\n",
    "        #self.g_theta2 = nn.Parameter(Tensor(sample))\n",
    "        self.x_design = nn.Parameter(Tensor(x))\n",
    "    def forward(self):\n",
    "       \n",
    "        #g_theta2_new = self.g_theta2 #filter_sample(self.g_theta2, 0.009)\n",
    "        \n",
    "        return self.x_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_design_pll(x0,f_target, g_theta, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new):\n",
    "    design = design_opti_pll(x0)\n",
    "    loc_sample0 = loc_sample\n",
    "    x_d = design.forward()\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss2,lower_bound, upper_bound = likelihood.get_pll(f_target,x_d, g_theta, agg_data, model, likelihood)\n",
    "        #loss2 = -1. * loss2\n",
    "        loss2.backward(retain_graph=True)\n",
    "#         print(x_d)\n",
    "#         print(lower_bound)\n",
    "#         print(upper_bound)\n",
    "       \n",
    "        return loss2\n",
    "        \n",
    "        \n",
    "        \n",
    "    optimizer = torch.optim.LBFGS(design.parameters(), lr=lr_new, history_size=100, max_iter=100, line_search_fn=\"strong_wolfe\")\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    x_d = design.forward()\n",
    "    loss2,lower_bound, upper_bound = likelihood.get_pll(f_target,x_d, g_theta, agg_data, model, likelihood)\n",
    "    #loss2 = -1. * loss2\n",
    "    print('Loss design: %.3f' % ( loss2))\n",
    "   # print(optimizer.state_dict())\n",
    "    print(x_d)\n",
    "    return x_d, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([112])\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -0.288\n",
      "Parameter containing:\n",
      "tensor([[ 0.6223, -0.2324]], requires_grad=True)\n",
      "tensor([[ 0.0898],\n",
      "        [-0.1103]], grad_fn=<CopySlices>)\n",
      "tensor([[0.3892],\n",
      "        [0.1769]], grad_fn=<CopySlices>)\n",
      "tensor([[0.3280],\n",
      "        [0.3402]])\n",
      "tensor([[0.3480],\n",
      "        [0.3602]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable bool object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vd/tt7x9mbn35b5wxq8_t6p0mt80000gn/T/ipykernel_43011/915769523.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mSUCCESS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAILURE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopping_criteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtol_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable bool object"
     ]
    }
   ],
   "source": [
    "# iter_hp = 30\n",
    "# iter_design = 40 \n",
    "# iter_param = 50\n",
    "# num_base_kernels = 3\n",
    "\n",
    "# f_target = Tensor(vf.tgt_vec) \n",
    "# f_target = f_target.reshape(f_target.shape[0],1) \n",
    "# tol_vector = 0.005 * torch.ones(f_target.shape)\n",
    "\n",
    "\n",
    "loc_size_rdn = (iter + 1)*loc_size + sample_size\n",
    "\n",
    "loc_sample = high_minus_low  * np.random.random_sample((loc_size_rdn,2)) + vf.low #np.random.random_sample((loc_size_rdn,2))\n",
    "g_theta_ = (Tensor(loc_sample).clone())\n",
    "agg_data1 = vfield_(g_theta_)\n",
    "agg_data1 = agg_data1.flatten()\n",
    "print(agg_data1.shape)\n",
    "\n",
    "x0 = Tensor(np.array([0.0,0.0])) \n",
    "x0 = x0.reshape(1,2)\n",
    "x00 = x0 \n",
    "vec_x_rdn = Tensor(np.array([0.,0.])) \n",
    "vec_x_rdn = vec_x_rdn.reshape(1,2)\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    " \n",
    "tol = 0.009 \n",
    "print('START HYPERPARAMETERS optimization')\n",
    "model_rdn, likelihood_rdn = hyper_opti(g_theta_,agg_data1,iter_hp,num_base_kernels,noise_value)\n",
    "\n",
    "print('END HYPERPARAMETERS optimization')\n",
    "\n",
    "x0_new,lower_bound, upper_bound = conduct_design_pll(x0,f_target, g_theta_, agg_data1, model_rdn, likelihood_rdn, iter_design, iter_param, lr_new)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target-tol_vector)\n",
    "print(f_target+tol_vector)\n",
    "loc_sample = np.random.random_sample((loc_size_rdn,2))\n",
    "\n",
    "\n",
    "SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(x0_new)\n",
    "print(SUCCESS)\n",
    "sol_rdn = x0_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAD Plots and Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we vizualize the target function, namely, the contours of the coordinates of the outputs and its norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=16)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=15)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=15)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=15)    # legend fontsize\n",
    "plt.rc('font', size=15)          # controls default text sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_target = Tensor(vf.tgt_vec) \n",
    "f_target = f_target.reshape(f_target.shape[0],1)\n",
    "vf.tgt_loc = vf.tgt_loc.reshape(2,1)\n",
    "x_plot = np.linspace(vf.low, vf.high, 30)\n",
    "y_plot = np.linspace(vf.low, vf.high, 30)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat = torch.zeros(n * n, 2)\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "out_plot = vfield_(x_concat)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize = (8, 18),  tight_layout=True)\n",
    "v_1 = out_plot[:,0].reshape(n,n)\n",
    "v_2 = out_plot[:,1].reshape(n,n)\n",
    "v = np.sqrt(v_1**2 + v_2**2)\n",
    "print(torch.max(v))\n",
    "\n",
    "#pos = ax1.imshow(v_1, cmap='RdGy', interpolation='none')\n",
    "\n",
    "cs1 = ax1.contourf(xv_plot, yv_plot,v_1, np.linspace(v_1.min(), v_1.max(), 100),cmap='jet')\n",
    "ax1.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "#cs11 = ax1.contour(xv_plot, yv_plot, v_1,np.linspace(v_1.min(), v_1.max(), 30),colors='w')\n",
    "ax1.set_title('$v_1$')\n",
    "ax1.set_xlabel('$x_1$')\n",
    "ax1.set_ylabel('$x_2$')\n",
    "cs2 = ax2.contourf(xv_plot, yv_plot, v_2, np.linspace(v_2.min(), v_2.max(), 100),cmap='jet')\n",
    "ax2.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax2.set_xlabel('$x_1$')\n",
    "ax2.set_ylabel('$x_2$')\n",
    "#cs21 = ax2.contour(xv_plot, yv_plot, v_2,colors='w')\n",
    "ax2.set_title('$v_2$')\n",
    "#ax2.set_aspect('equal')\n",
    "sns.scatterplot(x=out_plot[:,0], y=out_plot[:,1], s=5, color=\".15\", ax = ax3)    #cs3 = ax3.contourf(xv_plot, yv_plot, v,np.linspace(v.min(), v.max(), 100),cmap='jet')\n",
    "sns.histplot(x=out_plot[:,0], y=out_plot[:,1], bins=50, pthresh=.1, cmap=\"mako\", ax = ax3)\n",
    "sns.kdeplot(x=out_plot[:,0], y=out_plot[:,1], levels=5, color=\"w\", linewidths=1, ax = ax3)\n",
    "\n",
    "#ax3.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax3.set_xlabel('$x_1$')\n",
    "ax3.set_ylabel('$x_2$')\n",
    "#cs31 = ax3.contour(xv_plot, yv_plot, v, np.linspace(v.min(), v.max(), 30),colors='w')\n",
    "ax3.set_title('$scatter+hist$')\n",
    "#ax3.set_aspect('equal')\n",
    "cbar1 = fig.colorbar(cs1, ax = ax1);\n",
    "#cbar1.add_lines(cs11)\n",
    "\n",
    "cbar2 = fig.colorbar(cs2, ax = ax2);\n",
    "#cbar2.add_lines(cs21)\n",
    "\n",
    "#cbar3 = fig.colorbar(cs3, ax = ax3);\n",
    "#cbar3.add_lines(cs31)\n",
    "# ax01 = fig.add_subplot(3, 2, 2, projection='3d')\n",
    "# ax02 = fig.add_subplot(3, 2, 4, projection='3d')\n",
    "# ax03 = fig.add_subplot(3, 2, 6, projection='3d')\n",
    "\n",
    "# ax01.plot3D(x_concat[:,0], x_concat[:,1], out_plot[:,0])\n",
    "\n",
    "# ax02.plot3D(x_concat[:,0], x_concat[:,1], out_plot[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# ax03.plot3D(x_concat[:,0], x_concat[:,1], np.sqrt( (out_plot[:,1])**2 + (out_plot[:,0])**2))\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('figures/target_fun.png')\n",
    "# cs = plt.contourf(v_1, levels=[10, 30, 50],\n",
    "#     colors=['#808080', '#A0A0A0', '#C0C0C0'], extend='both')\n",
    "# cs.cmap.set_over('red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loc_size_rdn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_size = 4\n",
    "i,j=0,0\n",
    "low = -3.1\n",
    "high = 3.1\n",
    "PLOTS_PER_ROW = 2\n",
    "widths = 16* np.ones((PLOTS_PER_ROW))\n",
    "heights = 16 * np.ones((math.ceil((iter + 1)/PLOTS_PER_ROW)))\n",
    "#print(heights)\n",
    "gs_kw = dict(width_ratios=widths, height_ratios=heights)\n",
    "#fig, ax = plt.subplots(math.ceil((iter + 1)/PLOTS_PER_ROW),PLOTS_PER_ROW, constrained_layout=True,\n",
    "#                             gridspec_kw=gs_kw)\n",
    "fig, axs = plt.subplots(math.ceil((iter+1)/PLOTS_PER_ROW),PLOTS_PER_ROW, figsize=(14, 28),  tight_layout=True)\n",
    "ii = 0\n",
    "# vec_x = Tensor([[0.5000, 0.7000],\n",
    "#         [0.1427, 0.2234],\n",
    "#         [0.1859, 0.1796],\n",
    "#         [0.2023, 0.0953],\n",
    "#         [0.1999, 0.0963],\n",
    "#         [0.2003, 0.0998]])\n",
    "col = 0\n",
    "\n",
    "vec_x = vec_x.detach()\n",
    "axs[i][j].plot(0.8731, 0.5664,'gs',markersize=12)\n",
    "axs[i][j].plot(vec_x[col,0], vec_x[col,1],'rD',markersize=12)\n",
    "axs[i][j].plot(x_train.detach()[:,0], x_train.detach()[:,1], 'bv', markersize=12)\n",
    "axs[i][j].plot(v2.detach()[ii:ii+loc_size,0], v2.detach()[ii:ii+loc_size,1], 'yv', markersize=12)\n",
    "axs[i][j].set_xlabel('$x_1$')\n",
    "axs[i][j].set_ylabel('$x_2$')\n",
    "axs[i][j].set_title('initial config')\n",
    "\n",
    "#axs[i][j].set_aspect('equal')\n",
    "if (ii > 0):\n",
    "    axs[i][j].plot(v2.detach()[(ii-loc_size):ii,0], v2.detach()[ii-loc_size:ii,1], 'yv', markersize=12)\n",
    "axs[i][j].set_xlim(low, high)\n",
    "axs[i][j].set_ylim(low, high)\n",
    "ii = ii+loc_size+1\n",
    "j+=1\n",
    "\n",
    "loc_size = loc_size\n",
    "for col in range(1, iter+1):\n",
    "    axs[i][j].plot(0.8731, 0.5664,'gs',markersize=12)\n",
    "    axs[i][j].plot(vec_x[col,0], vec_x[col,1],'rD',markersize=12)\n",
    "    axs[i][j].plot(v2.detach()[ii:ii+loc_size,0], v2.detach()[ii:ii+loc_size,1], 'bv', markersize=12)\n",
    "  #  axs[i][j].set_aspect('equal')\n",
    "    if (ii > loc_size):\n",
    "        axs[i][j].plot(v2.detach()[(ii-loc_size):ii,0], v2.detach()[ii-loc_size:ii,1], 'yv', markersize=12)\n",
    "    axs[i][j].set_xlim(low, high)\n",
    "    axs[i][j].set_ylim(low, high)\n",
    "    axs[i][j].set_xlabel('$x_1$')\n",
    "    axs[i][j].set_ylabel('$x_2$')\n",
    "    axs[i][j].set_title('stage %s' % col)\n",
    "    ii = ii+loc_size+1\n",
    "    j+=1\n",
    "    \n",
    "    if j%PLOTS_PER_ROW==0:\n",
    "        i+=1\n",
    "        j=0\n",
    "plt.show()\n",
    "plt.savefig('figures/evol_sol.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x0 = Tensor(np.array([0.1937, 0.1257]))\n",
    "#x0 = Tensor(np.array([0.1885, 0.1038]))\n",
    "x_plot = np.linspace(vf.low, vf.high, 30)\n",
    "y_plot = np.linspace(vf.low, vf.high, 30)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat_ = torch.zeros(n * n, 2)\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "with torch.no_grad():\n",
    "    pr = model(x_concat_) #likelihood(model(x_concat_), noise = torch.ones(x_concat_.shape) * noise_value)# \n",
    "\n",
    "    mean_v_1 = pr.mean[:,0].reshape(n,n)\n",
    "    mean_v_2 = pr.mean[:,1].reshape(n,n)\n",
    "\n",
    "\n",
    "    var_v_1 = pr.variance[:,0].reshape(n,n)\n",
    "    var_v_2 = pr.variance[:,1].reshape(n,n)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 2, figsize = (20, 16), tight_layout=True)\n",
    "cs10 = ax1[0].contourf(xv_plot, yv_plot, mean_v_1.detach(),np.linspace(mean_v_1.detach().min(), mean_v_1.detach().max(), 100), cmap = 'jet')\n",
    "ax1[0].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax1[0].set_title('$\\mu(v_1)$', fontsize = 18)\n",
    "cbar10 = fig.colorbar(cs10, ax = ax1[0]);\n",
    "\n",
    "ax1[0].set_xlabel('$x_1$', fontsize = 16)\n",
    "ax1[0].set_ylabel('$x_2$', fontsize = 16)\n",
    "\n",
    "cs11 = ax1[1].contourf(xv_plot, yv_plot, var_v_1.detach(), np.linspace(var_v_1.detach().min(), var_v_1.detach().max(), 100), cmap = 'jet')\n",
    "ax1[1].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax1[1].set_title('$\\sigma^2(v_1)$', fontsize = 18)\n",
    "# ax1[0].set_aspect('equal')\n",
    "# ax1[1].set_aspect('equal')\n",
    "cbar11 = fig.colorbar(cs11, ax = ax1[1]);\n",
    "ax1[1].set_xlabel('$x_1$', fontsize = 16)\n",
    "ax1[1].set_ylabel('$x_2$', fontsize = 16)\n",
    "\n",
    "\n",
    "cs20 = ax2[0].contourf(xv_plot, yv_plot, mean_v_2.detach(),np.linspace(mean_v_2.detach().min(), mean_v_2.detach().max(), 100), cmap = 'jet')\n",
    "ax2[0].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax2[0].set_title('$\\mu(v_2)$', fontsize = 18)\n",
    "cbar20 = fig.colorbar(cs20, ax = ax2[0]);\n",
    "ax2[0].set_xlabel('$x_1$', fontsize = 16)\n",
    "ax2[0].set_ylabel('$x_2$', fontsize = 16)\n",
    "\n",
    "\n",
    "\n",
    "cs21 = ax2[1].contourf(xv_plot, yv_plot, var_v_2.detach(), np.linspace(var_v_2.detach().min(), var_v_2.detach().max(), 100), cmap = 'jet')\n",
    "ax2[1].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax2[1].set_title('$\\sigma^2(v_2)$', fontsize = 18)\n",
    "cbar21 = fig.colorbar(cs21, ax = ax2[1]);\n",
    "ax2[1].set_xlabel('$x_1$', fontsize = 16)\n",
    "ax2[1].set_ylabel('$x_2$', fontsize = 16)\n",
    "\n",
    "\n",
    "# ax2[0].set_aspect('equal')\n",
    "# ax2[1].set_aspect('equal')\n",
    "\n",
    "plt.savefig('figures/mean_var.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_size= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(vf.low, vf.high, 15)\n",
    "y_plot = np.linspace(vf.low, vf.high, 15)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat = torch.zeros(n * n, 2)\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "\n",
    "g_theta_grid = x_concat\n",
    "agg_data1_grid = vfield_(g_theta_grid)\n",
    "agg_data1_grid = agg_data1_grid.flatten()\n",
    "\n",
    "\n",
    "x0 = Tensor(np.array([0.0,0.0])) \n",
    "x0 = x0.reshape(1,2)\n",
    "x00 = x0 \n",
    "vec_x_grid = Tensor(np.array([0.0,0.0])) \n",
    "vec_x_grid = vec_x_grid.reshape(1,2)\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    " \n",
    "tol = 0.009 \n",
    "print('START HYPERPARAMETERS optimization')\n",
    "model_grid, likelihood_grid = hyper_opti(g_theta_grid,agg_data1_grid,iter_hp,num_base_kernels,noise_value)\n",
    "\n",
    "print('END HYPERPARAMETERS optimization')\n",
    "\n",
    "x0_new,lower_bound, upper_bound = conduct_design_pll(x0,f_target, g_theta_grid, agg_data1_grid, model_grid, likelihood_grid, iter_design, iter_param, lr_new)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target-tol_vector)\n",
    "print(f_target+tol_vector)\n",
    "#loc_sample = np.random.random_sample((loc_size_rdn,2))\n",
    "\n",
    "\n",
    "SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(x0_new)\n",
    "print(SUCCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.plot(x_concat[:,0],x_concat[:,1], 'bv',markersize=10)\n",
    "ax.plot(x0_new.detach()[0,0], x0_new.detach()[0,1],'gD',markersize=12)\n",
    "ax.plot(0.8731, 0.5664,'rs',markersize=12)\n",
    "plt.savefig('figures/grid_sol.eps')\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.plot(g_theta_[:,0].detach(),g_theta_[:,1].detach(), 'mv',markersize=10)\n",
    "ax.plot(sol_rdn.detach()[0,0], sol_rdn.detach()[0,1],'gD',markersize=12)\n",
    "ax.plot(0.8731, 0.5664,'rs',markersize=12)\n",
    "plt.savefig('figures/rdn_sol.eps')\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'yv',markersize=10)\n",
    "ax.plot(vec_x[iter,0], vec_x[iter,1],'rs',markersize=12)\n",
    "ax.plot(0.8731, 0.5664,'gD',markersize=12)\n",
    "\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "plt.savefig('figures/tad_sol_allpoints.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# likelihood.eval()\n",
    "# with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#     test_x = Tensor(np.random.random_sample((50,2)))\n",
    "#     predictions = likelihood(model(test_x))\n",
    "#     mean = predictions.mean\n",
    "#     lower, upper = predictions.confidence_region()\n",
    "\n",
    "# plt.plot(mean, 'bo')\n",
    "# plt.plot(vfield_(test_x), 'r+')\n",
    "# plt.plot(upper, 'gx')\n",
    "# plt.plot(lower, 'mx')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "#     if iter % plot_freq == 0:\n",
    "#         sns.set_theme(style=\"dark\")\n",
    "#         print('*****************ENTERING MODEL PRED ON 2 SAMPLE CHECKING + uncertainty**************')\n",
    "#         with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#             sample_size = 10\n",
    "#             noises = torch.ones(new_data.shape[0]) * (noise_value) \n",
    "#             predictions = likelihood(model(g_theta2.detach()))\n",
    "#             xv_plot = g_theta2.detach()[:,0]\n",
    "#             yv_plot = g_theta2.detach()[:,1]\n",
    "# #             mean = predictions.mean\n",
    "# #             lower, upper = predictions.confidence_region()\n",
    "\n",
    "#             mean_v_1 = predictions.mean[:,0]\n",
    "#             mean_v_2 = predictions.mean[:,1]\n",
    "#             true_value = vfield_(g_theta2.detach())\n",
    "            \n",
    "# #             print(mean_v_1)\n",
    "# #             print(mean_v_2)\n",
    "            \n",
    "# #             print(vfield_(g_theta2.detach()).t())\n",
    "\n",
    "#             var_v_1 = predictions.variance[:,0]\n",
    "#             var_v_2 = predictions.variance[:,1]\n",
    "#             print('variances')\n",
    "#             print(var_v_1)\n",
    "#             print(var_v_2)\n",
    "            \n",
    "            \n",
    "#             inv_quad = likelihood.get_inv_quad(Q21, new_data.flatten(),g_theta2.detach(),model,noise_value)\n",
    "#             print('chi square value')\n",
    "#             print(inv_quad)\n",
    "            \n",
    "#             f, (ax, ax3) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "#             # Get upper and lower confidence bounds\n",
    "#             lower, upper = predictions.confidence_region()\n",
    "         \n",
    "#             ax.plot(true_value[:,0], 'k*')\n",
    "#             # Plot predictive means as blue line\n",
    "#             ax.plot(mean_v_1, 'bo')\n",
    "#             ax.plot(upper[:,0], 'gx-')\n",
    "#             ax.plot(lower[:,0], 'mx-')\n",
    "#             #ax.fill_between((g_theta2.detach())[:,0], lower.numpy()[:,0], upper.numpy()[:,0], alpha=0.5)\n",
    "#             #ax.set_ylim([-3, 3])\n",
    "#             ax.legend(['True value', 'Mean', 'Upper Confidence', 'lower Confidence'])\n",
    "            \n",
    "            \n",
    "#             ax3.plot(true_value[:,1], 'k*')\n",
    "#             # Plot predictive means as blue line\n",
    "#             ax3.plot(mean_v_2, 'bo')\n",
    "#             ax3.plot(upper[:,1], 'gx-')\n",
    "#             ax3.plot(lower[:,1], 'mx-')\n",
    "#             #ax.fill_between((g_theta2.detach())[:,0], lower.numpy()[:,0], upper.numpy()[:,0], alpha=0.5)\n",
    "#             #ax.set_ylim([-3, 3])\n",
    "#             ax3.legend(['True value', 'Mean', 'Upper Confidence', 'lower Confidence'])\n",
    "            \n",
    "# #             print('check')\n",
    "# #             sample = likelihood(model(g_theta1.detach())).rsample(torch.Size([sample_size]))\n",
    "# #             print('check')\n",
    "# #             x = sample[:,:,0].reshape(g_theta1.shape[0] * sample_size)\n",
    "# #             y = sample[:,:,1].reshape(g_theta1.shape[0] * sample_size)\n",
    "# #             x = x.detach()\n",
    "# #             y = y.detach()\n",
    "# #             #print(x.shape)\n",
    "# #             sns.scatterplot(x=x, y=y, s=5, color=\".15\", ax = ax3)    #cs3 = ax3.contourf(xv_plot, yv_plot, v,np.linspace(v.min(), v.max(), 100),cmap='jet')\n",
    "# #             sns.histplot(x=x, y=y, bins=50, pthresh=.1, cmap=\"mako\", ax = ax3)\n",
    "# #             sns.kdeplot(x=x, y=y, levels=5, color=\"w\", linewidths=1, ax = ax3)\n",
    "#             plt.show()\n",
    "#         print('*****************LEAVING MODEL PRED ON 2 SAMPLE CHECKING + uncertainty**************')\n",
    "            #clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hyper_opti(g_theta1, agg_data, training_iter,num_base_kernels,noise_value, current_model = None, current_likelihood = None):\n",
    "  \n",
    "#     noises = torch.ones(agg_data.shape[0]) * (noise_value) #  torch.zeros(agg_data.shape[0]) # \n",
    "\n",
    "    \n",
    "#    # ii = 0\n",
    "# #     if (current_model is not None):\n",
    "# #         likelihood = current_likelihood #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises)  #\n",
    "\n",
    "# #         model = current_model#.get_fantasy_model(g_theta1, agg_data) #MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "# #         model.set_train_data(g_theta1, agg_data,  strict=False)\n",
    "# #     else:\n",
    "# #         likelihood = vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.TensorProductLikelihood(num_tasks = 2)#vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #\n",
    "# #         model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "        \n",
    "#     likelihood =  vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.TensorProductLikelihood(num_tasks = 2) #\n",
    "#     model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)    \n",
    "#     model.train()\n",
    "#     likelihood.train()\n",
    "#     optimizer = FullBatchLBFGS(model.parameters(), lr = 1.)\n",
    "#     #mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "#     def closure():\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         #output = model(g_theta1)\n",
    "# #         output_ll = likelihood(output)\n",
    "\n",
    "#         loss, inv_quad = likelihood.get_mll(agg_data,g_theta1, model, likelihood, noise_value)\n",
    "#         loss = -loss\n",
    "#         #loss = -mll(output, agg_data)\n",
    "#         print('Loss gp: %.3f' % ( loss))\n",
    "#         #print('inv_quad: %.3f' % ( inv_quad))\n",
    "        \n",
    "#         return loss\n",
    "    \n",
    "#     loss = closure()\n",
    "#     loss.backward()\n",
    "\n",
    "#     for i in range(training_iter):\n",
    "      \n",
    "#         options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\n",
    "#         loss, _, _,_, _, _, _, fail = optimizer.step(options)\n",
    "\n",
    "#         if fail:\n",
    "#             print('Convergence reached!')\n",
    "#             break\n",
    "#         #print(i)\n",
    "#     return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = torch.ones(10) * (noise_value)\n",
    "print(noises.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     K = model.covar_module\n",
    "#     mu = model.mean_module\n",
    "#     x = x0_new.detach()\n",
    "#     cov_noise1 = noise_value * torch.eye(agg_data.shape[0])\n",
    "#     Cff = K.forward(x,x) #+ cov_noisex\n",
    "\n",
    "#     Cf1 = K.forward(x,g_theta1)\n",
    "\n",
    "#     C11 = K.forward(g_theta1, g_theta1) + cov_noise1\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "   \n",
    "#     mean_data = mu.forward(g_theta1)\n",
    "    \n",
    "#     mean_data = torch.flatten(mean_data)    \n",
    "#     rhs_g1 =  agg_data  - mean_data #.reshape(mean_data.shape, 1) #g-S #+ noise1_vec #+ 0.005 * torch.ones(agg_data.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "#     mean_x = mu.forward(x)\n",
    "      \n",
    "#     mean_x = torch.flatten(mean_x)  #mean_x.reshape(mean_x.shape[0] * mean_x.shape[1], 1)\n",
    "        \n",
    "#     pf1 = mean_x.reshape(mean_x.shape, 1) + C11.inv_matmul(rhs_g1, Cf1.evaluate())\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "       \n",
    "#         #Q21 = Q21.add_jitter(1e-8)\n",
    "\n",
    "        \n",
    "#     C1f = Cf1.t()\n",
    "#     Qf1 = (Cff - C11.inv_matmul(C1f.evaluate(), Cf1.evaluate())) #\n",
    "    \n",
    "#     lower_bound = torch.zeros(pf1.shape)\n",
    "#     upper_bound = torch.zeros(pf1.shape)\n",
    "       \n",
    "#     for i in range(pf1.shape[0]):\n",
    "#         lower_bound[i] = pf1[i] - torch.sqrt(Qf1[i,i])\n",
    "#         upper_bound[i] = pf1[i] + torch.sqrt(Qf1[i,i])\n",
    "    \n",
    "#     print('Lower bound 0: %.15f'% (lower_bound[0]))\n",
    "#     print('Lower bound 1: %.15f'% (lower_bound[1]))\n",
    "#     print('Upper bound 0: %.15f'% (upper_bound[0]))\n",
    "#     print('Upper bound 1: %.15f'% (upper_bound[1]))\n",
    "#     print(f_target-tol_vector)\n",
    "#     print(f_target+tol_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hyper_opti(g_theta1, agg_data, training_iter,num_base_kernels,noise_value, current_model = None, current_likelihood = None):\n",
    "  \n",
    "#     noises = torch.ones(agg_data.shape[0]) * (noise_value) #  torch.zeros(agg_data.shape[0]) # \n",
    "\n",
    "    \n",
    "#    # ii = 0\n",
    "# #     if (current_model is not None):\n",
    "# #         likelihood = current_likelihood #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises)  #\n",
    "\n",
    "# #         model = current_model#.get_fantasy_model(g_theta1, agg_data) #MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "# #         model.set_train_data(g_theta1, agg_data,  strict=False)\n",
    "# #     else:\n",
    "# #         likelihood = vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.TensorProductLikelihood(num_tasks = 2)#vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #\n",
    "# #         model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "        \n",
    "#     likelihood =  vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.TensorProductLikelihood(num_tasks = 2) #\n",
    "#     model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)    \n",
    "#     model.train()\n",
    "#     likelihood.train()\n",
    "#     optimizer = FullBatchLBFGS(model.parameters(), lr = 1.)\n",
    "#     #mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "#     def closure():\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         #output = model(g_theta1)\n",
    "# #         output_ll = likelihood(output)\n",
    "\n",
    "#         loss, inv_quad = likelihood.get_mll(agg_data,g_theta1, model, likelihood, noise_value)\n",
    "#         loss = -loss\n",
    "#         #loss = -mll(output, agg_data)\n",
    "#         print('Loss gp: %.3f' % ( loss))\n",
    "#         #print('inv_quad: %.3f' % ( inv_quad))\n",
    "        \n",
    "#         return loss\n",
    "    \n",
    "#     loss = closure()\n",
    "#     loss.backward()\n",
    "\n",
    "#     for i in range(training_iter):\n",
    "      \n",
    "#         options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\n",
    "#         loss, _, _,_, _, _, _, fail = optimizer.step(options)\n",
    "\n",
    "#         if fail:\n",
    "#             print('Convergence reached!')\n",
    "#             break\n",
    "#         #print(i)\n",
    "#     return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(0, 1, 100)\n",
    "\n",
    "train_y = torch.stack([\n",
    "    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\n",
    "    torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,\n",
    "], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
