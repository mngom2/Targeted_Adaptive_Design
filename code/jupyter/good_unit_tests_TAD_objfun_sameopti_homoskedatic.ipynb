{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn  import functional as F\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import sys\n",
    "from decimal import Decimal\n",
    "from IPython.display import clear_output\n",
    "sys.path.append(\"..\")\n",
    "from kernels import vvkernels as vvk, sep_vvkernels as svvk, vvk_rbfkernel as vvk_rbf\n",
    "from means import vvmeans as vvm\n",
    "from likelihood import vvlikelihood as vvll\n",
    "from mlikelihoods import MarginalLogLikelihood as exmll\n",
    "from predstrategies import GPprediction\n",
    "from utils import ObjFun, get_vertices, stopping_criteria\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective function\n",
    "\n",
    "We sample from $$V_1(x_1, x_2) = 3(1 - x_1)^2 e^{-x_1^2 - (x_2 +1)^2} - 10 (x_1/5 - x_1 ^3 - x_2^5) e^{-x_1^2 - x_2 ^2} - 3 e^{- (x_1 + 2) ^2 - x_2^2} + 0.5(2x_1 + x_2)$$\n",
    "$$V_2(x_1, x_2) = 3(1 +x_2)^2 e^{-x_2^2 - (x_1 +1)^2} - 10 (-x_2/5 + x_2 ^3 + x_1^5) e^{-x_1^2 - x_2 ^2} - 3 e^{- ( 2- x_2) ^2 - x_1^2} + 0.5(2x_1 + x_2)$$\n",
    "\n",
    "where $(x_1, x_2) \\in [-3, 3]^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = ObjFun()\n",
    "f_target = vf.tgt_vec\n",
    "sample_size = 24\n",
    "D = vf.D\n",
    "N = vf.N\n",
    "\n",
    "vf.low = -3.\n",
    "vf.high = 3.\n",
    "\n",
    "high_minus_low = vf.high- vf.low\n",
    "def g_theta(sample_size, D):\n",
    "    loc = high_minus_low  * np.random.random_sample((sample_size,2)) + vf.low#(np.random.uniform(low=vf.low, high=vf.high, size=(sample_size, D)))\n",
    "    return Tensor(loc)\n",
    "train_x = g_theta(sample_size, D)\n",
    "noise_value = 0.0002 #noise_free = 0.\n",
    "def vfield_(x):\n",
    "    x = x.reshape(x.shape[0],D)\n",
    "    out = torch.zeros(x.shape[0], N)\n",
    "    out = vf(x[:,0], x[:,1]) + torch.randn(Tensor(vf(x[:,0], x[:,1])).size()) * math.sqrt(noise_value)\n",
    "    return out #/torch.max(out)\n",
    "\n",
    "train_y = vfield_(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP model initialization\n",
    "We inialize the GP model following https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_x #loc #torch.linspace(0, 1, 10)\n",
    "y_train = train_y #v  #torch.stack([torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,], -1)\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood,num_base_kernels):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        a = torch.ones(2,2)\n",
    "        chol_q = torch.tril(a)\n",
    "        self.mean_module = vvm.TensorProductSubMean(gpytorch.means.LinearMean(2), num_tasks = 2)  #vvm.TensorProductSubMean(gpytorch.means.LinearMean(2), num_tasks = 2)#vvm.TensorProductSubMean(gpytorch.means.ConstantMean(), num_tasks = 2)  # \n",
    "        base_kernels = []\n",
    "        for i in range(num_base_kernels):\n",
    "            base_kernels.append(( gpytorch.kernels.RBFKernel() )) #gpytorch.kernels.PolynomialKernel(4)  ##gpytorch.kernels.MaternKernel()# (vvk_rbf.vvkRBFKernel())\n",
    "#         base_kernels2 = []\n",
    "#         for i in range(num_base_kernels):\n",
    "#             base_kernels2.append(gpytorch.kernels.PolynomialKernel(5))  \n",
    "            \n",
    "        self.covar_module = svvk.SepTensorProductKernel(base_kernels,num_tasks = 2)\n",
    "        #self.covar_module = gpytorch.kernels.LCMKernel(base_kernels,num_tasks = 2)\n",
    "\n",
    "#\\         self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "#             gpytorch.kernels.RBFKernel(), num_tasks=2, rank=1\n",
    "#         )\n",
    "       # self.covar_module = vvk.TensorProductKernel(vvk_rbf.vvkRBFKernel(), a[0,0], a[1,0], a[1,1], num_tasks = 2, rank =1,  task_covar_prior=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamaters oprimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ###hyperparameters optimization###\n",
    "def hyper_opti(g_theta1, agg_data, training_iter,num_base_kernels,noise_value, current_model = None, current_likelihood = None):\n",
    "    noises = torch.ones(agg_data.shape[0]) * (noise_value) #  torch.zeros(agg_data.shape[0]) # \n",
    "    noises = noises.reshape(g_theta1.shape[0], 2)\n",
    "    \n",
    "#     if (current_model is not None):\n",
    "#         likelihood = current_likelihood #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises)  #\n",
    "\n",
    "#         model = current_model#.get_fantasy_model(g_theta1, agg_data) #MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "#         model.set_train_data(g_theta1, agg_data,  strict=False)\n",
    "#     else:\n",
    "#         likelihood = vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.TensorProductLikelihood(num_tasks = 2)#vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #\n",
    "#         model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "        \n",
    "    likelihood =  vvll.FixedNoiseMultitaskGaussianLikelihood(noises) #vvll.TensorProductLikelihood(num_tasks = 2) #\n",
    "    model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "    model.double()\n",
    "    likelihood.double()\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  lr=0.08) #, weight_decay=0.001)  # Includes GaussianLikelihood parameters\n",
    "    mll = exmll(likelihood, model)\n",
    "    #mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    for i in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "#         loss, inv_quad = likelihood.get_mll(agg_data,g_theta1, model, likelihood, noise_value)\n",
    "#         loss = -loss\n",
    "      #  output = model(g_theta1)\n",
    " #   Calc loss and backprop gradients\n",
    "        #loss = -mll(output, agg_data)\n",
    "        loss = -mll(agg_data,g_theta1, model, likelihood, noise_value)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design parameters and sampling point optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class design_opti(nn.Module):\n",
    "    def __init__(self, sample, x):\n",
    "        super(design_opti, self).__init__()\n",
    "        #loc = np.random.random_sample((loc_size,2))\n",
    "        self.g_theta2 = nn.Parameter(Tensor(sample))\n",
    "        self.x_design = nn.Parameter(Tensor(x))\n",
    "    def forward(self):\n",
    "       \n",
    "        g_theta2_new = self.g_theta2 #filter_sample(self.g_theta2, 0.009)\n",
    "        \n",
    "        return (g_theta2_new), self.x_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_design_opti(x0,loc_sample, f_target, g_theta1, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new,noise_value):\n",
    "    design = design_opti(loc_sample,x0)\n",
    "    loc_sample0 = loc_sample\n",
    "    \n",
    "    g_theta2, x_d = design.forward()\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss2, pf1, Qf1, Qf12 = likelihood.get_ell(agg_data,f_target,x_d, g_theta1, g_theta2, model, likelihood, noise_value)\n",
    "        \n",
    "        loss2 = -1. * loss2\n",
    "\n",
    "        loss2.backward()\n",
    "\n",
    "       \n",
    "        return loss2\n",
    "        \n",
    "        \n",
    "        \n",
    "    optimizer = torch.optim.LBFGS(design.parameters(), lr=lr_new, history_size=100, max_iter=100, line_search_fn=\"strong_wolfe\")\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "\n",
    "    g_theta2, x_d = design.forward()\n",
    "    loss2, pf1, Qf1, Qf12 = likelihood.get_ell(agg_data,f_target,x_d, g_theta1, g_theta2, model, likelihood, noise_value)\n",
    "    loss2 = -1. * loss2\n",
    "    print('Loss design: %.3f' % ( loss2))\n",
    "    #print(x_d)\n",
    "    return x_d, g_theta2, loss2, pf1, Qf1, Qf12\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conducting the TAD experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -6.548\n",
      "Parameter containing:\n",
      "tensor([[0.8398, 0.6926]], requires_grad=True)\n",
      "smallest chi_square value is tensor(0.0003)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "1\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -7.566\n",
      "Parameter containing:\n",
      "tensor([[0.8457, 0.6859]], requires_grad=True)\n",
      "smallest chi_square value is tensor(6.8490e-05)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "2\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -6.723\n",
      "Parameter containing:\n",
      "tensor([[0.8787, 0.6746]], requires_grad=True)\n",
      "smallest chi_square value is tensor(0.0002)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "3\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -7.621\n",
      "Parameter containing:\n",
      "tensor([[0.8695, 0.6619]], requires_grad=True)\n",
      "smallest chi_square value is tensor(0.0001)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -6.608\n",
      "Parameter containing:\n",
      "tensor([[0.8836, 0.6320]], requires_grad=True)\n",
      "smallest chi_square value is tensor(0.0002)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "5\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -6.297\n",
      "Parameter containing:\n",
      "tensor([[0.8531, 0.6286]], requires_grad=True)\n",
      "smallest chi_square value is tensor(9.9718e-05)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "6\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n",
      "Loss design: -7.931\n",
      "Parameter containing:\n",
      "tensor([[0.8683, 0.6042]], requires_grad=True)\n",
      "smallest chi_square value is tensor(4.9653e-06)\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "7\n",
      "START HYPERPARAMETERS optimization\n",
      "END HYPERPARAMETERS optimization\n"
     ]
    }
   ],
   "source": [
    "iter_hp = 75\n",
    "iter_design = 40 \n",
    "iter_param = 50\n",
    "num_base_kernels = 5\n",
    "max_iter = 50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_target = f_target.reshape(2,1) \n",
    "tol_vector = 0.01 * torch.ones(f_target.shape)\n",
    "\n",
    "plot_freq = 1\n",
    "\n",
    "loc_size = 4\n",
    "loc_sample = high_minus_low  * np.random.random_sample((loc_size,2)) + vf.low #np.random.random_sample((loc_size,2))\n",
    "loc_sample = Tensor(loc_sample)\n",
    "\n",
    "\n",
    "\n",
    "g_theta2_vec = (Tensor(loc_sample).clone()).flatten()\n",
    "\n",
    "g_theta1 = x_train\n",
    "agg_data = y_train.flatten()\n",
    "\n",
    "\n",
    "x0 = Tensor(np.array([0.0,0.0])) \n",
    "x0 = x0.reshape(1,2)\n",
    "vec_x = Tensor(np.array([0.0,0.0])) \n",
    "vec_x = vec_x.reshape(1,2)\n",
    "var_vec = torch.zeros([max_iter, 1])\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    "show_TTRBox = False\n",
    "iter = 0 \n",
    "\n",
    "while(SUCCESS == False and FAILURE == False):\n",
    "    print(iter)\n",
    "    print('START HYPERPARAMETERS optimization')\n",
    "    if (iter == 0):\n",
    "        cur_model = None\n",
    "        cur_likelihood = None\n",
    "    \n",
    "    \n",
    "        \n",
    "    model, likelihood = hyper_opti(g_theta1,agg_data,iter_hp,num_base_kernels,noise_value, current_model = cur_model, current_likelihood = cur_likelihood)\n",
    "\n",
    "    \n",
    "    print('END HYPERPARAMETERS optimization')\n",
    "    \n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "#     with torch.no_grad():\n",
    "#         pr = model(g_theta1.detach()) #likelihood(model(x0), noise = noises) #model(x0) #\n",
    "#         print('var')\n",
    "#         print(pr.variance)\n",
    "#         print('end var')\n",
    "    #with gpytorch.settings.fast_pred_var():\n",
    "    #print(g_theta1)\n",
    "    x0_new,g_theta2, loss, pf1, Qf1, Qf12 = conduct_design_opti(x0, loc_sample, f_target, g_theta1, agg_data, model, likelihood, iter_design,iter_param, lr_new,noise_value)\n",
    "    \n",
    "    cur_model = model\n",
    "    cur_likelihood = likelihood\n",
    "    \n",
    "    tol_drop = 0.009 #* var\n",
    "    lower_bound = torch.zeros(pf1.shape)\n",
    "    upper_bound = torch.zeros(pf1.shape)\n",
    "        \n",
    "    for i in range(pf1.shape[0]):\n",
    "        lower_bound[i] = pf1[i] -  torch.sqrt(Qf1[i,i])\n",
    "        upper_bound[i] = pf1[i] +  torch.sqrt(Qf1[i,i])\n",
    "        \n",
    "    SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "    vec_x = torch.cat([vec_x, x0_new.detach()])\n",
    "    \n",
    "    if not SUCCESS:\n",
    "    \n",
    "    #var_vec[iter] = var\n",
    "        \n",
    "        g_theta2_vec = torch.cat([g_theta2_vec, g_theta2.detach().flatten()], 0)\n",
    "        g_theta2_vec = torch.cat([g_theta2_vec, x0_new.flatten()], 0)\n",
    "\n",
    "        print(( x0_new))\n",
    "        loc_sample = Tensor(high_minus_low  * np.random.random_sample((loc_size,2)) + vf.low) #np.random.random_sample((loc_size,2))\n",
    "\n",
    "        \n",
    "\n",
    "        new_data = vfield_(g_theta2.detach())  \n",
    "        agg_data12 = torch.cat([agg_data, new_data.flatten()], 0)\n",
    "        g_theta12= torch.cat([g_theta1, g_theta2.detach()], 0)\n",
    "        new_data_x = vfield_(x0_new.detach() )    \n",
    "        agg_data = torch.cat([agg_data12, new_data_x.flatten()], 0)\n",
    "        g_theta1= torch.cat([g_theta12, x0_new.detach()], 0)\n",
    "\n",
    "    #initialize target candidate\n",
    "        x0 = Tensor(np.array([0.0,0.0])) \n",
    "        x0 = x0.reshape(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     print('Lower bound 0: %.15f'% (lower_bound[0]))\n",
    "    #     print('Lower bound 1: %.15f'% (lower_bound[1]))\n",
    "    #     print('Upper bound 0: %.15f'% (upper_bound[0]))\n",
    "    #     print('Upper bound 1: %.15f'% (upper_bound[1]))\n",
    "    #     print(f_target-tol_vector)\n",
    "    #     print(f_target+tol_vector)\n",
    "\n",
    "\n",
    "\n",
    "        #var_vec_out = var_vec.detach()[0:iter - 1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            v1,v2,v3,v4 = get_vertices(pf1,Qf12[0,0], Qf12[1,1])\n",
    "            data_2 = new_data.flatten()\n",
    "            p_value_ftgt_v1 = likelihood.get_inv_quad(Qf12, v1, g_theta12, agg_data12,x0_new.detach() , model, noise_value) #gpytorch.inv_quad(Qf12, f_target, x0_new.detach(),noise_value ) #\n",
    "            p_value_ftgt_v2 = likelihood.get_inv_quad(Qf12, v2,g_theta12, agg_data12,x0_new.detach() , model, noise_value)\n",
    "            p_value_ftgt_v3 = likelihood.get_inv_quad(Qf12, v3,  g_theta12, agg_data12, x0_new.detach() , model, noise_value)\n",
    "            p_value_ftgt_v4 = likelihood.get_inv_quad(Qf12, v4,  g_theta12, agg_data12,x0_new.detach() , model, noise_value)\n",
    "            p_value_ftgt = torch.min(Tensor([p_value_ftgt_v1, p_value_ftgt_v2, p_value_ftgt_v3, p_value_ftgt_v4]))\n",
    "            print('smallest chi_square value is '+str(p_value_ftgt))\n",
    "            if (p_value_ftgt > 13.816):\n",
    "                FAILURE = True\n",
    "            if (show_TTRBox == True):\n",
    "                f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "                width = 2 * torch.sqrt(Qf12[0,0])\n",
    "                height = 2 * torch.sqrt(Qf12[1,1])\n",
    "                ax.add_patch(patches.Rectangle((pf1[0]-torch.sqrt(Qf12[0,0]) , pf1[1] - torch.sqrt(Qf12[1,1])), width, height))\n",
    "                # Plot predictive means as blue line\n",
    "                width = 2 * 0.01\n",
    "                height = 2 * 0.01\n",
    "                #print(f_target[0])\n",
    "                ax.add_patch(patches.Rectangle((f_target[0] - 0.01, f_target[1] - 0.01), width, height, color = 'g'))\n",
    "                plt.show()\n",
    "            #clear_output(wait=False)\n",
    "\n",
    "        print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "        iter = iter + 1\n",
    "\n",
    "    \n",
    "print('Success is ' + str(SUCCESS) + ' and failure is ' + str(FAILURE)+' after '+ str(iter) + ' iterations')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = g_theta2_vec.reshape((iter)*(loc_size+1) + loc_size,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class design_opti_pll(nn.Module):\n",
    "    def __init__(self, x):\n",
    "        super(design_opti_pll, self).__init__()\n",
    "        #loc = np.random.random_sample((loc_size,2))\n",
    "        #self.g_theta2 = nn.Parameter(Tensor(sample))\n",
    "        self.x_design = nn.Parameter(Tensor(x))\n",
    "    def forward(self):\n",
    "       \n",
    "        #g_theta2_new = self.g_theta2 #filter_sample(self.g_theta2, 0.009)\n",
    "        \n",
    "        return self.x_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_design_pll(x0,f_target, g_theta, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new,noise_value):\n",
    "    design = design_opti_pll(x0)\n",
    "    loc_sample0 = loc_sample\n",
    "    x_d = design.forward()\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss2,lower_bound, upper_bound = likelihood.get_pll(f_target,x_d, g_theta, agg_data, model, likelihood, noise_value)\n",
    "        #loss2 = -1. * loss2\n",
    "        loss2.backward(retain_graph=True)\n",
    "#         print(x_d)\n",
    "#         print(lower_bound)\n",
    "#         print(upper_bound)\n",
    "       \n",
    "        return loss2\n",
    "        \n",
    "        \n",
    "        \n",
    "    optimizer = torch.optim.LBFGS(design.parameters(), lr=lr_new, history_size=100, max_iter=100, line_search_fn=\"strong_wolfe\")\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    x_d = design.forward()\n",
    "    loss2,lower_bound, upper_bound = likelihood.get_pll(f_target,x_d, g_theta, agg_data, model, likelihood ,noise_value)\n",
    "    #loss2 = -1. * loss2\n",
    "    print('Loss design: %.3f' % ( loss2))\n",
    "   # print(optimizer.state_dict())\n",
    "    print(x_d)\n",
    "    return x_d, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_hp = 30\n",
    "# iter_design = 40 \n",
    "# iter_param = 50\n",
    "# num_base_kernels = 3\n",
    "\n",
    "# f_target = Tensor(vf.tgt_vec) \n",
    "# f_target = f_target.reshape(f_target.shape[0],1) \n",
    "# tol_vector = 0.005 * torch.ones(f_target.shape)\n",
    "\n",
    "\n",
    "loc_size_rdn = (iter + 1)*loc_size + sample_size\n",
    "\n",
    "loc_sample = high_minus_low  * np.random.random_sample((loc_size_rdn,2)) + vf.low #np.random.random_sample((loc_size_rdn,2))\n",
    "g_theta_ = (Tensor(loc_sample).clone())\n",
    "agg_data1 = vfield_(g_theta_)\n",
    "agg_data1 = agg_data1.flatten()\n",
    "print(agg_data1.shape)\n",
    "\n",
    "x0 = Tensor(np.array([0.0,0.0])) \n",
    "x0 = x0.reshape(1,2)\n",
    "x00 = x0 \n",
    "vec_x_rdn = Tensor(np.array([0.,0.])) \n",
    "vec_x_rdn = vec_x_rdn.reshape(1,2)\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    " \n",
    "tol = 0.009 \n",
    "print('START HYPERPARAMETERS optimization')\n",
    "\n",
    "model_rdn, likelihood_rdn = hyper_opti(g_theta_,agg_data1,iter_hp,num_base_kernels,noise_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('END HYPERPARAMETERS optimization')\n",
    "model_rdn.eval()\n",
    "likelihood_rdn.eval()\n",
    "x0_new,lower_bound, upper_bound = conduct_design_pll(x0,f_target, g_theta_, agg_data1, model_rdn, likelihood_rdn, iter_design, iter_param, lr_new, noise_value)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target-tol_vector)\n",
    "print(f_target+tol_vector)\n",
    "loc_sample = np.random.random_sample((loc_size_rdn,2))\n",
    "\n",
    "\n",
    "SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(x0_new)\n",
    "print(SUCCESS)\n",
    "sol_rdn = x0_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAD Plots and Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we vizualize the target function, namely, the contours of the coordinates of the outputs and its norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=16)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=15)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=15)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=15)    # legend fontsize\n",
    "plt.rc('font', size=15)          # controls default text sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_target = vf.tgt_vec\n",
    "f_target = f_target.reshape(f_target.shape[0],1)\n",
    "vf.tgt_loc = vf.tgt_loc.reshape(2,1)\n",
    "x_plot = np.linspace(vf.low, vf.high, 30)\n",
    "y_plot = np.linspace(vf.low, vf.high, 30)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat = torch.zeros(n * n, 2)\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "out_plot = vfield_(x_concat)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize = (8, 18),  tight_layout=True)\n",
    "v_1 = out_plot[:,0].reshape(n,n)\n",
    "v_2 = out_plot[:,1].reshape(n,n)\n",
    "v = np.sqrt(v_1**2 + v_2**2)\n",
    "print(torch.max(v))\n",
    "\n",
    "#pos = ax1.imshow(v_1, cmap='RdGy', interpolation='none')\n",
    "\n",
    "cs1 = ax1.contourf(xv_plot, yv_plot,v_1, np.linspace(v_1.min(), v_1.max(), 100),cmap='jet')\n",
    "ax1.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "#cs11 = ax1.contour(xv_plot, yv_plot, v_1,np.linspace(v_1.min(), v_1.max(), 30),colors='w')\n",
    "ax1.set_title('$v_1$')\n",
    "ax1.set_xlabel('$x_1$')\n",
    "ax1.set_ylabel('$x_2$')\n",
    "cs2 = ax2.contourf(xv_plot, yv_plot, v_2, np.linspace(v_2.min(), v_2.max(), 100),cmap='jet')\n",
    "ax2.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax2.set_xlabel('$x_1$')\n",
    "ax2.set_ylabel('$x_2$')\n",
    "#cs21 = ax2.contour(xv_plot, yv_plot, v_2,colors='w')\n",
    "ax2.set_title('$v_2$')\n",
    "#ax2.set_aspect('equal')\n",
    "sns.scatterplot(x=out_plot[:,0], y=out_plot[:,1], s=5, color=\".15\", ax = ax3)    #cs3 = ax3.contourf(xv_plot, yv_plot, v,np.linspace(v.min(), v.max(), 100),cmap='jet')\n",
    "sns.histplot(x=out_plot[:,0], y=out_plot[:,1], bins=50, pthresh=.1, cmap=\"mako\", ax = ax3)\n",
    "sns.kdeplot(x=out_plot[:,0], y=out_plot[:,1], levels=5, color=\"w\", linewidths=1, ax = ax3)\n",
    "\n",
    "#ax3.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax3.set_xlabel('$x_1$')\n",
    "ax3.set_ylabel('$x_2$')\n",
    "#cs31 = ax3.contour(xv_plot, yv_plot, v, np.linspace(v.min(), v.max(), 30),colors='w')\n",
    "ax3.set_title('$scatter+hist$')\n",
    "#ax3.set_aspect('equal')\n",
    "cbar1 = fig.colorbar(cs1, ax = ax1);\n",
    "#cbar1.add_lines(cs11)\n",
    "\n",
    "cbar2 = fig.colorbar(cs2, ax = ax2);\n",
    "#cbar2.add_lines(cs21)\n",
    "\n",
    "#cbar3 = fig.colorbar(cs3, ax = ax3);\n",
    "#cbar3.add_lines(cs31)\n",
    "# ax01 = fig.add_subplot(3, 2, 2, projection='3d')\n",
    "# ax02 = fig.add_subplot(3, 2, 4, projection='3d')\n",
    "# ax03 = fig.add_subplot(3, 2, 6, projection='3d')\n",
    "\n",
    "# ax01.plot3D(x_concat[:,0], x_concat[:,1], out_plot[:,0])\n",
    "\n",
    "# ax02.plot3D(x_concat[:,0], x_concat[:,1], out_plot[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# ax03.plot3D(x_concat[:,0], x_concat[:,1], np.sqrt( (out_plot[:,1])**2 + (out_plot[:,0])**2))\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('figures/target_fun.png')\n",
    "# cs = plt.contourf(v_1, levels=[10, 30, 50],\n",
    "#     colors=['#808080', '#A0A0A0', '#C0C0C0'], extend='both')\n",
    "# cs.cmap.set_over('red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loc_size_rdn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_size = 4\n",
    "i,j=0,0\n",
    "low = -3.1\n",
    "high = 3.1\n",
    "PLOTS_PER_ROW = 2\n",
    "widths = 16* np.ones((PLOTS_PER_ROW))\n",
    "heights = 16 * np.ones((math.ceil((iter + 1)/PLOTS_PER_ROW)))\n",
    "#print(heights)\n",
    "gs_kw = dict(width_ratios=widths, height_ratios=heights)\n",
    "#fig, ax = plt.subplots(math.ceil((iter + 1)/PLOTS_PER_ROW),PLOTS_PER_ROW, constrained_layout=True,\n",
    "#                             gridspec_kw=gs_kw)\n",
    "fig, axs = plt.subplots(math.ceil((iter+1)/PLOTS_PER_ROW),PLOTS_PER_ROW, figsize=(14, 28),  tight_layout=True)\n",
    "ii = 0\n",
    "# vec_x = Tensor([[0.5000, 0.7000],\n",
    "#         [0.1427, 0.2234],\n",
    "#         [0.1859, 0.1796],\n",
    "#         [0.2023, 0.0953],\n",
    "#         [0.1999, 0.0963],\n",
    "#         [0.2003, 0.0998]])\n",
    "col = 0\n",
    "\n",
    "vec_x = vec_x.detach()\n",
    "axs[i][j].plot(0.8731, 0.5664,'gs',markersize=12)\n",
    "axs[i][j].plot(vec_x[col,0], vec_x[col,1],'rD',markersize=12)\n",
    "axs[i][j].plot(x_train.detach()[:,0], x_train.detach()[:,1], 'bv', markersize=12)\n",
    "axs[i][j].plot(v2.detach()[ii:ii+loc_size,0], v2.detach()[ii:ii+loc_size,1], 'yv', markersize=12)\n",
    "axs[i][j].set_xlabel('$x_1$')\n",
    "axs[i][j].set_ylabel('$x_2$')\n",
    "axs[i][j].set_title('initial config')\n",
    "\n",
    "#axs[i][j].set_aspect('equal')\n",
    "if (ii > 0):\n",
    "    axs[i][j].plot(v2.detach()[(ii-loc_size):ii,0], v2.detach()[ii-loc_size:ii,1], 'yv', markersize=12)\n",
    "axs[i][j].set_xlim(low, high)\n",
    "axs[i][j].set_ylim(low, high)\n",
    "ii = ii+loc_size+1\n",
    "j+=1\n",
    "\n",
    "loc_size = loc_size\n",
    "for col in range(1, iter+1):\n",
    "    axs[i][j].plot(0.8731, 0.5664,'gs',markersize=12)\n",
    "    axs[i][j].plot(vec_x[col,0], vec_x[col,1],'rD',markersize=12)\n",
    "    axs[i][j].plot(v2.detach()[ii:ii+loc_size,0], v2.detach()[ii:ii+loc_size,1], 'bv', markersize=12)\n",
    "  #  axs[i][j].set_aspect('equal')\n",
    "    if (ii > loc_size):\n",
    "        axs[i][j].plot(v2.detach()[(ii-loc_size):ii,0], v2.detach()[ii-loc_size:ii,1], 'yv', markersize=12)\n",
    "    axs[i][j].set_xlim(low, high)\n",
    "    axs[i][j].set_ylim(low, high)\n",
    "    axs[i][j].set_xlabel('$x_1$')\n",
    "    axs[i][j].set_ylabel('$x_2$')\n",
    "    axs[i][j].set_title('stage %s' % col)\n",
    "    ii = ii+loc_size+1\n",
    "    j+=1\n",
    "    \n",
    "    if j%PLOTS_PER_ROW==0:\n",
    "        i+=1\n",
    "        j=0\n",
    "plt.show()\n",
    "plt.savefig('figures/evol_sol.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x0 = Tensor(np.array([0.1937, 0.1257]))\n",
    "#x0 = Tensor(np.array([0.1885, 0.1038]))\n",
    "x_plot = np.linspace(vf.low, vf.high, 30)\n",
    "y_plot = np.linspace(vf.low, vf.high, 30)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat_ = torch.zeros(n * n, 2)\n",
    "\n",
    "# n_sample = x_concat_.shape[0]\n",
    "num_tasks = 2\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "\n",
    "model.eval()\n",
    "\n",
    "likelihood.eval()\n",
    "\n",
    "#noise = torch.eye(2 * g_theta1.detach().shape[0]) * noise_value\n",
    "#print(x_concat_)\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(False):\n",
    "    pred = GPprediction(model)\n",
    "    pr_mean, cov = pred.GPpred(g_theta1.detach(), agg_data, x_concat_, noise_value)\n",
    "    #pr = (model(g_theta1.detach())) # likelihood(model(x_concat_), noise = torch.ones(x_concat_.shape) * noise_value)#\n",
    "    pr_mean = pr_mean.reshape(x_concat_.shape[0], num_tasks)\n",
    "    mean_v_1 = pr_mean[:,0].reshape(n,n)\n",
    "    mean_v_2 = pr_mean[:,1].reshape(n,n)\n",
    "    pred_var = cov.diag().reshape(num_tasks, x_concat_.shape[0]).T\n",
    "    \n",
    "    var_v_1 = pred_var[:,0].reshape(n,n)\n",
    "    var_v_2 = pred_var[:,1].reshape(n,n)\n",
    "#     AA = pr.covariance_matrix.mean(axis=0).reshape(num_tasks, x_concat_.shape[0]).T #.diag() #.reshape(num_tasks, num_tasks * g_theta1.shape[0]).T\n",
    "\n",
    "# #     print(pr.covariance_matrix.mean(axis=0))\n",
    "# #     print(AA)\n",
    "# #     print(pr.variance)\n",
    "# #     print((pr.covariance_matrix))\n",
    "# #     K = model.covar_module\n",
    "#     print((cov.diag()))\n",
    "#     print(pr_mean)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 2, figsize = (20, 16), tight_layout=True)\n",
    "cs10 = ax1[0].contourf(xv_plot, yv_plot, mean_v_1.detach(),np.linspace(mean_v_1.detach().min(), mean_v_1.detach().max(), 100), cmap = 'jet')\n",
    "ax1[0].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax1[0].set_title('$\\mu(v_1)$', fontsize = 18)\n",
    "cbar10 = fig.colorbar(cs10, ax = ax1[0]);\n",
    "\n",
    "ax1[0].set_xlabel('$x_1$', fontsize = 16)\n",
    "ax1[0].set_ylabel('$x_2$', fontsize = 16)\n",
    "\n",
    "cs11 = ax1[1].contourf(xv_plot, yv_plot, var_v_1.detach(), np.linspace(var_v_1.detach().min(), var_v_1.detach().max(), 100), cmap = 'jet')\n",
    "ax1[1].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax1[1].set_title('$\\sigma^2(v_1)$', fontsize = 18)\n",
    "# ax1[0].set_aspect('equal')\n",
    "# ax1[1].set_aspect('equal')\n",
    "cbar11 = fig.colorbar(cs11, ax = ax1[1]);\n",
    "ax1[1].set_xlabel('$x_1$', fontsize = 16)\n",
    "ax1[1].set_ylabel('$x_2$', fontsize = 16)\n",
    "\n",
    "\n",
    "cs20 = ax2[0].contourf(xv_plot, yv_plot, mean_v_2.detach(),np.linspace(mean_v_2.detach().min(), mean_v_2.detach().max(), 100), cmap = 'jet')\n",
    "ax2[0].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax2[0].set_title('$\\mu(v_2)$', fontsize = 18)\n",
    "cbar20 = fig.colorbar(cs20, ax = ax2[0]);\n",
    "ax2[0].set_xlabel('$x_1$', fontsize = 16)\n",
    "ax2[0].set_ylabel('$x_2$', fontsize = 16)\n",
    "\n",
    "\n",
    "\n",
    "cs21 = ax2[1].contourf(xv_plot, yv_plot, var_v_2.detach(), np.linspace(var_v_2.detach().min(), var_v_2.detach().max(), 100), cmap = 'jet')\n",
    "ax2[1].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'ks', markersize=12)\n",
    "ax2[1].set_title('$\\sigma^2(v_2)$', fontsize = 18)\n",
    "cbar21 = fig.colorbar(cs21, ax = ax2[1]);\n",
    "ax2[1].set_xlabel('$x_1$', fontsize = 16)\n",
    "ax2[1].set_ylabel('$x_2$', fontsize = 16)\n",
    "\n",
    "\n",
    "# ax2[0].set_aspect('equal')\n",
    "# ax2[1].set_aspect('equal')\n",
    "\n",
    "plt.savefig('figures/mean_var.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_size= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(vf.low, vf.high, 13)\n",
    "y_plot = np.linspace(vf.low, vf.high, 13)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat = torch.zeros(n * n, 2)\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "\n",
    "g_theta_grid = x_concat\n",
    "agg_data1_grid = vfield_(g_theta_grid)\n",
    "agg_data1_grid = agg_data1_grid.flatten()\n",
    "\n",
    "\n",
    "x0 = Tensor(np.array([0.0,0.0])) \n",
    "x0 = x0.reshape(1,2)\n",
    "x00 = x0 \n",
    "vec_x_grid = Tensor(np.array([0.0,0.0])) \n",
    "vec_x_grid = vec_x_grid.reshape(1,2)\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    " \n",
    "tol = 0.009 \n",
    "print('START HYPERPARAMETERS optimization')\n",
    "model_grid, likelihood_grid = hyper_opti(g_theta_grid,agg_data1_grid,iter_hp,num_base_kernels,noise_value)\n",
    "\n",
    "print('END HYPERPARAMETERS optimization')\n",
    "model_grid.eval()\n",
    "likelihood_grid.eval()\n",
    "x0_new,lower_bound, upper_bound = conduct_design_pll(x0,f_target, g_theta_grid, agg_data1_grid, model_grid, likelihood_grid, iter_design, iter_param, lr_new,noise_value)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target-tol_vector)\n",
    "print(f_target+tol_vector)\n",
    "#loc_sample = np.random.random_sample((loc_size_rdn,2))\n",
    "\n",
    "\n",
    "SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(x0_new)\n",
    "print(SUCCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.plot(x_concat[:,0],x_concat[:,1], 'bv',markersize=10)\n",
    "ax.plot(x0_new.detach()[0,0], x0_new.detach()[0,1],'gD',markersize=12)\n",
    "ax.plot(0.8731, 0.5664,'rs',markersize=12)\n",
    "plt.savefig('figures/grid_sol.eps')\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.plot(g_theta_[:,0].detach(),g_theta_[:,1].detach(), 'mv',markersize=10)\n",
    "ax.plot(sol_rdn.detach()[0,0], sol_rdn.detach()[0,1],'gD',markersize=12)\n",
    "ax.plot(0.8731, 0.5664,'rs',markersize=12)\n",
    "plt.savefig('figures/rdn_sol.eps')\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'yv',markersize=10)\n",
    "ax.plot(vec_x[-1,0], vec_x[-1,1],'rs',markersize=12)\n",
    "ax.plot(0.8731, 0.5664,'gD',markersize=12)\n",
    "\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "plt.savefig('figures/tad_sol_allpoints.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
