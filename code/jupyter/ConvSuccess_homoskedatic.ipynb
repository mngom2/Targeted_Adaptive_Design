{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn  import functional as F\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import sys\n",
    "from decimal import Decimal\n",
    "from IPython.display import clear_output\n",
    "sys.path.append(\"..\")\n",
    "from LBFGS import FullBatchLBFGS\n",
    "from kernels import vvkernels as vvk, sep_vvkernels as svvk, vvk_rbfkernel as vvk_rbf\n",
    "from means import vvmeans as vvm\n",
    "from likelihood import vvlikelihood as vvll\n",
    "from mlikelihoods import MarginalLogLikelihood as exmll\n",
    "from predstrategies import GPprediction\n",
    "from utils import ObjFun, get_vertices, stopping_criteria\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=40)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=32)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=32)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=32)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=32)    # legend fontsize\n",
    "plt.rc('font', size=32)          # controls default text sizes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective function\n",
    "\n",
    "We sample from $$V_1(x_1, x_2) = 3(1 - x_1)^2 e^{-x_1^2 - (x_2 +1)^2} - 10 (x_1/5 - x_1 ^3 - x_2^5) e^{-x_1^2 - x_2 ^2} - 3 e^{- (x_1 + 2) ^2 - x_2^2} + 0.5(2x_1 + x_2)$$\n",
    "$$V_2(x_1, x_2) = 3(1 +x_2)^2 e^{-x_2^2 - (x_1 +1)^2} - 10 (-x_2/5 + x_2 ^3 + x_1^5) e^{-x_1^2 - x_2 ^2} - 3 e^{- ( 2- x_2) ^2 - x_1^2} + 0.5(2x_1 + x_2)$$\n",
    "\n",
    "where $(x_1, x_2) \\in [-3, 3]^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3380, 0.3502], dtype=torch.float32)\n",
      "tensor([[ 1.0966, -1.9940],\n",
      "        [ 1.0923, -1.0227],\n",
      "        [ 1.9755, -1.8962],\n",
      "        [ 1.3756, -1.2389]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "vf = ObjFun()\n",
    "f_target = vf.tgt_vec\n",
    "print(f_target)\n",
    "sample_size = 4\n",
    "D = vf.D\n",
    "N = vf.N\n",
    "\n",
    "vf.low = -3.\n",
    "vf.high = 3.\n",
    "\n",
    "high_minus_low = vf.high- vf.low\n",
    "#high_minus_low = -\n",
    "def g_theta(sample_size, D):\n",
    "    loc_x = (2. - 1.0 )  * np.random.random_sample((sample_size,1)) + 1.0\n",
    "    \n",
    "    loc_y = (2.  -1.0)  * np.random.random_sample((sample_size,1)) - 2.\n",
    "    loc = np.concatenate((loc_x, loc_y), 1)\n",
    "    #loc = high_minus_low  * np.random.random_sample((sample_size,2)) + vf.low#(np.random.uniform(low=vf.low, high=vf.high, size=(sample_size, D)))\n",
    "    return Tensor(loc)\n",
    "train_x = g_theta(sample_size, D)\n",
    "if use_cuda:\n",
    "    train_x = train_x.cuda()\n",
    "#train_x = Tensor([[-1.5, 1.5], [-1.5, 1.3]])\n",
    "print(train_x)\n",
    "noise_value = 0.0004 #noise_free = 0.\n",
    "def vfield_(x):\n",
    "    x = x.reshape(x.shape[0],D)\n",
    "    out = torch.zeros(x.shape[0], N)\n",
    "    randn = torch.randn(Tensor(vf(x[:,0], x[:,1])).size())\n",
    "    randn = randn.to(x.device)\n",
    "    out = vf(x[:,0], x[:,1]) + randn * math.sqrt(noise_value)\n",
    "    return out #/torch.max(out)\n",
    "\n",
    "train_y = vfield_(train_x)\n",
    "\n",
    "# print(train_y)\n",
    "# train_y = (train_y - train_y.mean())/train_y.std(dim=-2, keepdim=True)\n",
    "# train_x = (train_x - train_x.mean())/train_x.std(dim=-2, keepdim=True)\n",
    "# print(train_y)\n",
    "# print(train_y.std(dim=-2, keepdim=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP model initialization\n",
    "We inialize the GP model following https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_x #loc #torch.linspace(0, 1, 10)\n",
    "y_train = train_y #v  #torch.stack([torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,], -1)\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood,num_base_kernels):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = vvm.TensorProductSubMean(gpytorch.means.LinearMean(2), num_tasks = 2)  #vvm.TensorProductSubMean(gpytorch.means.LinearMean(2), num_tasks = 2)#vvm.TensorProductSubMean(gpytorch.means.ConstantMean(), num_tasks = 2)  # \n",
    "        base_kernels = [] #contain all the base kernels\n",
    "        for i in range(num_base_kernels):\n",
    "            base_kernels.append(gpytorch.kernels.ScaleKernel(( gpytorch.kernels.RBFKernel() ))) #gpytorch.kernels.PolynomialKernel(4)  ##gpytorch.kernels.MaternKernel()# (vvk_rbf.vvkRBFKernel())\n",
    " \n",
    "            \n",
    "        self.covar_module = svvk.SepTensorProductKernel(base_kernels,num_tasks = 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamaters oprimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ###hyperparameters optimization###\n",
    "def hyper_opti(g_theta1, agg_data, training_iter,num_base_kernels,noise_value, current_model = None, current_likelihood = None):\n",
    "    noises = torch.ones(agg_data.shape[0]) * (noise_value) #  torch.zeros(agg_data.shape[0]) # \n",
    "    noises = noises.reshape(g_theta1.shape[0], 2)\n",
    "    \n",
    "#     if (current_model is not None):\n",
    "#         likelihood = current_likelihood #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises)  #\n",
    "\n",
    "#         model = current_model#.get_fantasy_model(g_theta1, agg_data) #MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "#         model.set_train_data(g_theta1, agg_data,  strict=False)\n",
    "#     else:\n",
    "#         likelihood = vvll.FixedNoiseMultitaskGaussianLikelihood(noises) #vvll.TensorProductLikelihood(num_tasks = 2)#vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #\n",
    "#         model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "        \n",
    "    cov_noise1 =  noise_value * torch.eye(agg_data.shape[0])\n",
    "    likelihood =  vvll.FixedNoiseMultitaskGaussianLikelihood(noises) #vvll.TensorProductLikelihood(num_tasks = 2) #\n",
    "    model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "    model.double()\n",
    "    likelihood.double()\n",
    "\n",
    "    \"\"\"Put related things on GPU\"\"\"\n",
    "    if use_cuda:\n",
    "        print(\"Using CUDA\")\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "        g_theta1 = g_theta1.cuda()\n",
    "        agg_data = agg_data.cuda()\n",
    "        cov_noise1 = cov_noise1.cuda()\n",
    "        \n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "    \n",
    "    \"\"\"end for GPU\"\"\"\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  lr=0.1) #, weight_decay=0.001)  # Includes GaussianLikelihood parameters\n",
    "    mll = exmll(likelihood, model)\n",
    "    # Is this a likelihood?\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, chi_square = mll(agg_data,g_theta1, model, likelihood, cov_noise1)\n",
    "        loss = -1. * loss\n",
    "#         print('df is %.3f' %agg_data.shape[0] +'and chi_square %.3f' %chi_square) \n",
    "        #print('loss is %.3f' %loss)\n",
    "#         df = agg_data.shape[0]\n",
    "#         chi_square = chi_square.clone().detach()\n",
    "        \n",
    "#         p_val = 1. - stats.chi2.cdf(chi_square, df)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss)\n",
    "       # print(p_val)\n",
    "#         if (p_val > 0.99999):\n",
    "#             return model, likelihood\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    print('loss is %.3f' %loss)\n",
    "#     for params in model.named_parameters():\n",
    "#         print(params)\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design parameters and sampling point optimization (where to explore?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_design_opti(x0,loc_sample, f_target, g_theta1, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new,noise_value):\n",
    "\n",
    "    g_theta2 = nn.Parameter(Tensor(loc_sample))\n",
    "\n",
    "    x_d= nn.Parameter(Tensor(x0))\n",
    "    \n",
    "    optimizer = torch.optim.Adam([{'params': g_theta2, 'lr': 0.1},{'params': x_d, 'lr': 0.1}])\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    \n",
    "    cov_noise1 =  noise_value * torch.eye(agg_data.shape[0])\n",
    "    cov_noise2 =  noise_value * torch.eye(2 * g_theta2.shape[0])\n",
    "    \n",
    "    \"\"\"Put related things on GPU for conduct_design_opti\"\"\"\n",
    "    if use_cuda:\n",
    "        print(\"Using CUDA for conduct_design_opti()\")\n",
    "        \n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "        agg_data = agg_data.cuda()\n",
    "        \n",
    "        cov_noise1 = cov_noise1.cuda()\n",
    "        cov_noise2 = cov_noise2.cuda()\n",
    "        g_theta1 = g_theta1.cuda()\n",
    "        g_theta2 = g_theta2.cuda()\n",
    "        agg_data = agg_data.cuda()\n",
    "        x_d = x_d.cuda()\n",
    "        f_target = f_target.cuda()\n",
    "        \n",
    "    else:\n",
    "        print(\"Using CPU for conduct_design_opti()\")\n",
    "    \n",
    "    \"\"\"end for GPU\"\"\"\n",
    "    \n",
    "    \n",
    "    for ii in range( training_param_iter ):\n",
    "#         x_d = torch.cat([x_d_0, x_d_1]).reshape(1,2)\n",
    "#         g_theta2 = torch.cat([g_theta20, g_theta21],1)\n",
    "        optimizer.zero_grad()\n",
    "        loss2, pf1, Qf1, Qf12, data_fit, Q21 = likelihood.get_ell(agg_data,f_target,x_d, g_theta1, model, likelihood, g_theta2, cov_noise1, cov_noise2)\n",
    "\n",
    "        loss2 = -1. * loss2\n",
    "        \n",
    "        loss2.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss2)\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Loss design: %.3f' % ( loss2))\n",
    "    #print(x_d)\n",
    "    return x_d, g_theta2, loss2, pf1, Qf1, Qf12, data_fit, Q21\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conducting the TAD experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_size = 2\n",
    "#loc_sample0 = Tensor((2. - 1.5)  * np.random.random_sample((loc_size,2)) + 1.5)\n",
    "x0 = Tensor(np.array([-2. , 2.]))\n",
    " # 1./3. * Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "x0 = x0.reshape(1,2)\n",
    "\n",
    "dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .01 * torch.eye(loc_size) )\n",
    "                    #loc_size = 4\n",
    "loc_sample = dis_2sample.sample((loc_size + 1,))\n",
    "\n",
    "loc_sample0 = loc_sample.reshape(loc_size + 1, 2)\n",
    "#loc_sample0[-1] = train_x[-1] + 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1028,  2.0542],\n",
      "        [-1.9277,  1.9859],\n",
      "        [-2.0587,  2.0615]])\n",
      "0\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.621\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 1321.920\n",
      "expected info is tensor([[0.4860]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.7974, -0.8885]], device='cuda:0')\n",
      "new data istensor([[0.1372, 0.2313]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.1028,  2.0542],\n",
      "        [-1.9277,  1.9859],\n",
      "        [-2.0587,  2.0615]], device='cuda:0')\n",
      "p21val is 0.000000000000000\n",
      "pf12val is 0.000000000000000\n",
      "chi_f12 is 511.810675355316732\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "0\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 745.983\n",
      "expected info is tensor([[0.5243]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.4509,  0.8225]], device='cuda:0')\n",
      "new data istensor([[ 0.1687, -0.1738]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.5166, -0.7555],\n",
      "        [-0.3020, -2.0583],\n",
      "        [-0.5827, -0.9597]], device='cuda:0')\n",
      "p21val is 0.000000000000000\n",
      "pf12val is 0.000000000000000\n",
      "chi_f12 is 147.031164704376721\n",
      "patience is 2.000\n",
      "adding complexity to model\n",
      "num base is 3\n",
      "acquiring 2, new size is 7\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "1\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.018\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 111.636\n",
      "expected info is tensor([[0.3115]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.2939, -0.0281]], device='cuda:0')\n",
      "new data istensor([[0.1752, 0.0562]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.1028,  2.0542],\n",
      "        [-1.9277,  1.9859],\n",
      "        [-2.0587,  2.0615]], device='cuda:0')\n",
      "p21val is 0.000000000000136\n",
      "pf12val is 0.000289436275565\n",
      "chi_f12 is 16.295150808253236\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "1\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 78.076\n",
      "expected info is tensor([[0.4299]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.1261,  1.3448]], device='cuda:0')\n",
      "new data istensor([[ 0.1103, -0.1011]], device='cuda:0')\n",
      "g_theta2 istensor([[ 2.7546, -1.3700],\n",
      "        [ 1.1644, -0.2781],\n",
      "        [ 0.1574,  0.2301]], device='cuda:0')\n",
      "p21val is 0.000000000000000\n",
      "pf12val is 0.000001682932617\n",
      "chi_f12 is 26.589945362408997\n",
      "patience is 2.000\n",
      "adding complexity to model\n",
      "num base is 4\n",
      "acquiring 2, new size is 10\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "2\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.480\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -2.069\n",
      "expected info is tensor([[0.1597]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.2637,  0.4345]], device='cuda:0')\n",
      "new data istensor([[-0.5672,  0.6074]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.1028,  2.0542],\n",
      "        [-1.9277,  1.9859],\n",
      "        [-2.0587,  2.0615]], device='cuda:0')\n",
      "p21val is 0.378356406844525\n",
      "pf12val is 0.001364297484862\n",
      "chi_f12 is 13.194231291868252\n",
      "p_val_ftarget is 0.7752054517115804\n",
      "new 2 points\n",
      "tensor([[-0.5587, -0.7731],\n",
      "        [-0.4359, -1.0449],\n",
      "        [-1.2638,  0.4347]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "3\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.515\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 8.943\n",
      "expected info is tensor([[0.1291]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.7366,  0.9685]], device='cuda:0')\n",
      "new data istensor([[ 0.0740, -0.1839]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.3729, -1.0640],\n",
      "        [-0.5542, -0.9390],\n",
      "        [-1.4040,  0.3042]], device='cuda:0')\n",
      "p21val is 0.439539403525665\n",
      "pf12val is 0.024351995428456\n",
      "chi_f12 is 7.430282970061116\n",
      "p_val_ftarget is 7.743417122729745e-06\n",
      "new 2 points\n",
      "tensor([[-0.4620, -0.6659],\n",
      "        [-0.7258,  1.0188],\n",
      "        [-0.7367,  0.9685]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.691\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 34.304\n",
      "expected info is tensor([[0.0722]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.1405,  0.5417]], device='cuda:0')\n",
      "new data istensor([[0.1084, 0.0901]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.5345, -0.7326],\n",
      "        [-0.9039,  1.3572],\n",
      "        [-1.0157,  1.3335]], device='cuda:0')\n",
      "p21val is 0.004666050569514\n",
      "pf12val is 0.319126602051431\n",
      "chi_f12 is 2.284334766590860\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 121.912\n",
      "expected info is tensor([[0.1137]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.9793,  0.5731]], device='cuda:0')\n",
      "new data istensor([[-0.3150,  0.2519]], device='cuda:0')\n",
      "g_theta2 istensor([[-1.2953,  2.0104],\n",
      "        [-0.3702,  1.4201],\n",
      "        [-0.3100,  1.3601]], device='cuda:0')\n",
      "p21val is 0.015457112104820\n",
      "pf12val is 0.547932570167764\n",
      "chi_f12 is 1.203206093488316\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-9.7868e-01,  4.2289e-04],\n",
      "        [-1.4084e+00,  2.2715e+00],\n",
      "        [-9.7916e-01,  5.7309e-01]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "5\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.694\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 3.873\n",
      "expected info is tensor([[0.0589]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.5737,  0.0016]], device='cuda:0')\n",
      "new data istensor([[0.0437, 0.0427]], device='cuda:0')\n",
      "g_theta2 istensor([[-1.5326, -0.5263],\n",
      "        [-1.8824,  2.7787],\n",
      "        [-1.3146,  0.8689]], device='cuda:0')\n",
      "p21val is 0.869948564596887\n",
      "pf12val is 0.133031070123063\n",
      "chi_f12 is 4.034345136190186\n",
      "p_val_ftarget is 0.0009561404269071705\n",
      "new 2 points\n",
      "tensor([[-1.7940e+00,  1.4492e+00],\n",
      "        [-1.3325e+00,  1.0481e+00],\n",
      "        [-5.7365e-01,  1.4925e-03]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "6\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.664\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 2.171\n",
      "expected info is tensor([[0.0049]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.0136, -0.5203]], device='cuda:0')\n",
      "new data istensor([[0.2280, 0.0516]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.2248,  1.9176],\n",
      "        [-1.2888,  1.0952],\n",
      "        [-0.9174,  0.4290]], device='cuda:0')\n",
      "p21val is 0.885091537334849\n",
      "pf12val is 0.647085921160360\n",
      "chi_f12 is 0.870552387955583\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.004343401202641983\n",
      "new 2 points\n",
      "tensor([[-2.8902, -1.9950],\n",
      "        [-0.3116,  0.0570],\n",
      "        [-0.0133, -0.5204]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "7\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.809\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 16.064\n",
      "expected info is tensor([[0.0062]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 0.4569, -1.1242]], device='cuda:0')\n",
      "new data istensor([[-0.4178,  0.2850]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.7911, -2.6755],\n",
      "        [-0.7709,  0.5261],\n",
      "        [-0.3535, -0.7608]], device='cuda:0')\n",
      "p21val is 0.000212604926267\n",
      "pf12val is 0.259489725756565\n",
      "chi_f12 is 2.698076339240492\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "7\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 16.257\n",
      "expected info is tensor([[0.0064]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 0.4664, -1.1304]], device='cuda:0')\n",
      "new data istensor([[-0.4205,  0.3166]], device='cuda:0')\n",
      "g_theta2 istensor([[ 2.0022,  1.7334],\n",
      "        [ 2.4532,  1.2001],\n",
      "        [-0.4851, -0.5302]], device='cuda:0')\n",
      "p21val is 0.012124115098026\n",
      "pf12val is 0.204996869710613\n",
      "chi_f12 is 3.169521139329272\n",
      "p_val_ftarget is 3.314410523813649e-09\n",
      "new 2 points\n",
      "tensor([[ 0.4478, -0.8680],\n",
      "        [ 2.6743,  2.3845],\n",
      "        [ 0.4663, -1.1303]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "8\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -1.781\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 78.681\n",
      "expected info is tensor([[0.0204]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 0.0245, -1.6313]], device='cuda:0')\n",
      "new data istensor([[-0.7844,  0.3142]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.5700, -0.5081],\n",
      "        [ 2.6168,  2.5288],\n",
      "        [ 0.9641, -0.7624]], device='cuda:0')\n",
      "p21val is 0.808790390599161\n",
      "pf12val is 0.062363531235489\n",
      "chi_f12 is 5.549549219568704\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.5993,  2.2248],\n",
      "        [-1.0876,  2.4541],\n",
      "        [ 0.0245, -1.6312]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "9\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.805\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 35.477\n",
      "expected info is tensor([[0.0879]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 0.5683, -2.2493]], device='cuda:0')\n",
      "new data istensor([[-0.3629,  0.0769]], device='cuda:0')\n",
      "g_theta2 istensor([[ 1.0209,  2.6810],\n",
      "        [-0.5409,  2.9784],\n",
      "        [-0.2548, -1.2889]], device='cuda:0')\n",
      "p21val is 0.977584409419883\n",
      "pf12val is 0.962497782129365\n",
      "chi_f12 is 0.076447034208063\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-0.5720, -2.4779],\n",
      "        [ 1.9648,  0.4142],\n",
      "        [ 0.5684, -2.2492]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "10\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.801\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 15.983\n",
      "expected info is tensor([[0.0335]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 0.0228, -2.7717]], device='cuda:0')\n",
      "new data istensor([[-0.2343, -0.0026]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.9270, -2.1549],\n",
      "        [ 2.7896,  0.9981],\n",
      "        [ 0.9273, -1.8940]], device='cuda:0')\n",
      "p21val is 0.970015596309442\n",
      "pf12val is 0.895044669915503\n",
      "chi_f12 is 0.221763302865310\n",
      "samples escaped box\n",
      "p_val_ftarget is 7.569917581662367e-09\n",
      "new 2 points\n",
      "tensor([[ 0.0422, -1.9173],\n",
      "        [-2.2389,  0.8111],\n",
      "        [ 0.0229, -2.7718]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "11\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.871\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 25.286\n",
      "expected info is tensor([[0.1114]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.6193, -2.9310]], device='cuda:0')\n",
      "new data istensor([[-0.2940,  0.0032]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.4162, -1.7031],\n",
      "        [-2.8742,  0.7488],\n",
      "        [ 0.3057, -2.4003]], device='cuda:0')\n",
      "p21val is 0.520386424928304\n",
      "pf12val is 0.883454217133814\n",
      "chi_f12 is 0.247831616895159\n",
      "samples escaped box\n",
      "p_val_ftarget is 5.572209360593661e-13\n",
      "new 2 points\n",
      "tensor([[-0.3018, -2.8494],\n",
      "        [-2.5520,  2.3409],\n",
      "        [-0.6192, -2.9310]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "12\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.882\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 43.627\n",
      "expected info is tensor([[0.0447]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.1735, -2.9126]], device='cuda:0')\n",
      "new data istensor([[-0.2756,  0.0080]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.1149, -2.6775],\n",
      "        [-2.9962,  2.4230],\n",
      "        [-0.2622, -2.5272]], device='cuda:0')\n",
      "p21val is 0.453458793354563\n",
      "pf12val is 0.679489638609183\n",
      "chi_f12 is 0.772826588117612\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-0.6201, -1.0729],\n",
      "        [ 1.8336, -0.8591],\n",
      "        [-1.1734, -2.9125]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "13\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.872\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 24.063\n",
      "expected info is tensor([[0.0577]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.7396, -2.8101]], device='cuda:0')\n",
      "new data istensor([[-0.3548,  0.0239]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.1806, -0.6117],\n",
      "        [ 2.2806, -0.4084],\n",
      "        [-0.8375, -2.5282]], device='cuda:0')\n",
      "p21val is 0.923134301517657\n",
      "pf12val is 0.619007017595718\n",
      "chi_f12 is 0.959277338747137\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 1.6218137943724287e-12\n",
      "new 2 points\n",
      "tensor([[ 2.2359, -0.3337],\n",
      "        [ 2.8014, -1.8734],\n",
      "        [-1.7397, -2.8099]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "14\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.962\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 19.459\n",
      "expected info is tensor([[0.0302]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-2.2245, -2.2061]], device='cuda:0')\n",
      "new data istensor([[-0.3873,  0.0220]], device='cuda:0')\n",
      "g_theta2 istensor([[ 2.3078, -0.1810],\n",
      "        [ 2.8374, -1.4918],\n",
      "        [-1.3885, -2.8419]], device='cuda:0')\n",
      "p21val is 0.665251671811631\n",
      "pf12val is 0.817695587615302\n",
      "chi_f12 is 0.402530307842188\n",
      "samples escaped box\n",
      "p_val_ftarget is 2.4859470038052223e-10\n",
      "new 2 points\n",
      "tensor([[ 1.7484, -1.3531],\n",
      "        [ 1.3885, -2.3727],\n",
      "        [-2.2245, -2.2063]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "15\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -1.978\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 23.594\n",
      "expected info is tensor([[0.1242]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-2.8106, -1.6273]], device='cuda:0')\n",
      "new data istensor([[-0.4133,  0.0173]], device='cuda:0')\n",
      "g_theta2 istensor([[ 1.7496, -1.4407],\n",
      "        [ 1.5562, -2.2552],\n",
      "        [-1.9064, -2.5453]], device='cuda:0')\n",
      "p21val is 0.980765292861074\n",
      "pf12val is 0.816895481554124\n",
      "chi_f12 is 0.404488243720267\n",
      "samples escaped box\n",
      "p_val_ftarget is 4.104161455131816e-12\n",
      "new 2 points\n",
      "tensor([[ 1.5134, -1.4307],\n",
      "        [-2.7141,  2.6360],\n",
      "        [-2.8105, -1.6273]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "16\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.013\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 28.709\n",
      "expected info is tensor([[0.0212]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-2.8477, -0.9858]], device='cuda:0')\n",
      "new data istensor([[-0.3889, -0.0181]], device='cuda:0')\n",
      "g_theta2 istensor([[ 1.5815, -1.4575],\n",
      "        [-2.8383,  2.8846],\n",
      "        [-2.4257, -1.8895]], device='cuda:0')\n",
      "p21val is 0.983281636051509\n",
      "pf12val is 0.507431617327324\n",
      "chi_f12 is 1.356786642655242\n",
      "p_val_ftarget is 1.7208456881689926e-14\n",
      "new 2 points\n",
      "tensor([[-1.9893,  1.9735],\n",
      "        [-1.5163,  1.4366],\n",
      "        [-2.8477, -0.9857]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "17\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.046\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 28.885\n",
      "expected info is tensor([[0.0752]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-2.2762, -0.4487]], device='cuda:0')\n",
      "new data istensor([[-0.5760,  0.3508]], device='cuda:0')\n",
      "g_theta2 istensor([[-1.8445,  2.0655],\n",
      "        [-1.8757,  2.0468],\n",
      "        [-2.9599, -1.4631]], device='cuda:0')\n",
      "p21val is 0.264282656048751\n",
      "pf12val is 0.750609169733540\n",
      "chi_f12 is 0.573740351635364\n",
      "samples escaped box\n",
      "p_val_ftarget is 1.0436096431476471e-14\n",
      "new 2 points\n",
      "tensor([[-1.7403,  2.7439],\n",
      "        [ 1.3068, -2.0200],\n",
      "        [-2.2764, -0.4488]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "18\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.084\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss design: 66.700\n",
      "expected info is tensor([[0.1929]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-2.8667,  0.1036]], device='cuda:0')\n",
      "new data istensor([[-0.4627,  0.0600]], device='cuda:0')\n",
      "g_theta2 istensor([[-1.9686,  2.8285],\n",
      "        [ 1.5659, -1.6360],\n",
      "        [-2.0463, -0.6979]], device='cuda:0')\n",
      "p21val is 0.730871867777882\n",
      "pf12val is 0.997196146671189\n",
      "chi_f12 is 0.005615582977254\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.6368, -0.8958],\n",
      "        [-1.6069,  1.1921],\n",
      "        [-2.8668,  0.1036]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "19\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.112\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 225.634\n",
      "expected info is tensor([[0.1212]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-2.9836, -0.5058]], device='cuda:0')\n",
      "new data istensor([[-0.4661,  0.0246]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.8723, -0.8096],\n",
      "        [-1.2868,  1.7317],\n",
      "        [-2.5339,  0.3972]], device='cuda:0')\n",
      "p21val is 0.270705992536095\n",
      "pf12val is 0.860538622818615\n",
      "chi_f12 is 0.300393560358089\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.0973, -1.5746],\n",
      "        [ 2.6974,  2.6931],\n",
      "        [-2.9835, -0.5060]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "20\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.146\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 388.760\n",
      "expected info is tensor([[0.0040]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-3.0123,  0.4138]], device='cuda:0')\n",
      "new data istensor([[-0.4505,  0.0461]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.5920, -2.1191],\n",
      "        [ 2.7552,  2.9767],\n",
      "        [-2.5673, -0.9882]], device='cuda:0')\n",
      "p21val is 0.518166571249216\n",
      "pf12val is 0.583364601452784\n",
      "chi_f12 is 1.077885799357523\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-2.4170,  0.6908],\n",
      "        [-0.8669, -1.7496],\n",
      "        [ 0.0608, -1.7911]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "21\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.172\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 2164.564\n",
      "expected info is tensor([[0.0031]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 0.0608, -1.7911]], device='cuda:0')\n",
      "new data istensor([[-0.8055,  0.2741]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.9386,  0.6687],\n",
      "        [-0.9042, -1.6180],\n",
      "        [-0.5113, -1.1938]], device='cuda:0')\n",
      "p21val is 0.712896556093293\n",
      "pf12val is 0.433698334957760\n",
      "chi_f12 is 1.670812134609676\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 2.4582, -1.2836],\n",
      "        [-1.1650, -0.4795],\n",
      "        [ 0.0610, -1.7912]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "22\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.190\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 1261.909\n",
      "expected info is tensor([[0.0013]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.1096, -2.4344]], device='cuda:0')\n",
      "new data istensor([[-0.3487,  0.0403]], device='cuda:0')\n",
      "g_theta2 istensor([[ 2.7388, -0.8153],\n",
      "        [-1.8106,  0.0088],\n",
      "        [ 0.1671, -1.2683]], device='cuda:0')\n",
      "p21val is 0.317611910512898\n",
      "pf12val is 0.908981933155267\n",
      "chi_f12 is 0.190860121037874\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 1.0946,  1.9314],\n",
      "        [ 1.0668, -1.9072],\n",
      "        [-0.1096, -2.4345]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "23\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.212\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 476.672\n",
      "expected info is tensor([[0.0041]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.4776, -3.0150]], device='cuda:0')\n",
      "new data istensor([[-0.2525,  0.0344]], device='cuda:0')\n",
      "g_theta2 istensor([[ 1.5161,  2.3405],\n",
      "        [ 1.3729, -2.0269],\n",
      "        [ 0.3844, -2.9304]], device='cuda:0')\n",
      "p21val is 0.993444818211122\n",
      "pf12val is 0.368305406804452\n",
      "chi_f12 is 1.997685550406434\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 2.1651,  2.7991],\n",
      "        [ 0.9408, -1.4253],\n",
      "        [ 1.6690,  2.4327]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "24\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.261\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 73.305\n",
      "expected info is tensor([[0.4670]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[1.6690, 2.4327]], device='cuda:0')\n",
      "new data istensor([[ 0.3714, -0.0011]], device='cuda:0')\n",
      "g_theta2 istensor([[ 2.7272,  2.8188],\n",
      "        [ 0.5790, -1.8450],\n",
      "        [ 1.3260,  1.9977]], device='cuda:0')\n",
      "p21val is 0.765868135275821\n",
      "pf12val is 0.079925247128840\n",
      "chi_f12 is 5.053326984063501\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.8472, -0.4051],\n",
      "        [ 1.8833, -0.0584],\n",
      "        [ 1.6691,  2.4327]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "25\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.269\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 5.178\n",
      "expected info is tensor([[0.0100]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[2.0883, 2.9180]], device='cuda:0')\n",
      "new data istensor([[ 0.4014, -0.0367]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.6757, -0.8061],\n",
      "        [ 1.5193, -0.4465],\n",
      "        [ 1.3057,  2.0705]], device='cuda:0')\n",
      "p21val is 0.000049891911692\n",
      "pf12val is 0.743767196694183\n",
      "chi_f12 is 0.592054401567947\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "25\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 216006.110\n",
      "expected info is tensor([[0.0118]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[2.0885, 2.9180]], device='cuda:0')\n",
      "new data istensor([[ 0.3871, -0.0341]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.2476, -2.8352],\n",
      "        [ 2.7507,  4.4697],\n",
      "        [ 1.3057,  2.0705]], device='cuda:0')\n",
      "p21val is 0.931570903161908\n",
      "pf12val is 0.682249086457889\n",
      "chi_f12 is 0.764720916816613\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.00011407296537702116\n",
      "new 2 points\n",
      "tensor([[-0.2159, -2.5802],\n",
      "        [-2.0393, -0.3570],\n",
      "        [ 2.0886,  2.9181]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "26\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.286\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 30.155\n",
      "expected info is tensor([[0.1975]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[1.4038, 2.9410]], device='cuda:0')\n",
      "new data istensor([[ 0.3078, -0.0014]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.0663, -2.5215],\n",
      "        [-2.0460, -0.8212],\n",
      "        [ 2.2288,  2.5841]], device='cuda:0')\n",
      "p21val is 0.895571753455345\n",
      "pf12val is 0.534673084283466\n",
      "chi_f12 is 1.252199552543769\n",
      "samples escaped box\n",
      "p_val_ftarget is 9.992007221626409e-16\n",
      "new 2 points\n",
      "tensor([[-1.8948, -2.2605],\n",
      "        [ 0.5700, -2.1170],\n",
      "        [ 1.4037,  2.9411]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "27\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.320\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 118.439\n",
      "expected info is tensor([[0.0075]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[1.7376, 2.9577]], device='cuda:0')\n",
      "new data istensor([[0.3701, 0.0192]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.0146, -2.6006],\n",
      "        [ 0.8393, -1.9230],\n",
      "        [ 1.1865,  2.4010]], device='cuda:0')\n",
      "p21val is 0.255110102453200\n",
      "pf12val is 0.436227285858177\n",
      "chi_f12 is 1.659183747243524\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[0.3070, 0.1106],\n",
      "        [2.1280, 2.2484],\n",
      "        [1.7375, 2.9578]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "28\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -2.334\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 37.187\n",
      "expected info is tensor([[0.0299]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8624, 2.9937]], device='cuda:0')\n",
      "new data istensor([[ 0.2569, -0.0615]], device='cuda:0')\n",
      "g_theta2 istensor([[0.3864, 0.0307],\n",
      "        [1.2688, 2.6918],\n",
      "        [1.8681, 2.4238]], device='cuda:0')\n",
      "p21val is 0.058550704588849\n",
      "pf12val is 0.767490587797812\n",
      "chi_f12 is 0.529258126103201\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[0.5555, 1.5644],\n",
      "        [1.0815, 2.8934],\n",
      "        [0.8624, 2.9936]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "29\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.341\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 21.109\n",
      "expected info is tensor([[0.0102]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.2972, 2.7797]], device='cuda:0')\n",
      "new data istensor([[ 0.2717, -0.1924]], device='cuda:0')\n",
      "g_theta2 istensor([[0.8206, 1.1364],\n",
      "        [1.4162, 2.5396],\n",
      "        [1.2516, 2.5941]], device='cuda:0')\n",
      "p21val is 0.877937250759590\n",
      "pf12val is 0.532238405414182\n",
      "chi_f12 is 1.261327519086365\n",
      "p_val_ftarget is 1.2865153387053851e-11\n",
      "new 2 points\n",
      "tensor([[0.5440, 2.4861],\n",
      "        [1.1711, 2.3089],\n",
      "        [0.2972, 2.7797]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "30\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.358\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 135.477\n",
      "expected info is tensor([[0.1654]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.0689,  2.9812]], device='cuda:0')\n",
      "new data istensor([[ 0.1917, -0.0981]], device='cuda:0')\n",
      "g_theta2 istensor([[0.9471, 2.1426],\n",
      "        [1.4783, 2.8584],\n",
      "        [0.7028, 2.3396]], device='cuda:0')\n",
      "p21val is 0.631998823104221\n",
      "pf12val is 0.380219655030746\n",
      "chi_f12 is 1.934012307415243\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 1.6636,  1.9883],\n",
      "        [-0.7749, -1.1116],\n",
      "        [-0.0690,  2.9813]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "31\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.379\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 223.990\n",
      "expected info is tensor([[0.1468]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.5398, 2.9973]], device='cuda:0')\n",
      "new data istensor([[ 0.2641, -0.0880]], device='cuda:0')\n",
      "g_theta2 istensor([[ 1.4447,  2.2533],\n",
      "        [-0.4510, -0.7523],\n",
      "        [ 0.0216,  2.7480]], device='cuda:0')\n",
      "p21val is 0.214724465176936\n",
      "pf12val is 0.631359784914979\n",
      "chi_f12 is 0.919758793634653\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.3429,  0.8178],\n",
      "        [ 1.8916, -1.4191],\n",
      "        [ 0.5398,  2.9973]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "32\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.397\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 374.369\n",
      "expected info is tensor([[0.0041]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.2018, 3.0115]], device='cuda:0')\n",
      "new data istensor([[ 0.2068, -0.1159]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.5206,  0.5290],\n",
      "        [ 1.3726, -1.7548],\n",
      "        [ 1.0011,  2.5765]], device='cuda:0')\n",
      "p21val is 0.371266493931390\n",
      "pf12val is 0.886015085789815\n",
      "chi_f12 is 0.242042603342409\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.5225,  2.3999],\n",
      "        [-0.8270,  2.2678],\n",
      "        [ 2.0375, -1.0182]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "33\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.169\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 117.738\n",
      "expected info is tensor([[0.0448]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 2.0375, -1.0182]], device='cuda:0')\n",
      "new data istensor([[ 0.2277, -0.1988]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.5340,  2.2742],\n",
      "        [-1.7086,  2.2129],\n",
      "        [ 1.4207, -1.6468]], device='cuda:0')\n",
      "p21val is 0.015133958226289\n",
      "pf12val is 0.491212761984214\n",
      "chi_f12 is 1.421755842496981\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 1.4974, -1.9644],\n",
      "        [ 2.6233, -2.6973],\n",
      "        [ 2.0375, -1.0182]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "34\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.418\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 58.704\n",
      "expected info is tensor([[0.0184]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 2.5522, -1.7991]], device='cuda:0')\n",
      "new data istensor([[0.1816, 0.0131]], device='cuda:0')\n",
      "g_theta2 istensor([[ 1.2208, -2.0740],\n",
      "        [ 1.7783, -2.8335],\n",
      "        [ 1.5642, -1.1421]], device='cuda:0')\n",
      "p21val is 0.959743474217622\n",
      "pf12val is 0.820755805711461\n",
      "chi_f12 is 0.395059297918683\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-2.9598,  2.7481],\n",
      "        [ 2.7159, -2.0933],\n",
      "        [ 2.5524, -1.7990]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "35\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.423\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 181.180\n",
      "expected info is tensor([[0.1134]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 2.4182, -1.3319]], device='cuda:0')\n",
      "new data istensor([[ 0.2139, -0.0572]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.8686,  2.8494],\n",
      "        [ 2.8878, -2.5178],\n",
      "        [ 2.9656, -2.5061]], device='cuda:0')\n",
      "p21val is 0.783739749916569\n",
      "pf12val is 0.947544677057031\n",
      "chi_f12 is 0.107762381140831\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.5740,  0.1584],\n",
      "        [ 0.5310, -2.4701],\n",
      "        [ 2.4182, -1.3320]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "36\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.436\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 65.663\n",
      "expected info is tensor([[0.0060]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 2.4195, -2.2457]], device='cuda:0')\n",
      "new data istensor([[ 0.1514, -0.0100]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.1931,  0.5608],\n",
      "        [ 0.2969, -2.4934],\n",
      "        [ 2.9546, -1.7944]], device='cuda:0')\n",
      "p21val is 0.869409565091342\n",
      "pf12val is 0.554515539525436\n",
      "chi_f12 is 1.179320896384523\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-0.7257,  2.9728],\n",
      "        [-1.9900,  0.7621],\n",
      "        [ 2.4195, -2.2457]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "37\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.466\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 25.104\n",
      "expected info is tensor([[0.0061]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 2.3983, -2.9787]], device='cuda:0')\n",
      "new data istensor([[0.0801, 0.0130]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.5824,  2.9127],\n",
      "        [-2.0894,  0.7321],\n",
      "        [ 2.8874, -1.7634]], device='cuda:0')\n",
      "p21val is 0.505587884186729\n",
      "pf12val is 0.854829106186561\n",
      "chi_f12 is 0.313707411656799\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 1.928457393773897e-13\n",
      "new 2 points\n",
      "tensor([[-0.3290, -2.5316],\n",
      "        [-1.8867,  1.8391],\n",
      "        [ 2.3983, -2.9787]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "38\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.471\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 59.761\n",
      "expected info is tensor([[0.0082]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 2.9791, -2.8294]], device='cuda:0')\n",
      "new data istensor([[0.1867, 0.0184]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.2142, -2.5929],\n",
      "        [-2.3839,  2.3042],\n",
      "        [ 1.9410, -2.5623]], device='cuda:0')\n",
      "p21val is 0.883923173041608\n",
      "pf12val is 0.742091143185039\n",
      "chi_f12 is 0.596566417754220\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.2733,  1.2216],\n",
      "        [ 0.2966, -1.8182],\n",
      "        [ 2.9790, -2.8294]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "39\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -2.461\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 133.633\n",
      "expected info is tensor([[0.0024]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 2.8183, -2.9738]], device='cuda:0')\n",
      "new data istensor([[0.1450, 0.0309]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.4569,  1.1263],\n",
      "        [ 0.0191, -2.2243],\n",
      "        [ 2.6019, -2.4367]], device='cuda:0')\n",
      "p21val is 0.558655181143890\n",
      "pf12val is 0.991527742127833\n",
      "chi_f12 is 0.017016702912493\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.8577,  2.3208],\n",
      "        [ 1.0454,  1.2075],\n",
      "        [ 2.8183, -2.9738]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "40\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.507\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 186.251\n",
      "expected info is tensor([[0.0241]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[ 3.0064, -2.9398]], device='cuda:0')\n",
      "new data istensor([[0.1535, 0.0085]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.6942,  2.3420],\n",
      "        [ 0.9823,  1.3923],\n",
      "        [ 2.4723, -2.6129]], device='cuda:0')\n",
      "p21val is 0.650901234931647\n",
      "pf12val is 0.465681857720648\n",
      "chi_f12 is 1.528505173524421\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.6191,  0.3085],\n",
      "        [ 2.8363, -1.6528],\n",
      "        [-1.4561,  2.1165]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "41\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.515\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 684.156\n",
      "expected info is tensor([[0.0089]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.4561,  2.1165]], device='cuda:0')\n",
      "new data istensor([[ 0.0057, -0.0175]], device='cuda:0')\n",
      "g_theta2 istensor([[-1.6551,  0.2192],\n",
      "        [ 2.5980, -2.0270],\n",
      "        [-1.9592,  1.6175]], device='cuda:0')\n",
      "p21val is 0.497809003371250\n",
      "pf12val is 0.291292011009793\n",
      "chi_f12 is 2.466858081387834\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 1.4965, -2.0215],\n",
      "        [ 2.7863, -1.7829],\n",
      "        [-1.4563,  2.1164]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "42\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.541\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 84.176\n",
      "expected info is tensor([[0.0055]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.9391,  2.5888]], device='cuda:0')\n",
      "new data istensor([[ 0.1035, -0.0950]], device='cuda:0')\n",
      "g_theta2 istensor([[ 1.1406, -2.3328],\n",
      "        [ 2.7847, -1.5095],\n",
      "        [-1.8658,  1.7339]], device='cuda:0')\n",
      "p21val is 0.557172117542604\n",
      "pf12val is 0.896061915650022\n",
      "chi_f12 is 0.219491532213376\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 2.5445, -2.3133],\n",
      "        [-0.7182,  1.6144],\n",
      "        [-0.9391,  2.5888]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "43\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.549\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 100.908\n",
      "expected info is tensor([[0.0055]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.6539,  2.0614]], device='cuda:0')\n",
      "new data istensor([[ 0.4364, -0.2867]], device='cuda:0')\n",
      "g_theta2 istensor([[ 2.7480, -1.7640],\n",
      "        [-1.1737,  1.0707],\n",
      "        [-0.4164,  2.9430]], device='cuda:0')\n",
      "p21val is 0.817203173210109\n",
      "pf12val is 0.331527966696239\n",
      "chi_f12 is 2.208086217646901\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.6138,  1.1130],\n",
      "        [-2.4780,  2.6864],\n",
      "        [-0.6537,  2.0615]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "44\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.569\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 250.264\n",
      "expected info is tensor([[0.0205]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-0.2307,  2.4044]], device='cuda:0')\n",
      "new data istensor([[ 0.3605, -0.3054]], device='cuda:0')\n",
      "g_theta2 istensor([[-2.0994,  0.4736],\n",
      "        [-2.9466,  2.5059],\n",
      "        [-1.1688,  1.6187]], device='cuda:0')\n",
      "p21val is 0.172037271618137\n",
      "pf12val is 0.507145769161148\n",
      "chi_f12 is 1.357913607153155\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.5134,  2.3982],\n",
      "        [ 2.3986, -2.5704],\n",
      "        [-0.2306,  2.4043]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "45\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.573\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 239.110\n",
      "expected info is tensor([[0.0012]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.2989, 1.7924]], device='cuda:0')\n",
      "new data istensor([[ 0.8833, -0.4466]], device='cuda:0')\n",
      "g_theta2 istensor([[-1.9515,  1.9614],\n",
      "        [ 2.4773, -2.5527],\n",
      "        [-0.7879,  2.9118]], device='cuda:0')\n",
      "p21val is 0.711232911085320\n",
      "pf12val is 0.324067591494764\n",
      "chi_f12 is 2.253606338444925\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.5889,  1.8927],\n",
      "        [ 1.2362, -1.0462],\n",
      "        [ 0.2989,  1.7924]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "46\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.573\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 347.833\n",
      "expected info is tensor([[0.0154]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.9699, 1.5855]], device='cuda:0')\n",
      "new data istensor([[ 0.5736, -0.1082]], device='cuda:0')\n",
      "g_theta2 istensor([[-1.8021,  2.2491],\n",
      "        [ 1.2995, -1.1113],\n",
      "        [ 0.2391,  2.3578]], device='cuda:0')\n",
      "p21val is 0.051811800422499\n",
      "pf12val is 0.938637294785731\n",
      "chi_f12 is 0.126652283856455\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-0.8462,  0.0106],\n",
      "        [ 1.6992,  1.4360],\n",
      "        [ 0.9698,  1.5855]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "47\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.603\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 48.392\n",
      "expected info is tensor([[0.7005]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[1.6918, 1.4329]], device='cuda:0')\n",
      "new data istensor([[0.3433, 0.0164]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.7951,  0.1171],\n",
      "        [ 2.2886,  0.9083],\n",
      "        [ 1.4175,  0.8709]], device='cuda:0')\n",
      "p21val is 0.824604859337194\n",
      "pf12val is 0.204327972030612\n",
      "chi_f12 is 3.176057740162731\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[2.6441, 2.1171],\n",
      "        [0.6675, 0.8935],\n",
      "        [1.6920, 1.4328]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "48\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.602\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 3.258\n",
      "expected info is tensor([[0.0256]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8124, 0.7129]], device='cuda:0')\n",
      "new data istensor([[0.3408, 0.3501]], device='cuda:0')\n",
      "g_theta2 istensor([[2.9105, 2.5890],\n",
      "        [0.0428, 0.5317],\n",
      "        [2.1584, 1.9397]], device='cuda:0')\n",
      "p21val is 0.170516869468377\n",
      "pf12val is 0.003335509772422\n",
      "chi_f12 is 11.406259511993836\n",
      "p_val_ftarget is 5.547231101954431e-05\n",
      "new 2 points\n",
      "tensor([[0.3338, 0.2378],\n",
      "        [1.5185, 1.1057],\n",
      "        [0.8123, 0.7128]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "49\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.286\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -3.316\n",
      "expected info is tensor([[0.0112]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.7997, 0.7108]], device='cuda:0')\n",
      "new data istensor([[0.3388, 0.3239]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.0325, -0.3653],\n",
      "        [ 1.3291,  1.3110],\n",
      "        [ 0.2494,  1.1943]], device='cuda:0')\n",
      "p21val is 0.000027158578801\n",
      "pf12val is 0.729325511093609\n",
      "chi_f12 is 0.631270258714937\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "49\n",
      "Using CUDA for conduct_design_opti()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss design: -3.348\n",
      "expected info is tensor([[0.0098]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.7975, 0.7122]], device='cuda:0')\n",
      "new data istensor([[0.3059, 0.3848]], device='cuda:0')\n",
      "g_theta2 istensor([[ 1.5212,  1.4699],\n",
      "        [-0.5026, -0.8331],\n",
      "        [ 0.2320,  1.2065]], device='cuda:0')\n",
      "p21val is 0.028118170499638\n",
      "pf12val is 0.023285356612004\n",
      "chi_f12 is 7.519861175138644\n",
      "p_val_ftarget is 0.014669382344132176\n",
      "new 2 points\n",
      "tensor([[-0.4220, -0.6590],\n",
      "        [-1.2498, -1.6434],\n",
      "        [ 0.7975,  0.7122]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "50\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.592\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -5.407\n",
      "expected info is tensor([[0.0026]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8442, 0.7047]], device='cuda:0')\n",
      "new data istensor([[0.3117, 0.3400]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.2464, -0.5776],\n",
      "        [-1.3651, -1.6389],\n",
      "        [ 0.3558,  1.3154]], device='cuda:0')\n",
      "p21val is 0.907413350751698\n",
      "pf12val is 0.880112749981687\n",
      "chi_f12 is 0.255410509475998\n",
      "p_val_ftarget is 0.09668936917453086\n",
      "new 2 points\n",
      "tensor([[0.3210, 0.0947],\n",
      "        [0.6846, 0.4570],\n",
      "        [0.8443, 0.7047]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "51\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.605\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -5.117\n",
      "expected info is tensor([[0.0035]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8380, 0.7200]], device='cuda:0')\n",
      "new data istensor([[0.3407, 0.3389]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.2264, -0.2851],\n",
      "        [ 0.1198, -0.1353],\n",
      "        [ 0.4040,  1.3756]], device='cuda:0')\n",
      "p21val is 0.007443743649088\n",
      "pf12val is 0.712414533855018\n",
      "chi_f12 is 0.678190653036783\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "51\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -5.097\n",
      "expected info is tensor([[0.0032]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8397, 0.7187]], device='cuda:0')\n",
      "new data istensor([[0.3231, 0.3060]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.3638, -0.7942],\n",
      "        [ 0.1465,  0.0476],\n",
      "        [ 0.4024,  1.3674]], device='cuda:0')\n",
      "p21val is 0.900867521799978\n",
      "pf12val is 0.537286110021917\n",
      "chi_f12 is 1.242449066040688\n",
      "p_val_ftarget is 0.047860423119942985\n",
      "new 2 points\n",
      "tensor([[0.3427, 0.6622],\n",
      "        [1.4134, 2.1657],\n",
      "        [0.8398, 0.7185]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "52\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.626\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -2.549\n",
      "expected info is tensor([[0.0023]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8670, 0.6856]], device='cuda:0')\n",
      "new data istensor([[0.3293, 0.3307]], device='cuda:0')\n",
      "g_theta2 istensor([[-0.1022,  1.0708],\n",
      "        [ 1.4699,  2.3836],\n",
      "        [ 0.2277,  1.1633]], device='cuda:0')\n",
      "p21val is 0.013214881526005\n",
      "pf12val is 0.858114033403484\n",
      "chi_f12 is 0.306036564521473\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0034834056830620463\n",
      "new 2 points\n",
      "tensor([[2.7004, 1.7783],\n",
      "        [1.2462, 1.0653],\n",
      "        [0.8669, 0.6855]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "53\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.628\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -3.974\n",
      "expected info is tensor([[0.0043]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8084, 0.7278]], device='cuda:0')\n",
      "new data istensor([[0.3220, 0.3476]], device='cuda:0')\n",
      "g_theta2 istensor([[2.2002, 1.2954],\n",
      "        [1.7770, 1.5375],\n",
      "        [1.2540, 0.4107]], device='cuda:0')\n",
      "p21val is 0.280534043142430\n",
      "pf12val is 0.789300485228990\n",
      "chi_f12 is 0.473216375018671\n",
      "p_val_ftarget is 0.00967124192018709\n",
      "new 2 points\n",
      "tensor([[1.8199, 1.3776],\n",
      "        [1.5669, 1.4559],\n",
      "        [0.8085, 0.7278]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "54\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.633\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -4.427\n",
      "expected info is tensor([[0.0005]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8300, 0.7113]], device='cuda:0')\n",
      "new data istensor([[0.3440, 0.3372]], device='cuda:0')\n",
      "g_theta2 istensor([[2.2167, 1.8950],\n",
      "        [2.1363, 2.1355],\n",
      "        [0.3026, 1.0542]], device='cuda:0')\n",
      "p21val is 0.398626265212306\n",
      "pf12val is 0.604261838849657\n",
      "chi_f12 is 1.007495333911092\n",
      "p_val_ftarget is 0.013098845181062968\n",
      "new 2 points\n",
      "tensor([[0.4183, 0.3491],\n",
      "        [0.9598, 0.7219],\n",
      "        [0.8300, 0.7114]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "55\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.631\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -4.117\n",
      "expected info is tensor([[0.0044]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8727, 0.6370]], device='cuda:0')\n",
      "new data istensor([[0.3291, 0.3251]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.0360, -0.0390],\n",
      "        [ 1.4065,  0.9253],\n",
      "        [ 0.8119,  1.2156]], device='cuda:0')\n",
      "p21val is 0.089813780409490\n",
      "pf12val is 0.870073254301208\n",
      "chi_f12 is 0.278355741063883\n",
      "p_val_ftarget is 0.01126119796223446\n",
      "new 2 points\n",
      "tensor([[0.1144, 0.0058],\n",
      "        [0.3600, 0.1157],\n",
      "        [0.8727, 0.6369]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "56\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.654\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -3.983\n",
      "expected info is tensor([[0.0029]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8236, 0.7167]], device='cuda:0')\n",
      "new data istensor([[0.3110, 0.3267]], device='cuda:0')\n",
      "g_theta2 istensor([[ 0.0016,  0.1379],\n",
      "        [ 0.1872, -0.0942],\n",
      "        [ 1.2661,  0.4729]], device='cuda:0')\n",
      "p21val is 0.083325463257939\n",
      "pf12val is 0.750764328073942\n",
      "chi_f12 is 0.573326974574475\n",
      "p_val_ftarget is 0.006405238518064071\n",
      "new 2 points\n",
      "tensor([[1.8209, 1.3541],\n",
      "        [2.0132, 1.8281],\n",
      "        [0.8235, 0.7168]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "57\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.598\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: -4.009\n",
      "expected info is tensor([[0.0027]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[0.8296, 0.7099]], device='cuda:0')\n",
      "new data istensor([[0.3663, 0.3465]], device='cuda:0')\n",
      "g_theta2 istensor([[2.2767, 1.6012],\n",
      "        [2.0917, 2.0376],\n",
      "        [0.3060, 0.7959]], device='cuda:0')\n",
      "p21val is 0.052797318409264\n",
      "pf12val is 0.120161659414494\n",
      "chi_f12 is 4.237834562041887\n",
      "p_val_ftarget is 0.005998887691285981\n",
      "new 2 points\n",
      "tensor([[1.4075, 0.7712],\n",
      "        [0.8009, 0.0734],\n",
      "        [0.8297, 0.7101]], device='cuda:0')\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "58\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.664\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     89\u001b[0m likelihood\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 92\u001b[0m x0_new,g_theta2, loss, pf1, Qf1, Qf12, data_fit, Q21 \u001b[38;5;241m=\u001b[39m \u001b[43mconduct_design_opti\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_theta1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magg_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_design\u001b[49m\u001b[43m,\u001b[49m\u001b[43miter_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnoise_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m cur_model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     95\u001b[0m cur_likelihood \u001b[38;5;241m=\u001b[39m likelihood\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mconduct_design_opti\u001b[0;34m(x0, loc_sample, f_target, g_theta1, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new, noise_value)\u001b[0m\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     41\u001b[0m loss2, pf1, Qf1, Qf12, data_fit, Q21 \u001b[38;5;241m=\u001b[39m likelihood\u001b[38;5;241m.\u001b[39mget_ell(agg_data,f_target,x_d, g_theta1, model, likelihood, g_theta2, cov_noise1, cov_noise2)\n\u001b[0;32m---> 43\u001b[0m loss2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss2\u001b[49m\n\u001b[1;32m     45\u001b[0m loss2\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loc_sample = loc_sample0.clone()\n",
    "iter_hp = 50\n",
    "iter_design = 200\n",
    "iter_param = 200\n",
    "num_base_kernels = 2\n",
    "max_iter = 50\n",
    "\n",
    "f_target = f_target.reshape(2,1) \n",
    "tol_vector = 0.01 * torch.ones(f_target.shape)\n",
    "\n",
    "plot_freq = 1\n",
    "\n",
    "\n",
    " #np.random.random_sample((loc_size,2))\n",
    "#loc_sample = (loc_sample - loc_sample.mean())/loc_sample.std(dim=-2, keepdim=True)\n",
    "#train_x = (train_x - train_x.mean())/train_x.std(dim=-2, keepdim=True)\n",
    "\n",
    "#loc_sample = Tensor([[0.0, 0.1], [0.0, -0.1]]) #T\n",
    "# loc_x = (-1.5 + 2.)  * np.random.random_sample((loc_size,1)) +2.\n",
    "\n",
    "# # loc_y = (2. - 1.5)  * np.random.random_sample((loc_size,1)) - 1.5\n",
    "# # loc = np.concatenate((loc_x, loc_y), 1)\n",
    "print(loc_sample)\n",
    "\n",
    "\n",
    "g_theta2_vec = (Tensor(loc_sample).clone()).flatten().to(device)\n",
    "\n",
    "data_fit_vec = torch.empty((1,1)).to(device)\n",
    "entropy_vec = torch.empty((1,1)).to(device)\n",
    "loss_vec = torch.empty((1,1)).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "vec_x = x0.clone() #Tensor(np.array([0.0,0.0])) \n",
    "vec_x = vec_x.reshape(1,2)\n",
    "var_vec = torch.zeros([max_iter, 1])\n",
    "p21_vec = torch.empty((1,1))\n",
    "\n",
    "lr_new = .01\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    "show_TTRBox = False\n",
    "iter = 0    \n",
    "g_theta1 = x_train\n",
    "agg_data = y_train.flatten()\n",
    "patience = 0.0\n",
    "patience_f = 0.0\n",
    "patience_2 = 0.0\n",
    "checking_model = False\n",
    "model_double_check = False\n",
    "\n",
    "\n",
    "\n",
    "while(SUCCESS == False and FAILURE == False):\n",
    "    print(iter)\n",
    "    model_double_check = False\n",
    "    if (checking_model == False):\n",
    "        print('START HYPERPARAMETERS optimization')\n",
    "        if (iter == 0):\n",
    "            cur_model = None\n",
    "            cur_likelihood = None\n",
    "\n",
    "\n",
    "        loc_sample_old = loc_sample.clone()\n",
    "        x0_old = x0.clone()\n",
    "        model, likelihood = hyper_opti(g_theta1,agg_data,iter_hp,num_base_kernels,noise_value, current_model = cur_model, current_likelihood = cur_likelihood)\n",
    "\n",
    "        \n",
    "# Before this is hyper_opti\n",
    "\n",
    "        print('END HYPERPARAMETERS optimization')\n",
    "    \n",
    "   \n",
    "\n",
    " #     model = model.cpu()\n",
    "#     likelihood = likelihood.cpu()\n",
    "#     g_theta1 = g_theta1.cpu()\n",
    "#     agg_data = agg_data.cpu()\n",
    "        \n",
    "#     \"\"\"end for CPU\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "   \n",
    "    \n",
    "    x0_new,g_theta2, loss, pf1, Qf1, Qf12, data_fit, Q21 = conduct_design_opti(x0, loc_sample, f_target, g_theta1, agg_data, model, likelihood, iter_design,iter_param, lr_new,noise_value)\n",
    "  \n",
    "    cur_model = model\n",
    "    cur_likelihood = likelihood\n",
    "    \n",
    "  \n",
    "    lower_bound = torch.zeros(pf1.shape)\n",
    "    upper_bound = torch.zeros(pf1.shape)\n",
    "        \n",
    "    for i in range(pf1.shape[0]):\n",
    "        lower_bound[i] = pf1[i] -  torch.sqrt(Qf12[i,i])\n",
    "        upper_bound[i] = pf1[i] +  torch.sqrt(Qf12[i,i])\n",
    "\n",
    "    SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "    \n",
    "    \n",
    "#     \"\"\"Put everything back to CPU here\"\"\"\n",
    "#     model = model.cpu()\n",
    "#     likelihood = likelihood.cpu()\n",
    "#     g_theta1 = g_theta1.cpu()\n",
    "#     agg_data = agg_data.cpu()\n",
    "    \n",
    "# #     cov_noise1 = cov_noise1.cpu()\n",
    "# #     cov_noise2 = cov_noise2.cpu()\n",
    "# #     g_theta1 = g_theta1.cuda()\n",
    "#     g_theta2 = g_theta2.cpu()\n",
    "# #     agg_data = agg_data.cuda()\n",
    "# #     x_d = x_d.cpu()\n",
    "#     f_target = f_target.cpu()\n",
    "    \n",
    "    \n",
    "#     x0_new, loss, pf1, Qf1, Qf12, data_fit, Q21 = x0_new.cpu(), loss.cpu(), pf1.cpu(), Qf1.cpu(),Qf12.cpu(),data_fit.cpu(),Q21.cpu()\n",
    "#     \"\"\"End of putting everything back to CPU\"\"\"\n",
    "    \n",
    "    entropy = ( 0.5 * torch.log( torch.det(Qf1.evaluate()) / torch.det(Qf12.evaluate()) ) ).reshape(1,1)\n",
    "    \n",
    "    print('expected info is '+str(entropy))\n",
    "    \n",
    "    if not SUCCESS:\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        new_data = vfield_(g_theta2.detach())  \n",
    "        agg_data12 = torch.cat([agg_data, new_data.flatten()], 0)\n",
    "        g_theta12= torch.cat([g_theta1, g_theta2.detach()], 0)\n",
    "        new_data_x = vfield_(x0_new.detach() )  \n",
    "        print('current sol is'+str(x0_new.detach()))\n",
    "        print('new data is' + str(new_data_x))\n",
    "        print('g_theta2 is' + str(g_theta2.detach()))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            \n",
    "            if iter >= 0:\n",
    "                \n",
    "                \n",
    "                p21 = likelihood.get_p21(g_theta1, g_theta2.detach(), agg_data, model, noise_value)\n",
    "                \n",
    "#                 Q21 = Q21 + noise_value*torch.eye(Q21.shape[0])\n",
    "                chi_21 = (Q21).inv_quad(new_data.flatten() - p21.reshape(new_data.flatten().shape)).cpu()\n",
    "                \n",
    "                p_val = 1. - stats.chi2.cdf(chi_21, Q21.shape[0])\n",
    "                pf12 = likelihood.get_pf12(Q21,g_theta1, g_theta2.detach(), x0_new.detach(), new_data.flatten(), pf1, p21, model, noise_value)\n",
    "               \n",
    "                eye = torch.eye(Qf12.shape[0]).to(device)\n",
    "                chi_f12 = (Qf12 + noise_value*eye).inv_quad(new_data_x.flatten() - pf12.reshape(new_data_x.flatten().shape)).cpu()\n",
    "                p_val_f12 = 1. - stats.chi2.cdf(chi_f12, Qf12.shape[0])\n",
    "                print('p21val is %.15f' %p_val)\n",
    "                p21_vec = torch.cat([p21_vec, Tensor([p_val]).reshape(1,1)], 0)\n",
    "                print('pf12val is %.15f' %p_val_f12)\n",
    "                print('chi_f12 is %.15f' %chi_f12 )\n",
    "                \n",
    "                if (p_val < 0.01):# or p_val_f12 < 0.001:\n",
    "                    model_double_check = True\n",
    "                    checking_model = True\n",
    "                    patience = patience+1\n",
    "                    print('patience is %.3f' %patience)\n",
    "\n",
    "                if (model_double_check == True):\n",
    "                    #loc_sample = Tensor(high_minus_low  * np.random.random_sample((loc_sample.shape[0],2)) + vf.low)\n",
    "                    sum = torch.zeros(2, 2).to(device) #replace with num_tasks\n",
    "                    mean_2 = torch.mean(g_theta2.detach(), 0, True)\n",
    "                    x0_old = x0_old.to(device)\n",
    "                    for i in range(loc_size):\n",
    "                        #sum =sum + torch.matmul((g_theta2.detach()[i] -mean_2).t(), ( g_theta2.detach()[i] - mean_2 ) )# sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) #sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) # \n",
    "                        sum =sum + torch.matmul((g_theta2.detach()[i] -x0_old).t(), (g_theta2.detach()[i] - x0_old) ) #sum + torch.matmul((g_theta2.detach()[i] -\n",
    "                    emp_cov = 1./loc_size * sum #+ torch.eye(sum.shape[0]) * 1e-8\n",
    "\n",
    "                    dis_2sample = MultivariateNormal( loc = x0_old, covariance_matrix=emp_cov )\n",
    "                    #loc_size = 4\n",
    "                    loc_sample = dis_2sample.sample((loc_size,))\n",
    "\n",
    "                    loc_sample = loc_sample.reshape(loc_size, 2)\n",
    "                    loc_sample = torch.cat([loc_sample, x0_old],0)\n",
    "                    \n",
    "                    x0 = x0_old #Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low)\n",
    "                    if (patience >= 2):# or patience_2 >= 2 or patience_f >= 2):\n",
    "                        PATH = \".//model_Carlo/model_update/model_base_\"+str(iter)+\".pt\"\n",
    "                        torch.save(model, PATH)\n",
    "                        \n",
    "                        entropy_vec = torch.cat([entropy_vec, entropy], 0)\n",
    "                        data_fit_vec = torch.cat([data_fit_vec, data_fit], 0)\n",
    "                        iter = iter + 1\n",
    "                        patience = 0\n",
    "#                         patience_2 = 0\n",
    "#                         patience_f = 0\n",
    "                        model_double_check = False\n",
    "                        checking_model = False\n",
    "                        num_base_kernels = num_base_kernels + 1\n",
    "                        print('adding complexity to model')\n",
    "                        print('num base is ' + str(num_base_kernels))\n",
    "#     #                         \n",
    "                        loc_sample = loc_sample_old\n",
    "                        #x0 = x0_old\n",
    "                        agg_data = agg_data12.clone()\n",
    "                        g_theta1 = g_theta12.clone()\n",
    "                        vec_x = torch.cat([vec_x.to(device), x0_new.detach()])\n",
    "                        g_theta2_vec = torch.cat([g_theta2_vec, g_theta2.detach().flatten()], 0)\n",
    "                        print('acquiring 2, new size is ' + str(g_theta1.shape[0]))\n",
    "                 \n",
    "                    #iter_hp = iter_hp + 10\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                else:\n",
    "                    PATH = \".//model_Carlo/model_goodmodel/model_base_\"+str(iter)+\".pt\"\n",
    "                    torch.save(model, PATH)\n",
    "                    vec_x = torch.cat([vec_x.to(device), x0_new.detach()])\n",
    "                    loss_vec = torch.cat([loss_vec, -loss])\n",
    "                    g_theta2_vec = torch.cat([g_theta2_vec, g_theta2.detach().flatten()], 0)\n",
    "                    entropy_vec = torch.cat([entropy_vec, entropy], 0)\n",
    "                    data_fit_vec = torch.cat([data_fit_vec, data_fit], 0)\n",
    "                    model_double_check = False\n",
    "                    iter = iter + 1\n",
    "                    patience = 0\n",
    "                    patience_2 = 0\n",
    "                    patience_f = 0\n",
    "                    checking_model = False\n",
    "                    if (entropy < 1e-4 * tol_vector[0,0]):\n",
    "                        FAILURE = True\n",
    "                    \n",
    "                    x0 = (x0_new.detach())# + torch.randn(x0_new.detach().size()) * .001)#/torch.norm(x0_new.detach())\n",
    "                    sum = torch.zeros(2, 2).to(device)\n",
    "                    mean_2 = torch.mean(g_theta2.detach(), 0, True)\n",
    "\n",
    "                    for i in range(loc_size):\n",
    "                        #sum =sum + torch.matmul((g_theta2.detach()[i] -mean_2).t(), ( g_theta2.detach()[i] - mean_2 ) )# sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) #sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) # \n",
    "                        sum =sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) #sum + torch.matmul((g_theta2.detach()[i] -\n",
    "                    emp_cov = 1./loc_size * sum# + torch.eye(sum.shape[0]) * 1e-8\n",
    "\n",
    "                    dis_2sample = MultivariateNormal( loc = x0_new.detach(), covariance_matrix=emp_cov )\n",
    "                    #loc_size = 4\n",
    "                    loc_sample = dis_2sample.sample((loc_size,))\n",
    "\n",
    "                    loc_sample = loc_sample.reshape(loc_size, 2)\n",
    "                    #loc_sample = loc_sample#/torch.norm(loc_sample)\n",
    "                    #loc_sample = 2. *  (loc_sample - torch.min(loc_sample)) / (torch.max(loc_sample) - torch.min(loc_sample)) - 1.\n",
    "                    #loc_sample[0] = x0_new.detach() #+ torch.randn(x0_new.detach().size()) * .001 #g_theta2.detach() #loc_sample.reshape(loc_size, 2)\n",
    "                    #loc_sample = Tensor(high_minus_low  * np.random.random_sample((loc_size,2)) + vf.low)\n",
    "                    loc_sample = torch.cat([loc_sample, x0_new.detach()],0)\n",
    "                    for i in range(loc_sample.shape[0]):\n",
    "                        if loc_sample[i,0] < -3. or loc_sample[i,0] > 3. or loc_sample[i,1] < -3. or loc_sample[i,1] > 3.:\n",
    "                            print('samples escaped box')\n",
    "                            loc_sample[i] = Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low)\n",
    "                    \n",
    "                    \n",
    "#                     if p_val > 0.99 and p_val_f12 > 0.99:\n",
    "#                         num_base_kernels = max(num_base_kernels - 1, 3)\n",
    "                        #iter_hp = iter_hp - 10\n",
    "                    chi_f_target = (Qf12 ).inv_quad(f_target.to(device) - pf1).cpu()\n",
    "                    p_val_f_target = 1. - stats.chi2.cdf(chi_f_target, Qf12.shape[0])\n",
    "                    print('p_val_ftarget is '+str(p_val_f_target))\n",
    "                    if (p_val_f_target > .95):\n",
    "                        print('acquiring target point becuse p_val_ftarget is '+str(p_val_f_target))\n",
    "                        agg_data = agg_data12.clone()\n",
    "                        g_theta1 = g_theta12.clone()\n",
    "        \n",
    "\n",
    "                        x0 = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .0001\n",
    "                        loc_sample[-1] = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .0001\n",
    "                        agg_data = torch.cat([agg_data12, new_data_x.flatten()], 0)\n",
    "                        g_theta1= torch.cat([g_theta12, x0_new.detach()], 0)\n",
    "                    else:\n",
    "#                         x0 = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .001\n",
    "#                         loc_sample[-1] = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .001\n",
    "#                         agg_data = torch.cat([agg_data12, new_data_x.flatten()], 0)\n",
    "#                         g_theta1= torch.cat([g_theta12, x0_new.detach()], 0)\n",
    "                       \n",
    "                        agg_data = agg_data12.clone()\n",
    "                        g_theta1 = g_theta12.clone()\n",
    "                        x0 = (x0_new.detach()) + torch.randn(x0_new.detach().size()).to(device) * .0001\n",
    "                        loc_sample[-1] = (x0_new.detach()) + torch.randn(x0_new.detach().size()).to(device) * .0001\n",
    "                        agg_data = torch.cat([agg_data12, new_data_x.flatten()], 0)\n",
    "                        g_theta1= torch.cat([g_theta12, x0_new.detach()], 0)\n",
    "                        \n",
    "                    if x0_new.detach()[0,0] < -3. or x0_new.detach()[0,0] > 3. or x0_new.detach()[0,1] < -3. or x0_new.detach()[0,1] > 3.:\n",
    "#                         x0 = Tensor(np.array([0.0,-1.0])) # 1./3. * Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "#                         x0 = x0.reshape(1,2) \n",
    "                        #x0 = Tensor(np.array([-2. , 2.]))\n",
    " # 1./3. * Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "                        x0 = Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "                        x0 = x0.reshape(1,2)\n",
    "                        #x0 = Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "                 \n",
    "             #       loc_sample = (loc_sample - loc_sample.mean())/loc_sample.std(dim=-2, keepdim=True)\n",
    "                        loc_sample[-1] = x0 #(x0_new.detach()) \n",
    "                    print('new 2 points')\n",
    "                    print(loc_sample)\n",
    "                  \n",
    " #                    agg_data  = (agg_data  - agg_data.mean())/agg_data .std(dim=-1, keepdim=True)\n",
    "#                     g_theta1 = (g_theta1 - g_theta1.mean())/g_theta1.std(dim=-2, keepdim=True)\n",
    "        \n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "            \n",
    "            #clear_output(wait=False)\n",
    "           \n",
    "        print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "vec_x = torch.cat([vec_x, x0_new.detach()])\n",
    "g_theta2_vec = torch.cat([g_theta2_vec, g_theta2.detach().flatten()], 0)\n",
    "entropy_vec = torch.cat([entropy_vec, entropy], 0)\n",
    "data_fit_vec = torch.cat([data_fit_vec, data_fit], 0)\n",
    "PATH = \".//model_Carlo/model_goodmodel/model_base_\"+str(iter)+\".pt\"\n",
    "torch.save(model, PATH)\n",
    "print('current sol is'+str(x0_new.detach()))\n",
    "    \n",
    "print('Success is ' + str(SUCCESS) + ' and failure is ' + str(FAILURE)+' after '+ str(iter) + ' iterations')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target - 0.001)\n",
    "print(f_target + 0.001)\n",
    "print(pf1)\n",
    "print(num_base_kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting model validation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "#plt.rcParams[\"pdf.use14corefonts\"] = True\n",
    "data_fit_vec_plot = 0.5* data_fit_vec.detach()[1:]\n",
    "entropy_vec_plot = entropy_vec.detach()[1:]\n",
    "p21_vec_plot = p21_vec.detach()[1:]\n",
    "f, ax = plt.subplots(1, 1, figsize=(14, 14))\n",
    "#ax.plot(np.array(range(2,iter+2)), torch.log(entropy_vec_plot), '+-')\n",
    "#print(p21_vec_plot)\n",
    "ax.plot(p21_vec_plot,'s',color = 'blue', markersize=6)\n",
    "ax.axhline(.01,linestyle = '--',color = 'red', markersize=12, alpha = 1.0)\n",
    "ax.set_xlim(-0.3, p21_vec_plot.shape[0])\n",
    "ax.set_ylim(-0.3, 1.)\n",
    "#ax.set_yscale('log')\n",
    "plt.xticks(np.arange(0, iter+7, step=5.))\n",
    "ax.tick_params(labelsize='small', width=3)\n",
    "ax.set_xlabel('# of Model Checks')\n",
    "ax.set_ylabel('p-value')\n",
    "ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.05, 0.03), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(1.2,        #x start point\n",
    "             -0.25,                      #y start point\n",
    "             0,       #change in x \n",
    "             0.2,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black')             #arrow edge color\n",
    "\n",
    "ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.02, 0.4), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(0.1,        #x start point\n",
    "             0.23,                      #y start point\n",
    "             0,       #change in x \n",
    "             -0.16,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black') \n",
    "\n",
    "\n",
    "############################\n",
    "ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.26, 0.34), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(6.2,        #x start point\n",
    "             0.14,                      #y start point\n",
    "             0,       #change in x \n",
    "             -0.07,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black') \n",
    "\n",
    "\n",
    "\n",
    "ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.29, 0.03), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(7.2,        #x start point\n",
    "             -0.25,                      #y start point\n",
    "             0,       #change in x \n",
    "             0.2,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black')             #arrow edge color\n",
    "\n",
    "############################\n",
    "ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.57, 0.4), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(14.15,        #x start point\n",
    "             0.23,                      #y start point\n",
    "             0,       #change in x \n",
    "             -0.16,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black') \n",
    "################################\n",
    "\n",
    "\n",
    "############################\n",
    "ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.69, 0.4), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(17.18,        #x start point\n",
    "             0.23,                      #y start point\n",
    "             0,       #change in x \n",
    "             -0.16,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black') \n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "# ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.32, 0.03), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(10.25,        #x start point\n",
    "#              -0.25,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              0.2,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black')             #arrow edge color\n",
    "\n",
    "# ############################\n",
    "\n",
    "# ############################\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.33, 0.34), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(11.25,        #x start point\n",
    "#              0.14,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.07,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# #################################################\n",
    "\n",
    "# ################################\n",
    "\n",
    "\n",
    "# ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.38, 0.1), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(12.25,        #x start point\n",
    "#              -0.15,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              0.1,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black')             #arrow edge color\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.38, 0.4), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(13.25,        #x start point\n",
    "#              0.23,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.16,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# ################################\n",
    "\n",
    "\n",
    "# ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.55, 0.03), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(18.25,        #x start point\n",
    "#              -0.25,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              0.2,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black')  \n",
    "# ################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.49, 0.4), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(17.25,        #x start point\n",
    "#              0.23,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.16,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# ################################\n",
    "\n",
    "# ################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.55, 0.43), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(19.25,        #x start point\n",
    "#              0.26,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.19,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# ################################\n",
    "\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.94, 0.43), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(33.25,        #x start point\n",
    "#              0.26,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.19,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# ################################\n",
    "\n",
    "\n",
    "# ################################\n",
    "\n",
    "ax.annotate('Threshold Line ($y = 0.01$)', xy=(1.0,0.01), xytext=(6,0), color='red', \n",
    "                xycoords = ax.get_yaxis_transform(), textcoords=\"offset points\",\n",
    "                size=14, va=\"center\")\n",
    "\n",
    "\n",
    "#ax.legend(['p-value'], loc = 'upper left', fontsize = 30)\n",
    "plt.savefig('figures_Carlo/qvalue_base.pdf',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting expected value and data fit term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "data_fit_vec_plot = 0.5* data_fit_vec.detach()[1:]\n",
    "entropy_vec_plot = entropy_vec.detach()[1:]\n",
    "f, (ax1,ax2) = plt.subplots(1, 2, figsize=(18, 8), tight_layout=True)\n",
    "\n",
    "ax1.plot(np.array(range(1,iter+2)), (entropy_vec_plot), '--o', color = 'blue', markersize=12)\n",
    "#ax1.set_yscale('log')\n",
    "# ax.plot(np.array(data_fit_vec_plot), (entropy_vec_plot), 'o')\n",
    "#ax1.set_yscale('log')\n",
    "\n",
    "ax2.plot(np.array(range(1,iter+2)), data_fit_vec_plot, '--o', color = 'red', markersize=12)\n",
    "#ax2.set_ylim(-10, 600)\n",
    "ax1.set_xlabel('Iteration #', size=32)\n",
    "ax2.set_xlabel('Iteration #', size=32)\n",
    "ax1.set_ylabel('Expected Information', size = 32)\n",
    "ax2.set_ylabel('Log-Gaussian Term', size = 32)\n",
    "ax1.set_xticks(np.arange(0, iter+3, step=3.))\n",
    "ax2.set_xticks(np.arange(0, iter+3, step=3.))\n",
    "plt.savefig('figures_Carlo/exp_info/expectedinfo_vs_datafit_2_base.pdf',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving all data needed for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data_plots/vec_x_success_base.txt',vec_x.detach().numpy())\n",
    "np.savetxt('data_plots/g_theta2_success_base.txt', g_theta2.detach().numpy())\n",
    "np.savetxt('data_plots/g_theta1_success_base.txt', g_theta1.detach().numpy())\n",
    "np.savetxt('data_plots/x_train_ini_success_base.txt', x_train.detach().numpy())\n",
    "np.savetxt('data_plots/y_train_ini_success_base.txt', y_train.detach().numpy())\n",
    "np.savetxt('data_plots/entropy_vec_success_base.txt', entropy_vec_plot.detach().numpy())\n",
    "np.savetxt('data_plots/datafit_success_base.txt', data_fit_vec_plot.detach().numpy())\n",
    "np.savetxt('data_plots/p21_vec_success_base.txt',p21_vec_plot.detach().numpy())\n",
    "np.savetxt('data_plots/loss_success_base.txt',loss.detach().numpy())\n",
    "np.savetxt('data_plots/pf1_success_base.txt',pf1.detach().numpy())\n",
    "np.savetxt('data_plots/Qf1_success_base.txt',Qf1.evaluate().detach().numpy())\n",
    "np.savetxt('data_plots/Qf12_success_base.txt', Qf12.evaluate().detach().numpy())\n",
    "np.savetxt( 'data_plots/Q21_success_base.txt', Q21.evaluate().detach().numpy())\n",
    "#np.savetxt('data_plots/iter_success.txt', iter+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = g_theta2_vec.reshape(math.ceil(g_theta2_vec.shape[0]/2),2)\n",
    "torch.save(v2, 'data_plots/v2_success_base.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "ax.set_xlim(-3.1, 3.2)\n",
    "ax.set_ylim(-3.1, 3.2)\n",
    "#ax.scatter(g_theta1[:, 0].detach(),g_theta1[:, 1].detach(), c=\"b\", alpha=0.8)\n",
    "ax.plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'blue',markersize=15, alpha = 0.2)\n",
    "ax.plot(vec_x[-1,0], vec_x[-1,1],'v', color = 'red',markersize=15)\n",
    "ax.plot(0.8731, 0.5664,'gd', color = 'green',markersize=15)\n",
    "ax.set_title('Final TAD configuration', fontsize = 40)\n",
    "ax.set_xlabel('$d_1$')\n",
    "ax.set_ylabel('$d_2$')\n",
    "ax.legend(['1-points', 'TAD solution', 'Target'])\n",
    "plt.savefig('figures_Carlo/strategies/tad_sol_all_2_base.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec_x = vec_x.detach()\n",
    "#v2 = g_theta2_vec.reshape(math.ceil(g_theta2_vec.shape[0]/2), 2)\n",
    "ii = 0\n",
    "low = -3.2\n",
    "high = 3.2\n",
    "########################\n",
    "f, ax = plt.subplots(1, 1, figsize=(14, 14))\n",
    "ax.plot(0.8731, 0.5664,'d', color = 'green',markersize=15)\n",
    "ax.plot(vec_x[ii,0], vec_x[ii,1],'v', color = 'red',markersize=15)\n",
    "ax.plot(x_train.detach()[:,0], x_train.detach()[:,1], 's', color = 'black', markersize=15, alpha = 0.2)\n",
    "ax.plot(v2.detach()[ii:ii+loc_size+1,0], v2.detach()[ii:ii+loc_size+1,1], 'o', color = 'blue', markersize=15)\n",
    "ax.set_xlabel('$d_1$')\n",
    "ax.set_ylabel('$d_2$')\n",
    "ax.set_title('Initial Configuration', fontsize = 40)\n",
    "ax.legend(['Target', 'Initial Target Candidate', 'Initial 1-sample','Initial 2-sample'])\n",
    "\n",
    "ax.set_xlim(low, high)\n",
    "ax.set_ylim(low, high)\n",
    "plt.savefig('figures_Carlo/evol_solTAD/evol_sol_ini_2_base.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_x = vec_x.detach()\n",
    "v2 = g_theta2_vec.reshape(math.ceil(g_theta2_vec.shape[0]/2), 2)\n",
    "\n",
    "low = -3.2\n",
    "high = 3.2\n",
    "#for iter_plt in range(1,iter):\n",
    "iter_plt = 13\n",
    "ii = 3 + (iter_plt - 1) * (loc_size + 1)\n",
    "#######################\n",
    "\n",
    " \n",
    "###########\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(14,14))\n",
    "\n",
    "#ax.plot(x_train.detach()[:,0], x_train.detach()[:,1], 'bv', markersize=8)\n",
    "for i in range(1, iter_plt):\n",
    "    ax.plot(vec_x[i-1:i,0], vec_x[i-1:i,1],'v', color = 'red', markersize=15, alpha=0.2, label = '_nolegend_')\n",
    "    \n",
    "ax.plot(vec_x[0:iter_plt,0], vec_x[0:iter_plt,1],'v', color = 'red', markersize=15, linewidth=15, alpha= 0.2)\n",
    "#ax.plot(g_theta1.detach()[:,0], g_theta.detach()[:,1], 'bv', markersize=8)\n",
    "ax.plot(v2.detach()[0:ii,0], v2.detach()[0:ii,1], 's', color = 'blue', markersize=15,alpha=0.2)\n",
    "ax.plot(x_train.detach()[:,0], x_train.detach()[:,1], 's', color = 'black', markersize=15, alpha = 0.2)\n",
    "ax.plot(v2.detach()[ii:ii+loc_size+1,0], v2.detach()[ii:ii+loc_size+1,1], 'o',color = 'blue' , markersize=15)\n",
    "ax.plot(0.8731, 0.5664,'gd',markersize=15)\n",
    "ax.plot(vec_x[iter_plt,0], vec_x[iter_plt,1],'v', color = 'red',markersize=15)\n",
    "ax.set_xlabel('$d_1$')\n",
    "ax.set_ylabel('$d_2$')\n",
    "#ax.set_title('Iteration '+str(iter_plt), fontsize = 40)\n",
    "ax.set_title('Final Configuration')\n",
    "ax.legend([ 'Previous Target Candidates', 'Previous 2-samples', 'Initial 1-sample','Current 2-sample', 'Target', 'Current Target Candidate'], fontsize = 30)\n",
    "\n",
    "ax.set_xlim(low, high)\n",
    "ax.set_ylim(low, high)\n",
    "plt.savefig('figures_Carlo/evol_solTAD/evol_sol_base'+str(iter_plt)+'_final.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta2_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_design_pll(x0,f_target, g_theta1, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new,noise_value):\n",
    "\n",
    "    #g_theta2 = nn.Parameter(Tensor(loc_sample))\n",
    "\n",
    "    x_d= nn.Parameter(Tensor(x0))\n",
    "    \n",
    "    optimizer = torch.optim.Adam([{'params': x_d, 'lr': 0.001}])\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    \n",
    "    for ii in range( training_param_iter ):\n",
    "#         x_d = torch.cat([x_d_0, x_d_1]).reshape(1,2)\n",
    "#         g_theta2 = torch.cat([g_theta20, g_theta21],1)\n",
    "        optimizer.zero_grad()\n",
    "        #print(g_theta)\n",
    "        loss2,lower_bound, upper_bound = likelihood.get_pll(f_target,x_d, g_theta1, agg_data, model, likelihood, noise_value)\n",
    "        loss2 = -1. * loss2\n",
    "        \n",
    "        loss2.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    loss2,lower_bound, upper_bound = likelihood.get_pll(f_target,x_d, g_theta1, agg_data, model, likelihood ,noise_value)\n",
    "    #loss2 = -1. * loss2\n",
    "    print('Loss design: %.3f' % ( loss2))\n",
    "   # print(optimizer.state_dict())\n",
    "    print(x_d)\n",
    "    return x_d, lower_bound, upper_bound\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(vf.low, vf.high, 15)\n",
    "y_plot = np.linspace(vf.low, vf.high, 15)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat = torch.zeros(n * n, 2)\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "\n",
    "g_theta_grid = x_concat\n",
    "agg_data1_grid = vfield_(g_theta_grid)\n",
    "agg_data1_grid = agg_data1_grid.flatten()\n",
    "\n",
    "\n",
    "x0 = Tensor(np.array([-2.,2.])) \n",
    "x0 = x0.reshape(1,2)\n",
    "x00 = x0 \n",
    "vec_x_grid = Tensor(np.array([0.0,0.0])) \n",
    "vec_x_grid = vec_x_grid.reshape(1,2)\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    " \n",
    "tol = 0.009 \n",
    "print('START HYPERPARAMETERS optimization')\n",
    "model_grid, likelihood_grid = hyper_opti(g_theta_grid,agg_data1_grid,iter_hp,num_base_kernels,noise_value)\n",
    "\n",
    "print('END HYPERPARAMETERS optimization')\n",
    "model_grid.eval()\n",
    "likelihood_grid.eval()\n",
    "x0_new_grid,lower_bound, upper_bound = conduct_design_pll(x0,f_target, g_theta_grid, agg_data1_grid, model_grid, likelihood_grid, iter_design, iter_param, lr_new,noise_value)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target-tol_vector)\n",
    "print(f_target+tol_vector)\n",
    "#loc_sample = np.random.random_sample((loc_size_rdn,2))\n",
    "\n",
    "\n",
    "SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(x0_new_grid)\n",
    "print(SUCCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_grid = x0_new.detach()\n",
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "ax.plot(x_concat[:,0],x_concat[:,1], 's', color = 'blue', markersize=15, alpha = 0.2)\n",
    "ax.plot(x0_new_grid.detach()[0,0], x0_new_grid.detach()[0,1],'v',color = 'red',markersize=15)\n",
    "ax.plot(0.8731, 0.5664,'d', color = 'green',markersize=15)\n",
    "\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.set_xlabel('$d_1$')\n",
    "ax.set_ylabel('$d_2$')\n",
    "ax.set_title('Grid Solution', fontsize = 40)\n",
    "\n",
    "plt.savefig('figures_Carlo/strategies/grid_sol_2_base.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_hp = 30\n",
    "# iter_design = 40 \n",
    "# iter_param = 50\n",
    "# num_base_kernels = 3\n",
    "\n",
    "# f_target = Tensor(vf.tgt_vec) \n",
    "# f_target = f_target.reshape(f_target.shape[0],1) \n",
    "# tol_vector = 0.005 * torch.ones(f_target.shape)\n",
    "\n",
    "\n",
    "loc_size_rdn = math.ceil(g_theta1.shape[0]) #(iter)*(loc_size+1) + sample_size\n",
    "\n",
    "loc_sample = high_minus_low  * np.random.random_sample((loc_size_rdn,2)) + vf.low #np.random.random_sample((loc_size_rdn,2))\n",
    "g_theta_ = (Tensor(loc_sample).clone())\n",
    "agg_data1 = vfield_(g_theta_)\n",
    "agg_data1 = agg_data1.flatten()\n",
    "\n",
    "\n",
    "x0 = Tensor(np.array([-2.0,2.0])) \n",
    "x0 = x0.reshape(1,2)\n",
    "x00 = x0 \n",
    "vec_x_rdn = Tensor(np.array([0.,0.])) \n",
    "vec_x_rdn = vec_x_rdn.reshape(1,2)\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    " \n",
    "tol = 0.009 \n",
    "print('START HYPERPARAMETERS optimization')\n",
    "\n",
    "model_rdn, likelihood_rdn = hyper_opti(g_theta_,agg_data1,iter_hp,num_base_kernels,noise_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('END HYPERPARAMETERS optimization')\n",
    "model_rdn.eval()\n",
    "likelihood_rdn.eval()\n",
    "x0_new_rdn,lower_bound, upper_bound = conduct_design_pll(x0,f_target, g_theta_, agg_data1, model_rdn, likelihood_rdn, iter_design, iter_param, lr_new, noise_value)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target-tol_vector)\n",
    "print(f_target+tol_vector)\n",
    "loc_sample = np.random.random_sample((loc_size_rdn,2))\n",
    "\n",
    "\n",
    "SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(x0_new_rdn)\n",
    "print(SUCCESS)\n",
    "sol_rdn = x0_new_rdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data_plots/sol_rdn_success_base.txt', sol_rdn.detach().numpy())\n",
    "np.savetxt('data_plots/sol_grid_success_base.txt', x0_new_grid.detach().numpy())\n",
    "np.savetxt('data_plots/g_theta_rdn_success_base.txt', g_theta_.detach().numpy())\n",
    "#np.savetxt('data_plots/g_theta_grid_success.txt', x_concat.detach().numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "\n",
    "ax.plot(g_theta_[:,0].detach(),g_theta_[:,1].detach(), 's', color = 'blue',markersize=15, alpha = 0.2)\n",
    "ax.plot(sol_rdn.detach()[0,0], sol_rdn.detach()[0,1],'v', color = 'red',markersize=15)\n",
    "ax.plot(0.8731, 0.5664,'d', color = 'green',markersize=15)\n",
    "\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.set_xlabel('$d_1$', fontsize = 32)\n",
    "ax.set_ylabel('$d_2$', fontsize = 32)\n",
    "ax.set_title('Uniformly Random Solution', fontsize = 40)\n",
    "\n",
    "plt.savefig('figures_Carlo/strategies/rdn_sol_2_base.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualizing Means and Variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker\n",
    "class OOMFormatter(matplotlib.ticker.ScalarFormatter):\n",
    "    def __init__(self, order=0, fformat=\"%1.1f\", offset=True, mathText=True):\n",
    "        self.oom = order\n",
    "        self.fformat = fformat\n",
    "        matplotlib.ticker.ScalarFormatter.__init__(self,useOffset=offset,useMathText=mathText)\n",
    "    def _set_order_of_magnitude(self):\n",
    "        self.orderOfMagnitude = self.oom\n",
    "    def _set_format(self, vmin=None, vmax=None):\n",
    "        self.format = self.fformat\n",
    "        if self._useMathText:\n",
    "             self.format = r'$\\mathdefault{%s}$' % self.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_target = vf.tgt_vec\n",
    "f_target = f_target.reshape(f_target.shape[0],1)\n",
    "vf.tgt_loc = vf.tgt_loc.reshape(2,1)\n",
    "#x0 = Tensor(np.array([0.1937, 0.1257]))\n",
    "#x0 = Tensor(np.array([0.1885, 0.1038]))\n",
    "x_plot = np.linspace(-3.5, 3.5, 100)\n",
    "y_plot = np.linspace(-3.5, 3.5, 100)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat_ = torch.zeros(n * n, 2)\n",
    "\n",
    "# n_sample = x_concat_.shape[0]\n",
    "num_tasks = 2\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "    \n",
    "\n",
    "tgt_plot = vfield_(x_concat_)\n",
    "\n",
    "\n",
    "\n",
    "v_1 = tgt_plot[:,0].reshape(n,n)\n",
    "v_2 = tgt_plot[:,1].reshape(n,n)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "likelihood.eval()\n",
    "\n",
    "#noise = torch.eye(2 * g_theta1.detach().shape[0]) * noise_value\n",
    "#print(x_concat_)\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(True):\n",
    "    pred = GPprediction(model)\n",
    "    pr_mean, cov = pred.GPpred(g_theta1.detach(), agg_data, x_concat_, noise_value)\n",
    "    #pr = (model(g_theta1.detach())) # likelihood(model(x_concat_), noise = torch.ones(x_concat_.shape) * noise_value)#\n",
    "    pr_mean = pr_mean.reshape(x_concat_.shape[0], num_tasks)\n",
    "    mean_v_1 = pr_mean[:,0].reshape(n,n)\n",
    "    mean_v_2 = pr_mean[:,1].reshape(n,n)\n",
    "    pred_var = cov.diag().reshape(num_tasks, x_concat_.shape[0]).T\n",
    "    \n",
    "    var_v_1 = pred_var[:,0].reshape(n,n)\n",
    "    var_v_2 = pred_var[:,1].reshape(n,n)\n",
    "#     AA = pr.covariance_matrix.mean(axis=0).reshape(num_tasks, x_concat_.shape[0]).T #.diag() #.reshape(num_tasks, num_tasks * g_theta1.shape[0]).T\n",
    "\n",
    "# #     print(pr.covariance_matrix.mean(axis=0))\n",
    "# #     print(AA)\n",
    "# #     print(pr.variance)\n",
    "# #     print((pr.covariance_matrix))\n",
    "# #     K = model.covar_module\n",
    "#     print((cov.diag()))\n",
    "#     print(pr_mean)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 2, figsize = (28, 24), tight_layout=True)\n",
    "diff_mean_v1= torch.abs(v_1 - mean_v_1.detach())#/torch.abs(v_1)\n",
    "cs10 = ax1[0].contourf(xv_plot, yv_plot,diff_mean_v1 ,np.linspace(0, 1.1, 100), cmap = 'jet')\n",
    "ax1[0].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "ax1[0].plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "ax1[0].set_title('$|v_1 - \\mu(v_1)|$', fontsize = 40)\n",
    "cbar10 = fig.colorbar(cs10, ax = ax1[0],format=OOMFormatter(0, mathText=False));\n",
    "\n",
    "ax1[0].set_xlabel('$d_1$')\n",
    "ax1[0].set_ylabel('$d_2$')\n",
    "diff_mean_v1 = torch.abs(v_1 - mean_v_1.detach())/torch.sqrt(var_v_1)\n",
    "#print(var_v_1)\n",
    "cs11 = ax1[1].contourf(xv_plot, yv_plot,diff_mean_v1 ,np.linspace(diff_mean_v1.min(), diff_mean_v1.max(), 100), cmap = 'jet')\n",
    "ax1[1].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "ax1[1].plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "ax1[1].set_title('$|v_1 - \\mu(v_1)|/\\sigma(v_1)$', fontsize = 40)\n",
    "# ax1[0].set_aspect('equal')\n",
    "# ax1[1].set_aspect('equal')\n",
    "cbar11 = fig.colorbar(cs11, ax = ax1[1],format=OOMFormatter(0, mathText=False));\n",
    "ax1[1].set_xlabel('$d_1$')\n",
    "ax1[1].set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "diff_mean_v2= torch.abs(v_2 - mean_v_2.detach())\n",
    "cs20 = ax2[0].contourf(xv_plot, yv_plot, diff_mean_v2,np.linspace(0, 1.1, 100), cmap = 'jet')\n",
    "ax2[0].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "ax2[0].plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "ax2[0].set_title('$|v_2 - \\mu(v_2)|$', fontsize = 40)\n",
    "cbar20 = fig.colorbar(cs20, ax = ax2[0],format=OOMFormatter(0, mathText=False));\n",
    "ax2[0].set_xlabel('$d_1$')\n",
    "ax2[0].set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "diff_mean_v2= torch.abs(v_2 - mean_v_2.detach())/torch.sqrt(var_v_2)\n",
    "cs21 = ax2[1].contourf(xv_plot, yv_plot, diff_mean_v2,np.linspace(diff_mean_v2.min(), diff_mean_v2.max(), 100), cmap = 'jet')\n",
    "ax2[1].plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "ax2[1].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "ax2[1].set_title('$|v_2 - \\mu(v_2)|/\\sigma(v_2)$', fontsize = 40)\n",
    "cbar21 = fig.colorbar(cs21, ax = ax2[1],format=OOMFormatter(0, mathText=False));\n",
    "ax2[1].set_xlabel('$d_1$')\n",
    "ax2[1].set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "# ax2[0].set_aspect('equal')\n",
    "# ax2[1].set_aspect('equal')\n",
    "\n",
    "plt.savefig('figures_Carlo/mean_var/mean_final_2.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_target = vf.tgt_vec\n",
    "f_target = f_target.reshape(f_target.shape[0],1)\n",
    "vf.tgt_loc = vf.tgt_loc.reshape(2,1)\n",
    "#x0 = Tensor(np.array([0.1937, 0.1257]))\n",
    "#x0 = Tensor(np.array([0.1885, 0.1038]))\n",
    "x_plot = np.linspace(-3.5, 3.5, 100)\n",
    "y_plot = np.linspace(-3.5, 3.5, 100)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat_ = torch.zeros(n * n, 2)\n",
    "\n",
    "# n_sample = x_concat_.shape[0]\n",
    "num_tasks = 2\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "    \n",
    "\n",
    "tgt_plot = vfield_(x_concat_)\n",
    "\n",
    "\n",
    "\n",
    "v_1 = tgt_plot[:,0].reshape(n,n)\n",
    "v_2 = tgt_plot[:,1].reshape(n,n)\n",
    "plot = [1, 6, 10, iter+1]\n",
    "\n",
    "for ii in plot:\n",
    "    try:\n",
    "        \n",
    "        PATH = \".//model_Carlo/model_goodmodel/model_base_\"+str(ii - 1)+\".pt\"\n",
    "        model_16 = torch.load(PATH)\n",
    "    except:\n",
    "        PATH = \".//model_Carlo/model_update/model_base_\"+str(ii - 1)+\".pt\"\n",
    "        model_16 = torch.load(PATH)\n",
    "        \n",
    "    #model_16 = torch.load(PATH)\n",
    "    model_16.eval()\n",
    "\n",
    "    likelihood.eval()\n",
    "\n",
    "    #noise = torch.eye(2 * g_theta1.detach().shape[0]) * noise_value\n",
    "    #print(x_concat_)\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var(False):\n",
    "        pred = GPprediction(model_16)\n",
    "        pr_mean, cov = pred.GPpred(g_theta1.detach(), agg_data, x_concat_, noise_value)\n",
    "        #pr = (model(g_theta1.detach())) # likelihood(model(x_concat_), noise = torch.ones(x_concat_.shape) * noise_value)#\n",
    "        pr_mean = pr_mean.reshape(x_concat_.shape[0], num_tasks)\n",
    "        mean_v_1 = pr_mean[:,0].reshape(n,n)\n",
    "        mean_v_2 = pr_mean[:,1].reshape(n,n)\n",
    "        pred_var = cov.diag().reshape(num_tasks, x_concat_.shape[0]).T\n",
    "\n",
    "        var_v_1 = pred_var[:,0].reshape(n,n)\n",
    "        var_v_2 = pred_var[:,1].reshape(n,n)\n",
    "    #     AA = pr.covariance_matrix.mean(axis=0).reshape(num_tasks, x_concat_.shape[0]).T #.diag() #.reshape(num_tasks, num_tasks * g_theta1.shape[0]).T\n",
    "\n",
    "    # #     print(pr.covariance_matrix.mean(axis=0))\n",
    "    # #     print(AA)\n",
    "    # #     print(pr.variance)\n",
    "    # #     print((pr.covariance_matrix))\n",
    "    # #     K = model.covar_module\n",
    "    #     print((cov.diag()))\n",
    "    #     print(pr_mean)\n",
    "\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (28, 12), tight_layout=True)\n",
    "    diff_mean_v1= torch.abs(v_1 - mean_v_1.detach())#/torch.abs(v_1)\n",
    "    minn = torch.min(var_v_1.detach().min(), var_v_2.detach().min())\n",
    "    maxx = torch.min(var_v_1.detach().max(), var_v_2.detach().max())\n",
    "\n",
    "    cs11 = ax1.contourf(xv_plot, yv_plot, var_v_1.detach(), np.linspace(0.0,1.1, 100), cmap = 'jet')\n",
    "    ax1.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "    \n",
    "    ax1.plot(g_theta1[0:(4 + (ii - 1)* 3), 0].detach(),g_theta1[0:(4 + (ii - 1)* 3), 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "  \n",
    "    ax1.set_title('$\\sigma^2(v_1)$ (Iteration '+str(ii)+')', fontsize = 40)\n",
    "    # ax1[0].set_aspect('equal')\n",
    "    # ax1[1].set_aspect('equal')\n",
    "    cbar11 = fig.colorbar(cs11, ax = ax1,format=OOMFormatter(-0, mathText=False));\n",
    "    ax1.set_xlabel('$d_1$')\n",
    "    ax1.set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    cs21 = ax2.contourf(xv_plot, yv_plot, var_v_2.detach(), np.linspace(0.0, 1.1, 100), cmap = 'jet')\n",
    "    ax2.plot(g_theta1[0:(4 + (ii - 1)* 3), 0].detach(),g_theta1[0:(4 + (ii - 1)* 3), 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "    ax2.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "    ax2.set_title('$\\sigma^2(v_2)$ (Iteration '+str(ii)+')', fontsize = 40)\n",
    "    cbar21 = fig.colorbar(cs21, ax = ax2,format=OOMFormatter(-0, mathText=False));\n",
    "    ax2.set_xlabel('$d_1$')\n",
    "    ax2.set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "    # ax2[0].set_aspect('equal')\n",
    "    # ax2[1].set_aspect('equal')\n",
    "\n",
    "    plt.savefig('figures_Carlo/mean_var/var_iter_base'+str(ii)+'.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_plot = np.linspace(-3., 3., 30)\n",
    "# y_plot = np.linspace(-3., 3., 30)\n",
    "# xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "# n = x_plot.shape[0]\n",
    "# x_concat_ = torch.zeros(n * n, 2)\n",
    "# training_param_iter = 200\n",
    "\n",
    "# # n_sample = x_concat_.shape[0]\n",
    "# num_tasks = 2\n",
    "# i = 0\n",
    "# k = 0\n",
    "# while i < n*n:\n",
    "#     x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "#     x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "#     k = k+1\n",
    "#     i = i+n\n",
    "\n",
    "# # #dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .01 * torch.eye(2) )\n",
    "# #                     #loc_size = 4\n",
    "# # loc_sample = 1./3. * Tensor(high_minus_low  * np.random.random_sample((3,2)) + vf.low) # #dis_2sample.sample((2 + 1,))\n",
    "# # loc_sample0 = loc_sample.reshape(2 + 1, 2)\n",
    "# # g2 = loc_sample0 #Tensor(loc_sample) #.detach()\n",
    "# likelihood.eval()\n",
    "# model.eval()\n",
    "# z = torch.zeros(n*n, 1)\n",
    "# for ii in range(n*n):\n",
    "#     print(ii)\n",
    "#     x0 = x_concat_[ii,:].reshape(1,2)\n",
    "#     dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .001 * torch.eye(2) )\n",
    "#                     #loc_size = 4\n",
    "#     loc_sample = dis_2sample.sample((2 + 1,))\n",
    "#     loc_sample0 = loc_sample.reshape(2 + 1, 2)\n",
    "#     g2 = loc_sample0 #Tensor(loc_sample) #.detach()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     x_d, g_theta2, loss2, pf1, Qf1, Qf12, data_fit, Q21 = conduct_2opt(agg_data,f_target,x0, g_theta1, model, likelihood, noise_value, g2, training_param_iter)\n",
    "#     z[ii] = loss2\n",
    "# z = z.reshape(n,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_plot = np.linspace(-3., 3., 30)\n",
    "# y_plot = np.linspace(-3., 3., 30)\n",
    "# xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "# n = x_plot.shape[0]\n",
    "# x_concat_ = torch.zeros(n * n, 2)\n",
    "# training_param_iter = 200\n",
    "\n",
    "# # n_sample = x_concat_.shape[0]\n",
    "# num_tasks = 2\n",
    "# i = 0\n",
    "# k = 0\n",
    "# while i < n*n:\n",
    "#     x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "#     x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "#     k = k+1\n",
    "#     i = i+n\n",
    "\n",
    "# #dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .01 * torch.eye(2) )\n",
    "#                     #loc_size = 4\n",
    "# loc_sample = 1./3. * Tensor(high_minus_low  * np.random.random_sample((3,2)) + vf.low) # #dis_2sample.sample((2 + 1,))\n",
    "# loc_sample0 = loc_sample.reshape(2 + 1, 2)\n",
    "# g2 = g_theta2.detach() #loc_sample0 #Tensor(loc_sample) #.detach()\n",
    "# likelihood.eval()\n",
    "# model.eval()\n",
    "# plot = [1, 7, 17, 26]\n",
    "# zz = torch.zeros(n*n, 4)\n",
    "# kk = 0\n",
    "# for jj in plot:\n",
    "#     try:\n",
    "        \n",
    "#         PATH = \".//model_Carlo/model_goodmodel/model_\"+str(jj - 1)+\".pt\"\n",
    "#         model_16 = torch.load(PATH)\n",
    "#     except:\n",
    "#         PATH = \".//model_Carlo/model_update/model_\"+str(jj - 1)+\".pt\"\n",
    "#         model_16 = torch.load(PATH)\n",
    "#    # model_16 = torch.load(PATH)\n",
    "#     model_16.eval()\n",
    "\n",
    "#     likelihood.eval()\n",
    "#     g2 = v2.detach()[jj - 1 +loc_size+1 : jj - 1 +loc_size+1 +loc_size+1]\n",
    "#     g_theta1_cur = g_theta1[0:(4 + (jj - 1)* 3)]\n",
    "#     agg_data_cur = agg_data[0:2 * (4 + (jj - 1)* 3)]\n",
    "#     print(agg_data_cur.shape)\n",
    "#     for ii in range(n*n):\n",
    "#         print(ii)\n",
    "#         x0 = x_concat_[ii,:].reshape(1,2)\n",
    "#     #     dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .001 * torch.eye(2) )\n",
    "#     #                     #loc_size = 4\n",
    "#     #     loc_sample = dis_2sample.sample((2 + 1,))\n",
    "#     #     loc_sample0 = loc_sample.reshape(2 + 1, 2)\n",
    "#         #g2 = loc_sample0 #Tensor(loc_sample) #.detach()\n",
    "\n",
    "\n",
    "        \n",
    "#         loss2_, pf1_, Qf1_, Qf12_, data_fit_, Q21_ = likelihood.get_ell(agg_data_cur,f_target,x0, g_theta1_cur, model_16, likelihood, noise_value, g2)\n",
    "#         zz[ii, kk] = loss2_\n",
    "#     kk = kk+1\n",
    "# zz = zz.reshape(n,n, 4)\n",
    "# torch.save(zz.detach(), 'data_plots/zz_success.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot = [1, 5, 10, 20]\n",
    "\n",
    "# for jj in range(4):\n",
    "#     fig, ax = plt.subplots(figsize = (16,14))\n",
    "#     #\n",
    "#     cs = ax.contour(xv_plot, yv_plot,  zz[:,:,jj].detach(), np.linspace( zz[:,:,jj].detach().numpy().min(), zz[:,:,jj].detach().numpy().max(), 1000), cmap = 'jet')\n",
    "#     cbar = fig.colorbar(cs, ax = ax,format=OOMFormatter(0, mathText=False));\n",
    "#     ax.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "#     kk = plot[jj]\n",
    "#     if kk < plot[3]:\n",
    "#         ax.plot(vec_x[kk,0], vec_x[kk,1],'o', color = 'black',markersize=12)\n",
    "#     if kk == plot[3]:\n",
    "#         ax.plot(vec_x[- 1,0], vec_x[- 1,1],'o', color = 'black',markersize=12)\n",
    "#     ax.set_title('TAD Acquisition Function (Iteration '+str(kk)+')', fontsize = 40)\n",
    "#     ax.set_xlabel('$d_1$')\n",
    "#     ax.set_ylabel('$d_2$')\n",
    "    \n",
    "#     plt.savefig('figures_Carlo/tad_obj'+str(kk)+'.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p21_vec_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_venv",
   "language": "python",
   "name": "python_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
