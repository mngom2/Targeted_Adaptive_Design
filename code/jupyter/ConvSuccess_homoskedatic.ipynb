{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn  import functional as F\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import sys\n",
    "from decimal import Decimal\n",
    "from IPython.display import clear_output\n",
    "sys.path.append(\"..\")\n",
    "from LBFGS import FullBatchLBFGS\n",
    "from kernels import vvkernels as vvk, sep_vvkernels as svvk, vvk_rbfkernel as vvk_rbf\n",
    "from means import vvmeans as vvm\n",
    "from likelihood import vvlikelihood as vvll\n",
    "from mlikelihoods import MarginalLogLikelihood as exmll\n",
    "from predstrategies import GPprediction\n",
    "from utils import ObjFun, get_vertices, stopping_criteria\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=40)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=32)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=32)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=32)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=32)    # legend fontsize\n",
    "plt.rc('font', size=32)          # controls default text sizes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective function\n",
    "\n",
    "We sample from $$V_1(x_1, x_2) = 3(1 - x_1)^2 e^{-x_1^2 - (x_2 +1)^2} - 10 (x_1/5 - x_1 ^3 - x_2^5) e^{-x_1^2 - x_2 ^2} - 3 e^{- (x_1 + 2) ^2 - x_2^2} + 0.5(2x_1 + x_2)$$\n",
    "$$V_2(x_1, x_2) = 3(1 +x_2)^2 e^{-x_2^2 - (x_1 +1)^2} - 10 (-x_2/5 + x_2 ^3 + x_1^5) e^{-x_1^2 - x_2 ^2} - 3 e^{- ( 2- x_2) ^2 - x_1^2} + 0.5(2x_1 + x_2)$$\n",
    "\n",
    "where $(x_1, x_2) \\in [-3, 3]^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3380, 0.3502], dtype=torch.float32)\n",
      "tensor([[ 1.7935, -1.0671],\n",
      "        [ 1.4009, -1.3609],\n",
      "        [ 1.7311, -1.8737],\n",
      "        [ 1.8545, -1.3372]])\n"
     ]
    }
   ],
   "source": [
    "vf = ObjFun()\n",
    "f_target = vf.tgt_vec\n",
    "print(f_target)\n",
    "sample_size = 4\n",
    "D = vf.D\n",
    "N = vf.N\n",
    "\n",
    "vf.low = -3.\n",
    "vf.high = 3.\n",
    "\n",
    "high_minus_low = vf.high- vf.low\n",
    "#high_minus_low = -\n",
    "def g_theta(sample_size, D):\n",
    "    loc_x = (2. - 1.0 )  * np.random.random_sample((sample_size,1)) + 1.0\n",
    "    \n",
    "    loc_y = (2.  -1.0)  * np.random.random_sample((sample_size,1)) - 2.\n",
    "    loc = np.concatenate((loc_x, loc_y), 1)\n",
    "    #loc = high_minus_low  * np.random.random_sample((sample_size,2)) + vf.low#(np.random.uniform(low=vf.low, high=vf.high, size=(sample_size, D)))\n",
    "    return Tensor(loc)\n",
    "train_x = g_theta(sample_size, D)\n",
    "#train_x = Tensor([[-1.5, 1.5], [-1.5, 1.3]])\n",
    "print(train_x)\n",
    "noise_value = 0.0004 #noise_free = 0.\n",
    "def vfield_(x):\n",
    "    x = x.reshape(x.shape[0],D)\n",
    "    out = torch.zeros(x.shape[0], N)\n",
    "    \n",
    "    out = vf(x[:,0], x[:,1]) + torch.randn(Tensor(vf(x[:,0], x[:,1])).size()) * math.sqrt(noise_value)\n",
    "    return out #/torch.max(out)\n",
    "\n",
    "train_y = vfield_(train_x)\n",
    "\n",
    "# print(train_y)\n",
    "# train_y = (train_y - train_y.mean())/train_y.std(dim=-2, keepdim=True)\n",
    "# train_x = (train_x - train_x.mean())/train_x.std(dim=-2, keepdim=True)\n",
    "# print(train_y)\n",
    "# print(train_y.std(dim=-2, keepdim=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP model initialization\n",
    "We inialize the GP model following https://docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_x #loc #torch.linspace(0, 1, 10)\n",
    "y_train = train_y #v  #torch.stack([torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,torch.cos(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2,], -1)\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood,num_base_kernels):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = vvm.TensorProductSubMean(gpytorch.means.LinearMean(2), num_tasks = 2)  #vvm.TensorProductSubMean(gpytorch.means.LinearMean(2), num_tasks = 2)#vvm.TensorProductSubMean(gpytorch.means.ConstantMean(), num_tasks = 2)  # \n",
    "        base_kernels = [] #contain all the base kernels\n",
    "        for i in range(num_base_kernels):\n",
    "            base_kernels.append(gpytorch.kernels.ScaleKernel(( gpytorch.kernels.RBFKernel() ))) #gpytorch.kernels.PolynomialKernel(4)  ##gpytorch.kernels.MaternKernel()# (vvk_rbf.vvkRBFKernel())\n",
    " \n",
    "            \n",
    "        self.covar_module = svvk.SepTensorProductKernel(base_kernels,num_tasks = 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamaters oprimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ###hyperparameters optimization###\n",
    "def hyper_opti(g_theta1, agg_data, training_iter,num_base_kernels,noise_value, current_model = None, current_likelihood = None):\n",
    "    noises = torch.ones(agg_data.shape[0]) * (noise_value) #  torch.zeros(agg_data.shape[0]) # \n",
    "    noises = noises.reshape(g_theta1.shape[0], 2)\n",
    "    \n",
    "#     if (current_model is not None):\n",
    "#         likelihood = current_likelihood #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises)  #\n",
    "\n",
    "#         model = current_model#.get_fantasy_model(g_theta1, agg_data) #MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "#         model.set_train_data(g_theta1, agg_data,  strict=False)\n",
    "#     else:\n",
    "#         likelihood = vvll.FixedNoiseMultitaskGaussianLikelihood(noises) #vvll.TensorProductLikelihood(num_tasks = 2)#vvll.FixedNoiseMultitaskGaussianLikelihood(2, noises) #\n",
    "#         model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "        \n",
    "    cov_noise1 =  noise_value * torch.eye(agg_data.shape[0])\n",
    "    likelihood =  vvll.FixedNoiseMultitaskGaussianLikelihood(noises) #vvll.TensorProductLikelihood(num_tasks = 2) #\n",
    "    model = MultitaskGPModel(g_theta1, agg_data, likelihood,num_base_kernels)\n",
    "    model.double()\n",
    "    likelihood.double()\n",
    "\n",
    "    \"\"\"Put related things on GPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using CUDA\")\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "        g_theta1 = g_theta1.cuda()\n",
    "        agg_data = agg_data.cuda()\n",
    "        cov_noise1 = cov_noise1.cuda()\n",
    "        \n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "    \n",
    "    \"\"\"end for GPU\"\"\"\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  lr=0.1) #, weight_decay=0.001)  # Includes GaussianLikelihood parameters\n",
    "    mll = exmll(likelihood, model)\n",
    "    # Is this a likelihood?\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, chi_square = mll(agg_data,g_theta1, model, likelihood, cov_noise1)\n",
    "        loss = -1. * loss\n",
    "#         print('df is %.3f' %agg_data.shape[0] +'and chi_square %.3f' %chi_square) \n",
    "        #print('loss is %.3f' %loss)\n",
    "#         df = agg_data.shape[0]\n",
    "#         chi_square = chi_square.clone().detach()\n",
    "        \n",
    "#         p_val = 1. - stats.chi2.cdf(chi_square, df)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss)\n",
    "       # print(p_val)\n",
    "#         if (p_val > 0.99999):\n",
    "#             return model, likelihood\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    print('loss is %.3f' %loss)\n",
    "#     for params in model.named_parameters():\n",
    "#         print(params)\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design parameters and sampling point optimization (where to explore?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_design_opti(x0,loc_sample, f_target, g_theta1, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new,noise_value):\n",
    "\n",
    "    g_theta2 = nn.Parameter(Tensor(loc_sample))\n",
    "\n",
    "    x_d= nn.Parameter(Tensor(x0))\n",
    "    \n",
    "    optimizer = torch.optim.Adam([{'params': g_theta2, 'lr': 0.1},{'params': x_d, 'lr': 0.1}])\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    \n",
    "    cov_noise1 =  noise_value * torch.eye(agg_data.shape[0])\n",
    "    cov_noise2 =  noise_value * torch.eye(2 * g_theta2.shape[0])\n",
    "    \n",
    "    \"\"\"Put related things on GPU for conduct_design_opti\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using CUDA for conduct_design_opti()\")\n",
    "        \n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "        agg_data = agg_data.cuda()\n",
    "        \n",
    "        cov_noise1 = cov_noise1.cuda()\n",
    "        cov_noise2 = cov_noise2.cuda()\n",
    "        g_theta1 = g_theta1.cuda()\n",
    "        g_theta2 = g_theta2.cuda()\n",
    "        agg_data = agg_data.cuda()\n",
    "        x_d = x_d.cuda()\n",
    "        f_target = f_target.cuda()\n",
    "        \n",
    "    else:\n",
    "        print(\"Using CPU for conduct_design_opti()\")\n",
    "    \n",
    "    \"\"\"end for GPU\"\"\"\n",
    "    \n",
    "    \n",
    "    for ii in range( training_param_iter ):\n",
    "#         x_d = torch.cat([x_d_0, x_d_1]).reshape(1,2)\n",
    "#         g_theta2 = torch.cat([g_theta20, g_theta21],1)\n",
    "        optimizer.zero_grad()\n",
    "        loss2, pf1, Qf1, Qf12, data_fit, Q21 = likelihood.get_ell(agg_data,f_target,x_d, g_theta1, model, likelihood, g_theta2, cov_noise1, cov_noise2)\n",
    "\n",
    "        loss2 = -1. * loss2\n",
    "        \n",
    "        loss2.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #scheduler.step(loss2)\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Loss design: %.3f' % ( loss2))\n",
    "    #print(x_d)\n",
    "    return x_d, g_theta2, loss2, pf1, Qf1, Qf12, data_fit, Q21\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conducting the TAD experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_size = 2\n",
    "#loc_sample0 = Tensor((2. - 1.5)  * np.random.random_sample((loc_size,2)) + 1.5)\n",
    "x0 = Tensor(np.array([-2. , 2.]))\n",
    " # 1./3. * Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "x0 = x0.reshape(1,2)\n",
    "\n",
    "dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .01 * torch.eye(loc_size) )\n",
    "                    #loc_size = 4\n",
    "loc_sample = dis_2sample.sample((loc_size + 1,))\n",
    "\n",
    "loc_sample0 = loc_sample.reshape(loc_size + 1, 2)\n",
    "#loc_sample0[-1] = train_x[-1] + 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0100,  1.8874],\n",
      "        [-1.8928,  2.1760],\n",
      "        [-2.1702,  1.9464]])\n",
      "0\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grand/datascience/tiany/python_venv/lib/python3.8/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  /lus/theta-fs0/software/thetagpu/conda/2022-07-01/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -2.470\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 3445.008\n",
      "expected info is tensor([[3.7713]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-2.,  2.]])\n",
      "new data istensor([[-0.1055,  0.0051]])\n",
      "g_theta2 istensor([[-2.0100,  1.8874],\n",
      "        [-1.8928,  2.1760],\n",
      "        [-2.1702,  1.9464]])\n",
      "p21val is 0.000005130890547\n",
      "pf12val is 0.916141478996287\n",
      "chi_f12 is 0.175168946363872\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "0\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 3437.390\n",
      "expected info is tensor([[3.7899]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-2.,  2.]])\n",
      "new data istensor([[-0.1033, -0.0273]])\n",
      "g_theta2 istensor([[-2.0943,  1.8737],\n",
      "        [-1.8877,  2.2413],\n",
      "        [-2.0000,  2.0000]])\n",
      "p21val is 0.000001036639248\n",
      "pf12val is 0.320186055587815\n",
      "chi_f12 is 2.277706056875443\n",
      "patience is 2.000\n",
      "adding complexity to model\n",
      "num base is3\n",
      "acquiring 2, new size is7\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "1\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.428\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 106.162\n",
      "expected info is tensor([[0.0112]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0000,  1.0000]])\n",
      "new data istensor([[-0.0708, -0.0137]])\n",
      "g_theta2 istensor([[-2.0100,  1.8874],\n",
      "        [-1.8928,  2.1760],\n",
      "        [-2.1702,  1.9464]])\n",
      "p21val is 0.632191967111333\n",
      "pf12val is 0.947097628582588\n",
      "chi_f12 is 0.108706197250941\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.7574,  1.7570],\n",
      "        [-1.9920,  2.3903],\n",
      "        [-1.0000,  1.0001]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "2\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.767\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 889.500\n",
      "expected info is tensor([[0.6281]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0000,  0.9999]])\n",
      "new data istensor([[-0.0735,  0.0074]])\n",
      "g_theta2 istensor([[-1.7574,  1.7570],\n",
      "        [-1.9920,  2.3903],\n",
      "        [-1.0000,  1.0001]])\n",
      "p21val is 0.928561800253303\n",
      "pf12val is 0.926983811023806\n",
      "chi_f12 is 0.151638354810032\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-2.1036,  2.5388],\n",
      "        [-0.6363,  0.4447],\n",
      "        [-1.0000,  1.0000]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "3\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.753\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 2141.684\n",
      "expected info is tensor([[0.3741]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0000,  0.9999]])\n",
      "new data istensor([[-0.0490, -0.0055]])\n",
      "g_theta2 istensor([[-2.1036,  2.5388],\n",
      "        [-0.6363,  0.4447],\n",
      "        [-1.0000,  1.0000]])\n",
      "p21val is 0.311696602659009\n",
      "pf12val is 0.505786923447318\n",
      "chi_f12 is 1.363279596577245\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.0740, -0.4840],\n",
      "        [-1.0096,  0.9975],\n",
      "        [-1.0001,  1.0000]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.793\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 3163.219\n",
      "expected info is tensor([[0.3057]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0002,  0.9998]])\n",
      "new data istensor([[-0.0675,  0.0093]])\n",
      "g_theta2 istensor([[ 0.0740, -0.4840],\n",
      "        [-1.0096,  0.9975],\n",
      "        [-1.0001,  1.0000]])\n",
      "p21val is 0.000000000202426\n",
      "pf12val is 0.961781183188147\n",
      "chi_f12 is 0.077936628985662\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 2932.231\n",
      "expected info is tensor([[0.2070]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0002,  0.9998]])\n",
      "new data istensor([[-0.0585,  0.0238]])\n",
      "g_theta2 istensor([[-1.5186,  1.7221],\n",
      "        [-2.5132,  3.0940],\n",
      "        [-1.0002,  0.9998]])\n",
      "p21val is 0.527862782387440\n",
      "pf12val is 0.455707091697360\n",
      "chi_f12 is 1.571810037254405\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 0.1380, -0.5776],\n",
      "        [-2.3922,  2.9343],\n",
      "        [-1.0001,  0.9997]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "5\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.909\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 4054.655\n",
      "expected info is tensor([[0.1326]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0000,  0.9998]])\n",
      "new data istensor([[-0.0579,  0.0097]])\n",
      "g_theta2 istensor([[ 0.1380, -0.5776],\n",
      "        [-2.3922,  2.9343],\n",
      "        [-1.0001,  0.9997]])\n",
      "p21val is 0.000000000390931\n",
      "pf12val is 0.983241846106188\n",
      "chi_f12 is 0.033800321005570\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "5\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 4465.600\n",
      "expected info is tensor([[0.2292]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0000,  0.9998]])\n",
      "new data istensor([[-0.0492, -0.0073]])\n",
      "g_theta2 istensor([[ 9.8450e-04, -3.8950e-01],\n",
      "        [-8.5630e-01,  8.0004e-01],\n",
      "        [-1.0000e+00,  9.9984e-01]])\n",
      "p21val is 0.000000000000000\n",
      "pf12val is 0.586549411032338\n",
      "chi_f12 is 1.066996734305492\n",
      "patience is 2.000\n",
      "adding complexity to model\n",
      "num base is4\n",
      "acquiring 2, new size is26\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "6\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.808\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 34.390\n",
      "expected info is tensor([[4.1489e-05]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-3.3675e-05,  1.9998e+00]])\n",
      "new data istensor([[ 0.7687, -0.4466]])\n",
      "g_theta2 istensor([[ 0.1380, -0.5776],\n",
      "        [-2.3922,  2.9343],\n",
      "        [-1.0001,  0.9997]])\n",
      "p21val is 0.528936755045736\n",
      "pf12val is 0.000000378299230\n",
      "chi_f12 is 29.575160683700624\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 2.0656e+00, -5.5152e-01],\n",
      "        [-7.3373e-01,  2.1962e+00],\n",
      "        [ 5.3479e-05,  1.9998e+00]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "7\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.762\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 2139.155\n",
      "expected info is tensor([[0.6915]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.3377e-04,  1.9998e+00]])\n",
      "new data istensor([[ 0.7456, -0.5009]])\n",
      "g_theta2 istensor([[ 2.0656e+00, -5.5152e-01],\n",
      "        [-7.3373e-01,  2.1962e+00],\n",
      "        [ 5.3479e-05,  1.9998e+00]])\n",
      "p21val is 0.011161785467245\n",
      "pf12val is 0.259005741828958\n",
      "chi_f12 is 2.701810096609116\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 2.4908e+00, -1.4051e+00],\n",
      "        [ 8.8183e-01,  1.1892e+00],\n",
      "        [-1.3636e-04,  2.0000e+00]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "8\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.702\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 4476.427\n",
      "expected info is tensor([[0.2881]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-4.2693e-05,  2.0000e+00]])\n",
      "new data istensor([[ 0.7784, -0.4642]])\n",
      "g_theta2 istensor([[ 2.4908e+00, -1.4051e+00],\n",
      "        [ 8.8183e-01,  1.1892e+00],\n",
      "        [-1.3636e-04,  2.0000e+00]])\n",
      "p21val is 0.000000000000030\n",
      "pf12val is 0.616591273265129\n",
      "chi_f12 is 0.967097833244496\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "8\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 4516.263\n",
      "expected info is tensor([[0.2974]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-4.2693e-05,  2.0000e+00]])\n",
      "new data istensor([[ 0.7766, -0.4566]])\n",
      "g_theta2 istensor([[ 4.8240e-01,  1.3020e+00],\n",
      "        [ 5.7341e-01,  1.3135e+00],\n",
      "        [-4.2693e-05,  2.0000e+00]])\n",
      "p21val is 0.000014976676786\n",
      "pf12val is 0.653432472884838\n",
      "chi_f12 is 0.851032165452372\n",
      "patience is 2.000\n",
      "adding complexity to model\n",
      "num base is5\n",
      "acquiring 2, new size is37\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "9\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -2.624\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 18.651\n",
      "expected info is tensor([[0.0004]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0000,  3.0000]])\n",
      "new data istensor([[ 0.0468, -0.0364]])\n",
      "g_theta2 istensor([[ 2.4908e+00, -1.4051e+00],\n",
      "        [ 8.8183e-01,  1.1892e+00],\n",
      "        [-1.3636e-04,  2.0000e+00]])\n",
      "p21val is 0.010243881867929\n",
      "pf12val is 0.213111384591291\n",
      "chi_f12 is 3.091880635201418\n",
      "samples escaped box\n",
      "p_val_ftarget is 2.8367785898097964e-10\n",
      "new 2 points\n",
      "tensor([[-1.7918,  1.5534],\n",
      "        [ 1.4841,  0.0125],\n",
      "        [-1.0000,  3.0001]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "10\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.574\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 592.528\n",
      "expected info is tensor([[0.6779]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0001,  3.0000]])\n",
      "new data istensor([[ 0.0571, -0.0448]])\n",
      "g_theta2 istensor([[-1.7918,  1.5534],\n",
      "        [ 1.4841,  0.0125],\n",
      "        [-1.0000,  3.0001]])\n",
      "p21val is 0.008133421784594\n",
      "pf12val is 0.581444155270659\n",
      "chi_f12 is 1.084480694566373\n",
      "patience is 1.000\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "10\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 593.594\n",
      "expected info is tensor([[0.6788]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.0001,  3.0000]])\n",
      "new data istensor([[ 0.0831, -0.0706]])\n",
      "g_theta2 istensor([[ 0.0745,  4.7245],\n",
      "        [-0.6459,  1.1411],\n",
      "        [-1.0001,  3.0000]])\n",
      "p21val is 0.029197402792285\n",
      "pf12val is 0.378273351825336\n",
      "chi_f12 is 1.944276383469190\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[ 1.4184, -0.6676],\n",
      "        [-2.8094,  2.0740],\n",
      "        [-1.8934,  2.3734]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "11\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.531\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 1594.005\n",
      "expected info is tensor([[0.4251]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8934,  2.3734]])\n",
      "new data istensor([[-0.0507, -0.0309]])\n",
      "g_theta2 istensor([[ 1.4184, -0.6676],\n",
      "        [-2.8094,  2.0740],\n",
      "        [-1.8934,  2.3734]])\n",
      "p21val is 0.041209596301816\n",
      "pf12val is 0.195485899043361\n",
      "chi_f12 is 3.264534059626972\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-2.7987, -0.9258],\n",
      "        [ 0.5991, -1.0557],\n",
      "        [-1.8935,  2.3733]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "12\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.501\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 2228.665\n",
      "expected info is tensor([[0.2206]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3733]])\n",
      "new data istensor([[-0.0761, -0.0338]])\n",
      "g_theta2 istensor([[-2.7987, -0.9258],\n",
      "        [ 0.5991, -1.0557],\n",
      "        [-1.8935,  2.3733]])\n",
      "p21val is 0.117602414741149\n",
      "pf12val is 0.479768046300977\n",
      "chi_f12 is 1.468905057499464\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-0.6243,  1.0165],\n",
      "        [-2.2856,  0.1943],\n",
      "        [-1.8934,  2.3733]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "13\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.481\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 2911.471\n",
      "expected info is tensor([[0.1586]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3732]])\n",
      "new data istensor([[-0.0811, -0.0047]])\n",
      "g_theta2 istensor([[-0.6243,  1.0165],\n",
      "        [-2.2856,  0.1943],\n",
      "        [-1.8934,  2.3733]])\n",
      "p21val is 0.322438348296463\n",
      "pf12val is 0.937435831581186\n",
      "chi_f12 is 0.129213939587058\n",
      "samples escaped box\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-0.6479,  2.9926],\n",
      "        [-2.0177,  1.5390],\n",
      "        [-1.8932,  2.3732]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "14\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.511\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 3646.804\n",
      "expected info is tensor([[0.1442]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8934,  2.3730]])\n",
      "new data istensor([[-0.0736, -0.0150]])\n",
      "g_theta2 istensor([[-0.6479,  2.9926],\n",
      "        [-2.0177,  1.5390],\n",
      "        [-1.8932,  2.3732]])\n",
      "p21val is 0.545936250768092\n",
      "pf12val is 0.907883380675660\n",
      "chi_f12 is 0.193278688017205\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.9135,  2.9617],\n",
      "        [-2.0270,  2.6504],\n",
      "        [-1.8935,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "15\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.544\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 4877.719\n",
      "expected info is tensor([[0.1491]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3729]])\n",
      "new data istensor([[-0.0832,  0.0388]])\n",
      "g_theta2 istensor([[-1.9135,  2.9617],\n",
      "        [-2.0270,  2.6504],\n",
      "        [-1.8935,  2.3731]])\n",
      "p21val is 0.719237466266625\n",
      "pf12val is 0.079494529834547\n",
      "chi_f12 is 5.064134133603566\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.7843,  2.2886],\n",
      "        [-1.8574,  2.3643],\n",
      "        [-1.8934,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "16\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.579\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 6327.001\n",
      "expected info is tensor([[0.2420]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3729]])\n",
      "new data istensor([[-0.0639, -0.0136]])\n",
      "g_theta2 istensor([[-1.7843,  2.2886],\n",
      "        [-1.8574,  2.3643],\n",
      "        [-1.8934,  2.3730]])\n",
      "p21val is 0.887802269782561\n",
      "pf12val is 0.661217873795732\n",
      "chi_f12 is 0.827343762083389\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.9203,  2.3869],\n",
      "        [-1.8842,  2.3647],\n",
      "        [-1.8932,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "17\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.651\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 7878.562\n",
      "expected info is tensor([[0.1561]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3729]])\n",
      "new data istensor([[-0.0635, -0.0048]])\n",
      "g_theta2 istensor([[-1.9203,  2.3869],\n",
      "        [-1.8842,  2.3647],\n",
      "        [-1.8932,  2.3728]])\n",
      "p21val is 0.027371971724221\n",
      "pf12val is 0.812582615373453\n",
      "chi_f12 is 0.415075378975434\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8840,  2.3664],\n",
      "        [-1.8678,  2.3594],\n",
      "        [-1.8932,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "18\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.668\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 9308.409\n",
      "expected info is tensor([[0.1364]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3728]])\n",
      "new data istensor([[-0.0795, -0.0292]])\n",
      "g_theta2 istensor([[-1.8840,  2.3664],\n",
      "        [-1.8678,  2.3594],\n",
      "        [-1.8932,  2.3729]])\n",
      "p21val is 0.681446281668189\n",
      "pf12val is 0.603276641607036\n",
      "chi_f12 is 1.010758823985040\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8668,  2.3583],\n",
      "        [-1.9068,  2.3793],\n",
      "        [-1.8934,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "19\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.713\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 10871.673\n",
      "expected info is tensor([[0.1122]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3729]])\n",
      "new data istensor([[-0.0787,  0.0308]])\n",
      "g_theta2 istensor([[-1.8668,  2.3583],\n",
      "        [-1.9068,  2.3793],\n",
      "        [-1.8934,  2.3729]])\n",
      "p21val is 0.864800294660282\n",
      "pf12val is 0.119168669582217\n",
      "chi_f12 is 4.254430795948988\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.9076,  2.3801],\n",
      "        [-1.8576,  2.3544],\n",
      "        [-1.8931,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "20\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -2.747\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 12436.862\n",
      "expected info is tensor([[0.0980]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3729]])\n",
      "new data istensor([[-0.0723, -0.0301]])\n",
      "g_theta2 istensor([[-1.9076,  2.3801],\n",
      "        [-1.8576,  2.3544],\n",
      "        [-1.8931,  2.3728]])\n",
      "p21val is 0.148029590723441\n",
      "pf12val is 0.590402077913996\n",
      "chi_f12 is 1.053902972400084\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8966,  2.3745],\n",
      "        [-1.8683,  2.3598],\n",
      "        [-1.8929,  2.3727]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "21\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.775\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 14000.992\n",
      "expected info is tensor([[0.0868]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3730]])\n",
      "new data istensor([[-0.0952, -0.0049]])\n",
      "g_theta2 istensor([[-1.8966,  2.3745],\n",
      "        [-1.8683,  2.3598],\n",
      "        [-1.8929,  2.3727]])\n",
      "p21val is 0.409180066062020\n",
      "pf12val is 0.663048276736594\n",
      "chi_f12 is 0.821814951713123\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8859,  2.3692],\n",
      "        [-1.8730,  2.3624],\n",
      "        [-1.8930,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "22\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.807\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 15579.526\n",
      "expected info is tensor([[0.0778]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3732]])\n",
      "new data istensor([[-0.0550,  0.0006]])\n",
      "g_theta2 istensor([[-1.8859,  2.3692],\n",
      "        [-1.8730,  2.3624],\n",
      "        [-1.8930,  2.3730]])\n",
      "p21val is 0.196380829884602\n",
      "pf12val is 0.455920984831467\n",
      "chi_f12 is 1.570871526721266\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8805,  2.3663],\n",
      "        [-1.8798,  2.3660],\n",
      "        [-1.8932,  2.3734]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "23\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.824\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 17075.942\n",
      "expected info is tensor([[0.0702]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3732]])\n",
      "new data istensor([[-0.0698, -0.0122]])\n",
      "g_theta2 istensor([[-1.8805,  2.3663],\n",
      "        [-1.8798,  2.3660],\n",
      "        [-1.8932,  2.3734]])\n",
      "p21val is 0.611985983708508\n",
      "pf12val is 0.892900439822575\n",
      "chi_f12 is 0.226560387762895\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8857,  2.3691],\n",
      "        [-1.9033,  2.3786],\n",
      "        [-1.8932,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "24\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.854\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 18466.600\n",
      "expected info is tensor([[0.0638]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3731]])\n",
      "new data istensor([[-0.0833, -0.0064]])\n",
      "g_theta2 istensor([[-1.8857,  2.3691],\n",
      "        [-1.9033,  2.3786],\n",
      "        [-1.8932,  2.3730]])\n",
      "p21val is 0.529164466295452\n",
      "pf12val is 0.974145201827646\n",
      "chi_f12 is 0.052389817197615\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8953,  2.3742],\n",
      "        [-1.8796,  2.3658],\n",
      "        [-1.8932,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "25\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.877\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 20097.599\n",
      "expected info is tensor([[0.0589]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8935,  2.3731]])\n",
      "new data istensor([[-0.0670, -0.0007]])\n",
      "g_theta2 istensor([[-1.8953,  2.3742],\n",
      "        [-1.8796,  2.3658],\n",
      "        [-1.8932,  2.3729]])\n",
      "p21val is 0.153609726727019\n",
      "pf12val is 0.791196789554661\n",
      "chi_f12 is 0.468417112746288\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.9082,  2.3808],\n",
      "        [-1.8873,  2.3698],\n",
      "        [-1.8935,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "26\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.896\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 21615.238\n",
      "expected info is tensor([[0.0543]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8935,  2.3730]])\n",
      "new data istensor([[-0.0474, -0.0232]])\n",
      "g_theta2 istensor([[-1.9082,  2.3808],\n",
      "        [-1.8873,  2.3698],\n",
      "        [-1.8935,  2.3730]])\n",
      "p21val is 0.937825827247301\n",
      "pf12val is 0.227182879984967\n",
      "chi_f12 is 2.963999894306205\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8854,  2.3687],\n",
      "        [-1.8905,  2.3714],\n",
      "        [-1.8935,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "27\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.922\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 23072.530\n",
      "expected info is tensor([[0.0509]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3731]])\n",
      "new data istensor([[-0.0963, -0.0127]])\n",
      "g_theta2 istensor([[-1.8854,  2.3687],\n",
      "        [-1.8905,  2.3714],\n",
      "        [-1.8935,  2.3730]])\n",
      "p21val is 0.969099571578259\n",
      "pf12val is 0.657431623255219\n",
      "chi_f12 is 0.838829030774349\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8844,  2.3680],\n",
      "        [-1.8997,  2.3767],\n",
      "        [-1.8933,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "28\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.957\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 24632.672\n",
      "expected info is tensor([[0.0475]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3732]])\n",
      "new data istensor([[-0.0675,  0.0018]])\n",
      "g_theta2 istensor([[-1.8844,  2.3680],\n",
      "        [-1.8997,  2.3767],\n",
      "        [-1.8933,  2.3731]])\n",
      "p21val is 0.264754608820039\n",
      "pf12val is 0.740144754058658\n",
      "chi_f12 is 0.601818996641970\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8880,  2.3702],\n",
      "        [-1.8988,  2.3764],\n",
      "        [-1.8931,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "29\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.960\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 26229.159\n",
      "expected info is tensor([[0.0446]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3732]])\n",
      "new data istensor([[-0.0939,  0.0070]])\n",
      "g_theta2 istensor([[-1.8880,  2.3702],\n",
      "        [-1.8988,  2.3764],\n",
      "        [-1.8931,  2.3731]])\n",
      "p21val is 0.265833066514270\n",
      "pf12val is 0.558712962907346\n",
      "chi_f12 is 1.164238841751569\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8941,  2.3738],\n",
      "        [-1.8965,  2.3751],\n",
      "        [-1.8933,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "30\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.980\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 27715.187\n",
      "expected info is tensor([[0.0421]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3732]])\n",
      "new data istensor([[-0.0307, -0.0292]])\n",
      "g_theta2 istensor([[-1.8941,  2.3738],\n",
      "        [-1.8965,  2.3751],\n",
      "        [-1.8933,  2.3730]])\n",
      "p21val is 0.805058692066616\n",
      "pf12val is 0.033031466857053\n",
      "chi_f12 is 6.820589261448781\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8954,  2.3745],\n",
      "        [-1.8963,  2.3750],\n",
      "        [-1.8932,  2.3734]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "31\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -2.995\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 29259.131\n",
      "expected info is tensor([[0.0398]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3732]])\n",
      "new data istensor([[-0.0715,  0.0136]])\n",
      "g_theta2 istensor([[-1.8954,  2.3745],\n",
      "        [-1.8963,  2.3750],\n",
      "        [-1.8932,  2.3734]])\n",
      "p21val is 0.729433246121882\n",
      "pf12val is 0.525390775546556\n",
      "chi_f12 is 1.287225917791133\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8959,  2.3748],\n",
      "        [-1.8961,  2.3749],\n",
      "        [-1.8931,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "32\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -3.010\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 30525.879\n",
      "expected info is tensor([[0.0380]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3733]])\n",
      "new data istensor([[-0.0704, -0.0226]])\n",
      "g_theta2 istensor([[-1.8959,  2.3748],\n",
      "        [-1.8961,  2.3749],\n",
      "        [-1.8931,  2.3731]])\n",
      "p21val is 0.333381295232398\n",
      "pf12val is 0.727573574435697\n",
      "chi_f12 is 0.636080303610334\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8948,  2.3741],\n",
      "        [-1.8835,  2.3681],\n",
      "        [-1.8929,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "33\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.021\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 32140.314\n",
      "expected info is tensor([[0.0361]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3732]])\n",
      "new data istensor([[-0.1018, -0.0135]])\n",
      "g_theta2 istensor([[-1.8948,  2.3741],\n",
      "        [-1.8835,  2.3681],\n",
      "        [-1.8929,  2.3731]])\n",
      "p21val is 0.954221989194349\n",
      "pf12val is 0.458546391218942\n",
      "chi_f12 is 1.559387623983846\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.9000,  2.3769],\n",
      "        [-1.8967,  2.3751],\n",
      "        [-1.8932,  2.3733]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "34\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.046\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 33537.035\n",
      "expected info is tensor([[0.0344]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3731]])\n",
      "new data istensor([[-0.0923, -0.0229]])\n",
      "g_theta2 istensor([[-1.9000,  2.3769],\n",
      "        [-1.8967,  2.3751],\n",
      "        [-1.8932,  2.3733]])\n",
      "p21val is 0.506074097861530\n",
      "pf12val is 0.578590624834697\n",
      "chi_f12 is 1.094320179521262\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8927,  2.3728],\n",
      "        [-1.8883,  2.3703],\n",
      "        [-1.8930,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "35\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.059\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 35115.595\n",
      "expected info is tensor([[0.0330]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3732]])\n",
      "new data istensor([[-0.0668, -0.0040]])\n",
      "g_theta2 istensor([[-1.8927,  2.3728],\n",
      "        [-1.8883,  2.3703],\n",
      "        [-1.8930,  2.3731]])\n",
      "p21val is 0.403407139948074\n",
      "pf12val is 0.861912548593433\n",
      "chi_f12 is 0.297202930425557\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8925,  2.3729],\n",
      "        [-1.8915,  2.3721],\n",
      "        [-1.8932,  2.3732]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "36\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.067\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 36529.151\n",
      "expected info is tensor([[0.0316]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8930,  2.3728]])\n",
      "new data istensor([[-0.1015,  0.0184]])\n",
      "g_theta2 istensor([[-1.8925,  2.3729],\n",
      "        [-1.8915,  2.3721],\n",
      "        [-1.8932,  2.3732]])\n",
      "p21val is 0.756212304695399\n",
      "pf12val is 0.186748610574285\n",
      "chi_f12 is 3.355983790054980\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8937,  2.3729],\n",
      "        [-1.8936,  2.3730],\n",
      "        [-1.8929,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "37\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.076\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 38035.861\n",
      "expected info is tensor([[0.0303]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3728]])\n",
      "new data istensor([[-0.0797,  0.0110]])\n",
      "g_theta2 istensor([[-1.8937,  2.3729],\n",
      "        [-1.8936,  2.3730],\n",
      "        [-1.8929,  2.3728]])\n",
      "p21val is 0.052491579704717\n",
      "pf12val is 0.637459853152494\n",
      "chi_f12 is 0.900527958759321\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8924,  2.3728],\n",
      "        [-1.8921,  2.3727],\n",
      "        [-1.8932,  2.3727]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "38\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.081\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 39529.721\n",
      "expected info is tensor([[0.0291]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8930,  2.3730]])\n",
      "new data istensor([[-0.0318, -0.0488]])\n",
      "g_theta2 istensor([[-1.8924,  2.3728],\n",
      "        [-1.8921,  2.3727],\n",
      "        [-1.8932,  2.3727]])\n",
      "p21val is 0.936709037296811\n",
      "pf12val is 0.009157788466733\n",
      "chi_f12 is 9.386301126417376\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8928,  2.3730],\n",
      "        [-1.8936,  2.3733],\n",
      "        [-1.8928,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "39\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.078\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 41062.845\n",
      "expected info is tensor([[0.0280]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8929,  2.3730]])\n",
      "new data istensor([[-0.0647,  0.0197]])\n",
      "g_theta2 istensor([[-1.8928,  2.3730],\n",
      "        [-1.8936,  2.3733],\n",
      "        [-1.8928,  2.3730]])\n",
      "p21val is 0.608122686483621\n",
      "pf12val is 0.319439026583705\n",
      "chi_f12 is 2.282377726980875\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8915,  2.3724],\n",
      "        [-1.8932,  2.3731],\n",
      "        [-1.8930,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "40\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.097\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 42442.567\n",
      "expected info is tensor([[0.0270]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8929,  2.3731]])\n",
      "new data istensor([[-0.0296, -0.0200]])\n",
      "g_theta2 istensor([[-1.8915,  2.3724],\n",
      "        [-1.8932,  2.3731],\n",
      "        [-1.8930,  2.3731]])\n",
      "p21val is 0.837750268932344\n",
      "pf12val is 0.054602147511896\n",
      "chi_f12 is 5.815364130570099\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8925,  2.3729],\n",
      "        [-1.8922,  2.3727],\n",
      "        [-1.8929,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "41\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.093\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 43935.742\n",
      "expected info is tensor([[0.0261]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8930,  2.3732]])\n",
      "new data istensor([[-0.0925, -0.0056]])\n",
      "g_theta2 istensor([[-1.8925,  2.3729],\n",
      "        [-1.8922,  2.3727],\n",
      "        [-1.8929,  2.3731]])\n",
      "p21val is 0.662930644137201\n",
      "pf12val is 0.695528205395913\n",
      "chi_f12 is 0.726167428626190\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8939,  2.3736],\n",
      "        [-1.8917,  2.3724],\n",
      "        [-1.8930,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "42\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.114\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 45232.232\n",
      "expected info is tensor([[0.0252]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3733]])\n",
      "new data istensor([[-0.0895, -0.0300]])\n",
      "g_theta2 istensor([[-1.8939,  2.3736],\n",
      "        [-1.8917,  2.3724],\n",
      "        [-1.8930,  2.3731]])\n",
      "p21val is 0.048306717312351\n",
      "pf12val is 0.435569163683071\n",
      "chi_f12 is 1.662203361743996\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3732],\n",
      "        [-1.8934,  2.3734],\n",
      "        [-1.8931,  2.3732]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "43\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.110\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 46882.221\n",
      "expected info is tensor([[0.0244]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3732]])\n",
      "new data istensor([[-0.0463, -0.0511]])\n",
      "g_theta2 istensor([[-1.8930,  2.3732],\n",
      "        [-1.8934,  2.3734],\n",
      "        [-1.8931,  2.3732]])\n",
      "p21val is 0.664340648493981\n",
      "pf12val is 0.035258525819877\n",
      "chi_f12 is 6.690095823476952\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8932,  2.3732],\n",
      "        [-1.8929,  2.3735],\n",
      "        [-1.8934,  2.3733]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "44\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -3.112\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 48499.405\n",
      "expected info is tensor([[0.0236]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3731]])\n",
      "new data istensor([[-0.0882, -0.0147]])\n",
      "g_theta2 istensor([[-1.8932,  2.3732],\n",
      "        [-1.8929,  2.3735],\n",
      "        [-1.8934,  2.3733]])\n",
      "p21val is 0.619072761407993\n",
      "pf12val is 0.784405624033257\n",
      "chi_f12 is 0.485658029663862\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8938,  2.3723],\n",
      "        [-1.8932,  2.3731],\n",
      "        [-1.8933,  2.3732]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "45\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.125\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 49894.366\n",
      "expected info is tensor([[0.0229]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3730]])\n",
      "new data istensor([[-0.0698,  0.0032]])\n",
      "g_theta2 istensor([[-1.8938,  2.3723],\n",
      "        [-1.8932,  2.3731],\n",
      "        [-1.8933,  2.3732]])\n",
      "p21val is 0.525613604932062\n",
      "pf12val is 0.804086029544752\n",
      "chi_f12 is 0.436098027212270\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8932,  2.3731],\n",
      "        [-1.8929,  2.3733],\n",
      "        [-1.8932,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "46\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.131\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 51441.690\n",
      "expected info is tensor([[0.0222]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3728]])\n",
      "new data istensor([[-0.0718, -0.0213]])\n",
      "g_theta2 istensor([[-1.8932,  2.3731],\n",
      "        [-1.8929,  2.3733],\n",
      "        [-1.8932,  2.3731]])\n",
      "p21val is 0.567751530126347\n",
      "pf12val is 0.810968131602628\n",
      "chi_f12 is 0.419053041653363\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8934,  2.3729],\n",
      "        [-1.8935,  2.3724],\n",
      "        [-1.8932,  2.3726]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "47\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.141\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 52935.735\n",
      "expected info is tensor([[0.0216]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3729]])\n",
      "new data istensor([[-0.0810, -0.0030]])\n",
      "g_theta2 istensor([[-1.8934,  2.3729],\n",
      "        [-1.8935,  2.3724],\n",
      "        [-1.8932,  2.3726]])\n",
      "p21val is 0.133534728676351\n",
      "pf12val is 0.929660179586771\n",
      "chi_f12 is 0.145872315805707\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8935,  2.3727],\n",
      "        [-1.8931,  2.3730],\n",
      "        [-1.8932,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "48\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.142\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 54606.206\n",
      "expected info is tensor([[0.0209]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3727]])\n",
      "new data istensor([[-0.0930,  0.0386]])\n",
      "g_theta2 istensor([[-1.8935,  2.3727],\n",
      "        [-1.8931,  2.3730],\n",
      "        [-1.8932,  2.3729]])\n",
      "p21val is 0.523914859697217\n",
      "pf12val is 0.044526639053637\n",
      "chi_f12 is 6.223335276997687\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8936,  2.3724],\n",
      "        [-1.8932,  2.3728],\n",
      "        [-1.8933,  2.3726]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "49\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.145\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 55927.697\n",
      "expected info is tensor([[0.0204]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3728]])\n",
      "new data istensor([[-0.0686,  0.0102]])\n",
      "g_theta2 istensor([[-1.8936,  2.3724],\n",
      "        [-1.8932,  2.3728],\n",
      "        [-1.8933,  2.3726]])\n",
      "p21val is 0.471839897174365\n",
      "pf12val is 0.611948967966336\n",
      "chi_f12 is 0.982212771245023\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3730],\n",
      "        [-1.8931,  2.3728],\n",
      "        [-1.8930,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "50\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.154\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 57393.171\n",
      "expected info is tensor([[0.0199]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3729]])\n",
      "new data istensor([[-0.0748,  0.0157]])\n",
      "g_theta2 istensor([[-1.8931,  2.3730],\n",
      "        [-1.8931,  2.3728],\n",
      "        [-1.8930,  2.3728]])\n",
      "p21val is 0.683344193003481\n",
      "pf12val is 0.484272584482616\n",
      "chi_f12 is 1.450214679436594\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3730],\n",
      "        [-1.8931,  2.3729],\n",
      "        [-1.8932,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "51\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.162\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 58886.106\n",
      "expected info is tensor([[0.0193]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3730]])\n",
      "new data istensor([[-0.0628, -0.0017]])\n",
      "g_theta2 istensor([[-1.8931,  2.3730],\n",
      "        [-1.8931,  2.3729],\n",
      "        [-1.8932,  2.3728]])\n",
      "p21val is 0.468682206997884\n",
      "pf12val is 0.763280952259854\n",
      "chi_f12 is 0.540258189900329\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8933,  2.3730],\n",
      "        [-1.8934,  2.3729],\n",
      "        [-1.8934,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "52\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.164\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 60484.310\n",
      "expected info is tensor([[0.0188]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3729]])\n",
      "new data istensor([[-0.0175,  0.0097]])\n",
      "g_theta2 istensor([[-1.8933,  2.3730],\n",
      "        [-1.8934,  2.3729],\n",
      "        [-1.8934,  2.3730]])\n",
      "p21val is 0.107505652791813\n",
      "pf12val is 0.009143761461951\n",
      "chi_f12 is 9.389366879336258\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3729],\n",
      "        [-1.8933,  2.3729],\n",
      "        [-1.8932,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "53\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.160\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 61891.665\n",
      "expected info is tensor([[0.0184]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3729]])\n",
      "new data istensor([[-0.0724, -0.0332]])\n",
      "g_theta2 istensor([[-1.8931,  2.3729],\n",
      "        [-1.8933,  2.3729],\n",
      "        [-1.8932,  2.3729]])\n",
      "p21val is 0.795870105605562\n",
      "pf12val is 0.447835187113469\n",
      "chi_f12 is 1.606660000322419\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8932,  2.3730],\n",
      "        [-1.8935,  2.3730],\n",
      "        [-1.8933,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "54\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.167\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 63462.844\n",
      "expected info is tensor([[0.0180]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8934,  2.3729]])\n",
      "new data istensor([[-0.0765,  0.0146]])\n",
      "g_theta2 istensor([[-1.8932,  2.3730],\n",
      "        [-1.8935,  2.3730],\n",
      "        [-1.8933,  2.3729]])\n",
      "p21val is 0.280432977102566\n",
      "pf12val is 0.525554075167142\n",
      "chi_f12 is 1.286604383286103\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8933,  2.3730],\n",
      "        [-1.8935,  2.3729],\n",
      "        [-1.8933,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "55\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.169\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 64836.350\n",
      "expected info is tensor([[0.0175]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3730]])\n",
      "new data istensor([[-0.0431, -0.0042]])\n",
      "g_theta2 istensor([[-1.8933,  2.3730],\n",
      "        [-1.8935,  2.3729],\n",
      "        [-1.8933,  2.3730]])\n",
      "p21val is 0.134352644999113\n",
      "pf12val is 0.270679978251306\n",
      "chi_f12 is 2.613636095932952\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8935,  2.3729],\n",
      "        [-1.8931,  2.3730],\n",
      "        [-1.8933,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "56\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -3.170\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 66177.579\n",
      "expected info is tensor([[0.0171]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3728]])\n",
      "new data istensor([[-0.0675, -0.0127]])\n",
      "g_theta2 istensor([[-1.8935,  2.3729],\n",
      "        [-1.8931,  2.3730],\n",
      "        [-1.8933,  2.3730]])\n",
      "p21val is 0.643847245124710\n",
      "pf12val is 0.895905904926604\n",
      "chi_f12 is 0.219839776689692\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3725],\n",
      "        [-1.8931,  2.3728],\n",
      "        [-1.8933,  2.3727]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "57\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.176\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 67568.547\n",
      "expected info is tensor([[0.0168]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3728]])\n",
      "new data istensor([[-0.0766,  0.0023]])\n",
      "g_theta2 istensor([[-1.8930,  2.3725],\n",
      "        [-1.8931,  2.3728],\n",
      "        [-1.8933,  2.3727]])\n",
      "p21val is 0.057379325590099\n",
      "pf12val is 0.892025142364460\n",
      "chi_f12 is 0.228521920584235\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3727],\n",
      "        [-1.8933,  2.3730],\n",
      "        [-1.8933,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "58\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.180\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 69153.933\n",
      "expected info is tensor([[0.0164]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8934,  2.3727]])\n",
      "new data istensor([[-0.0801, -0.0194]])\n",
      "g_theta2 istensor([[-1.8931,  2.3727],\n",
      "        [-1.8933,  2.3730],\n",
      "        [-1.8933,  2.3728]])\n",
      "p21val is 0.897585569172556\n",
      "pf12val is 0.802998638320180\n",
      "chi_f12 is 0.438804521555121\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8936,  2.3726],\n",
      "        [-1.8932,  2.3726],\n",
      "        [-1.8933,  2.3726]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "59\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.184\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 70680.557\n",
      "expected info is tensor([[0.0160]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8934,  2.3728]])\n",
      "new data istensor([[-0.0360, -0.0295]])\n",
      "g_theta2 istensor([[-1.8936,  2.3726],\n",
      "        [-1.8932,  2.3726],\n",
      "        [-1.8933,  2.3726]])\n",
      "p21val is 0.856035980143910\n",
      "pf12val is 0.078175769778899\n",
      "chi_f12 is 5.097591057637600\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8936,  2.3727],\n",
      "        [-1.8933,  2.3728],\n",
      "        [-1.8933,  2.3726]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "60\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.191\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 72017.977\n",
      "expected info is tensor([[0.0157]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8934,  2.3730]])\n",
      "new data istensor([[-0.0626, -0.0084]])\n",
      "g_theta2 istensor([[-1.8936,  2.3727],\n",
      "        [-1.8933,  2.3728],\n",
      "        [-1.8933,  2.3726]])\n",
      "p21val is 0.211217602828490\n",
      "pf12val is 0.834209470508762\n",
      "chi_f12 is 0.362541488960271\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8936,  2.3725],\n",
      "        [-1.8935,  2.3729],\n",
      "        [-1.8934,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "61\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.194\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 73356.867\n",
      "expected info is tensor([[0.0154]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3730]])\n",
      "new data istensor([[-0.1028, -0.0103]])\n",
      "g_theta2 istensor([[-1.8936,  2.3725],\n",
      "        [-1.8935,  2.3729],\n",
      "        [-1.8934,  2.3731]])\n",
      "p21val is 0.863731037789346\n",
      "pf12val is 0.362655530843988\n",
      "chi_f12 is 2.028603692198389\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8937,  2.3722],\n",
      "        [-1.8938,  2.3723],\n",
      "        [-1.8934,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "62\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.201\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 74861.586\n",
      "expected info is tensor([[0.0150]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3729]])\n",
      "new data istensor([[-0.0957, -0.0093]])\n",
      "g_theta2 istensor([[-1.8937,  2.3722],\n",
      "        [-1.8938,  2.3723],\n",
      "        [-1.8934,  2.3729]])\n",
      "p21val is 0.647431075178560\n",
      "pf12val is 0.574571740758835\n",
      "chi_f12 is 1.108260628730813\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8942,  2.3715],\n",
      "        [-1.8936,  2.3724],\n",
      "        [-1.8935,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "63\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.206\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 76446.854\n",
      "expected info is tensor([[0.0147]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3730]])\n",
      "new data istensor([[-0.0489, -0.0003]])\n",
      "g_theta2 istensor([[-1.8942,  2.3715],\n",
      "        [-1.8936,  2.3724],\n",
      "        [-1.8935,  2.3730]])\n",
      "p21val is 0.960159001700050\n",
      "pf12val is 0.406939585744615\n",
      "chi_f12 is 1.798181085062932\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8934,  2.3729],\n",
      "        [-1.8923,  2.3747],\n",
      "        [-1.8932,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "64\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.216\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 77935.700\n",
      "expected info is tensor([[0.0145]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3730]])\n",
      "new data istensor([[-0.0388, -0.0354]])\n",
      "g_theta2 istensor([[-1.8934,  2.3729],\n",
      "        [-1.8923,  2.3747],\n",
      "        [-1.8932,  2.3730]])\n",
      "p21val is 0.922577920944222\n",
      "pf12val is 0.070864826973129\n",
      "chi_f12 is 5.293962124013969\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8932,  2.3730],\n",
      "        [-1.8936,  2.3722],\n",
      "        [-1.8931,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "65\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.217\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 79355.572\n",
      "expected info is tensor([[0.0142]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3729]])\n",
      "new data istensor([[-6.7991e-02,  3.4441e-05]])\n",
      "g_theta2 istensor([[-1.8932,  2.3730],\n",
      "        [-1.8936,  2.3722],\n",
      "        [-1.8931,  2.3729]])\n",
      "p21val is 0.727521876381778\n",
      "pf12val is 0.893451639482336\n",
      "chi_f12 is 0.225326141314751\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8935,  2.3723],\n",
      "        [-1.8932,  2.3730],\n",
      "        [-1.8931,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "66\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.223\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 80718.917\n",
      "expected info is tensor([[0.0139]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3729]])\n",
      "new data istensor([[-0.0270,  0.0170]])\n",
      "g_theta2 istensor([[-1.8935,  2.3723],\n",
      "        [-1.8932,  2.3730],\n",
      "        [-1.8931,  2.3730]])\n",
      "p21val is 0.568229840790027\n",
      "pf12val is 0.029966800245491\n",
      "chi_f12 is 7.015330337204504\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3728],\n",
      "        [-1.8931,  2.3729],\n",
      "        [-1.8932,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "67\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.224\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 82165.467\n",
      "expected info is tensor([[0.0137]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3728]])\n",
      "new data istensor([[-0.0890, -0.0184]])\n",
      "g_theta2 istensor([[-1.8930,  2.3728],\n",
      "        [-1.8931,  2.3729],\n",
      "        [-1.8932,  2.3728]])\n",
      "p21val is 0.137117769370416\n",
      "pf12val is 0.636672371400990\n",
      "chi_f12 is 0.903000172668045\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3728],\n",
      "        [-1.8931,  2.3727],\n",
      "        [-1.8931,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "68\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -3.225\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 83797.922\n",
      "expected info is tensor([[0.0134]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3728]])\n",
      "new data istensor([[-0.0833, -0.0148]])\n",
      "g_theta2 istensor([[-1.8931,  2.3728],\n",
      "        [-1.8931,  2.3727],\n",
      "        [-1.8931,  2.3728]])\n",
      "p21val is 0.921329103514146\n",
      "pf12val is 0.829255183461488\n",
      "chi_f12 is 0.374454700783783\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8933,  2.3728],\n",
      "        [-1.8933,  2.3728],\n",
      "        [-1.8933,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "69\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.233\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 85144.328\n",
      "expected info is tensor([[0.0132]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3727]])\n",
      "new data istensor([[-0.0793,  0.0120]])\n",
      "g_theta2 istensor([[-1.8933,  2.3728],\n",
      "        [-1.8933,  2.3728],\n",
      "        [-1.8933,  2.3728]])\n",
      "p21val is 0.933217929274359\n",
      "pf12val is 0.629018689473706\n",
      "chi_f12 is 0.927188619456711\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8932,  2.3727],\n",
      "        [-1.8936,  2.3729],\n",
      "        [-1.8932,  2.3727]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "70\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.236\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 86488.613\n",
      "expected info is tensor([[0.0130]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3730]])\n",
      "new data istensor([[-0.1135, -0.0407]])\n",
      "g_theta2 istensor([[-1.8932,  2.3727],\n",
      "        [-1.8936,  2.3729],\n",
      "        [-1.8932,  2.3727]])\n",
      "p21val is 0.765041733034592\n",
      "pf12val is 0.032860139261852\n",
      "chi_f12 is 6.830989856692653\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8928,  2.3730],\n",
      "        [-1.8927,  2.3731],\n",
      "        [-1.8930,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "71\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.240\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 88106.723\n",
      "expected info is tensor([[0.0128]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3729]])\n",
      "new data istensor([[-0.0896, -0.0270]])\n",
      "g_theta2 istensor([[-1.8928,  2.3730],\n",
      "        [-1.8927,  2.3731],\n",
      "        [-1.8930,  2.3731]])\n",
      "p21val is 0.117593373604924\n",
      "pf12val is 0.433868965045399\n",
      "chi_f12 is 1.670025428656890\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3729],\n",
      "        [-1.8934,  2.3729],\n",
      "        [-1.8930,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "72\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.236\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 89567.863\n",
      "expected info is tensor([[0.0125]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3730]])\n",
      "new data istensor([[-0.1177, -0.0240]])\n",
      "g_theta2 istensor([[-1.8931,  2.3729],\n",
      "        [-1.8934,  2.3729],\n",
      "        [-1.8930,  2.3730]])\n",
      "p21val is 0.984577510265823\n",
      "pf12val is 0.063364236645849\n",
      "chi_f12 is 5.517711334914968\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8933,  2.3729],\n",
      "        [-1.8929,  2.3730],\n",
      "        [-1.8929,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "73\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.242\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 90977.447\n",
      "expected info is tensor([[0.0124]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8930,  2.3730]])\n",
      "new data istensor([[-0.0505,  0.0130]])\n",
      "g_theta2 istensor([[-1.8933,  2.3729],\n",
      "        [-1.8929,  2.3730],\n",
      "        [-1.8929,  2.3731]])\n",
      "p21val is 0.185674377766800\n",
      "pf12val is 0.310947245024248\n",
      "chi_f12 is 2.336264022677673\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3729],\n",
      "        [-1.8930,  2.3730],\n",
      "        [-1.8931,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "74\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.241\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 92377.238\n",
      "expected info is tensor([[0.0121]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8930,  2.3732]])\n",
      "new data istensor([[-0.0599, -0.0163]])\n",
      "g_theta2 istensor([[-1.8930,  2.3729],\n",
      "        [-1.8930,  2.3730],\n",
      "        [-1.8931,  2.3728]])\n",
      "p21val is 0.746210542710477\n",
      "pf12val is 0.685662549454678\n",
      "chi_f12 is 0.754739365399585\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3731],\n",
      "        [-1.8930,  2.3730],\n",
      "        [-1.8931,  2.3732]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "75\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.247\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 93956.832\n",
      "expected info is tensor([[0.0120]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3732]])\n",
      "new data istensor([[-0.0896, -0.0040]])\n",
      "g_theta2 istensor([[-1.8930,  2.3731],\n",
      "        [-1.8930,  2.3730],\n",
      "        [-1.8931,  2.3732]])\n",
      "p21val is 0.167314815509118\n",
      "pf12val is 0.731546198824341\n",
      "chi_f12 is 0.625189808457368\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3730],\n",
      "        [-1.8931,  2.3731],\n",
      "        [-1.8933,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "76\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.249\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 95401.968\n",
      "expected info is tensor([[0.0118]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8930,  2.3730]])\n",
      "new data istensor([[-0.0676, -0.0102]])\n",
      "g_theta2 istensor([[-1.8930,  2.3730],\n",
      "        [-1.8931,  2.3731],\n",
      "        [-1.8933,  2.3731]])\n",
      "p21val is 0.408082649510133\n",
      "pf12val is 0.937038871171967\n",
      "chi_f12 is 0.130061025791145\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3730],\n",
      "        [-1.8931,  2.3731],\n",
      "        [-1.8932,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "77\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.252\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 96891.422\n",
      "expected info is tensor([[0.0116]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3727]])\n",
      "new data istensor([[-0.0947, -0.0088]])\n",
      "g_theta2 istensor([[-1.8930,  2.3730],\n",
      "        [-1.8931,  2.3731],\n",
      "        [-1.8932,  2.3730]])\n",
      "p21val is 0.039079830716947\n",
      "pf12val is 0.575604827312334\n",
      "chi_f12 is 1.104667834859004\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3725],\n",
      "        [-1.8929,  2.3733],\n",
      "        [-1.8931,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "78\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.249\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 98388.470\n",
      "expected info is tensor([[0.0114]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3728]])\n",
      "new data istensor([[-0.0702,  0.0129]])\n",
      "g_theta2 istensor([[-1.8931,  2.3725],\n",
      "        [-1.8929,  2.3733],\n",
      "        [-1.8931,  2.3728]])\n",
      "p21val is 0.138528018674542\n",
      "pf12val is 0.609928578840806\n",
      "chi_f12 is 0.988826825074324\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3730],\n",
      "        [-1.8932,  2.3726],\n",
      "        [-1.8928,  2.3727]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "79\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.249\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 99897.537\n",
      "expected info is tensor([[0.0112]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3728]])\n",
      "new data istensor([[-0.0828, -0.0002]])\n",
      "g_theta2 istensor([[-1.8931,  2.3730],\n",
      "        [-1.8932,  2.3726],\n",
      "        [-1.8928,  2.3727]])\n",
      "p21val is 0.025486713394477\n",
      "pf12val is 0.850663743507164\n",
      "chi_f12 is 0.323476719015001\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3729],\n",
      "        [-1.8931,  2.3726],\n",
      "        [-1.8929,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "80\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -3.244\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 101282.798\n",
      "expected info is tensor([[0.0111]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8930,  2.3729]])\n",
      "new data istensor([[-0.0665,  0.0242]])\n",
      "g_theta2 istensor([[-1.8931,  2.3729],\n",
      "        [-1.8931,  2.3726],\n",
      "        [-1.8929,  2.3728]])\n",
      "p21val is 0.247196648756006\n",
      "pf12val is 0.296581415628235\n",
      "chi_f12 is 2.430867018543254\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3729],\n",
      "        [-1.8928,  2.3734],\n",
      "        [-1.8931,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "81\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.246\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 102421.500\n",
      "expected info is tensor([[0.0109]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8929,  2.3730]])\n",
      "new data istensor([[-0.0674, -0.0151]])\n",
      "g_theta2 istensor([[-1.8930,  2.3729],\n",
      "        [-1.8928,  2.3734],\n",
      "        [-1.8931,  2.3729]])\n",
      "p21val is 0.952067930460042\n",
      "pf12val is 0.872118864995114\n",
      "chi_f12 is 0.273659102590297\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8929,  2.3730],\n",
      "        [-1.8928,  2.3735],\n",
      "        [-1.8929,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "82\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.254\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 103988.168\n",
      "expected info is tensor([[0.0108]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3731]])\n",
      "new data istensor([[-0.1084, -0.0359]])\n",
      "g_theta2 istensor([[-1.8929,  2.3730],\n",
      "        [-1.8928,  2.3735],\n",
      "        [-1.8929,  2.3730]])\n",
      "p21val is 0.675712147709765\n",
      "pf12val is 0.070593942647356\n",
      "chi_f12 is 5.301621872719823\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3733],\n",
      "        [-1.8930,  2.3732],\n",
      "        [-1.8930,  2.3730]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "83\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.254\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 105604.603\n",
      "expected info is tensor([[0.0106]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3731]])\n",
      "new data istensor([[-0.0688,  0.0071]])\n",
      "g_theta2 istensor([[-1.8930,  2.3733],\n",
      "        [-1.8930,  2.3732],\n",
      "        [-1.8930,  2.3730]])\n",
      "p21val is 0.888776785402466\n",
      "pf12val is 0.780267974664901\n",
      "chi_f12 is 0.496235722076177\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3732],\n",
      "        [-1.8931,  2.3730],\n",
      "        [-1.8933,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "84\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.259\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 107088.977\n",
      "expected info is tensor([[0.0105]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8932,  2.3730]])\n",
      "new data istensor([[-0.0786,  0.0009]])\n",
      "g_theta2 istensor([[-1.8930,  2.3732],\n",
      "        [-1.8931,  2.3730],\n",
      "        [-1.8933,  2.3731]])\n",
      "p21val is 0.678007917569318\n",
      "pf12val is 0.903036246629597\n",
      "chi_f12 is 0.203985172277274\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3731],\n",
      "        [-1.8932,  2.3729],\n",
      "        [-1.8931,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "85\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.264\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 108427.565\n",
      "expected info is tensor([[0.0103]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3728]])\n",
      "new data istensor([[-0.0834, -0.0042]])\n",
      "g_theta2 istensor([[-1.8931,  2.3731],\n",
      "        [-1.8932,  2.3729],\n",
      "        [-1.8931,  2.3731]])\n",
      "p21val is 0.873145157704754\n",
      "pf12val is 0.872041927560756\n",
      "chi_f12 is 0.273835548327950\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8932,  2.3733],\n",
      "        [-1.8932,  2.3728],\n",
      "        [-1.8932,  2.3728]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "86\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.269\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 109863.755\n",
      "expected info is tensor([[0.0102]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8930,  2.3729]])\n",
      "new data istensor([[-0.0564, -0.0078]])\n",
      "g_theta2 istensor([[-1.8932,  2.3733],\n",
      "        [-1.8932,  2.3728],\n",
      "        [-1.8932,  2.3728]])\n",
      "p21val is 0.637524071246012\n",
      "pf12val is 0.701409068808111\n",
      "chi_f12 is 0.709328023557297\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3727],\n",
      "        [-1.8930,  2.3727],\n",
      "        [-1.8931,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "87\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.274\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 111494.949\n",
      "expected info is tensor([[0.0100]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3729]])\n",
      "new data istensor([[-0.0628, -0.0401]])\n",
      "g_theta2 istensor([[-1.8930,  2.3727],\n",
      "        [-1.8930,  2.3727],\n",
      "        [-1.8931,  2.3731]])\n",
      "p21val is 0.433215995996684\n",
      "pf12val is 0.209208284974695\n",
      "chi_f12 is 3.128849888892074\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3728],\n",
      "        [-1.8932,  2.3731],\n",
      "        [-1.8932,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "88\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.265\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 112991.514\n",
      "expected info is tensor([[0.0099]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3731]])\n",
      "new data istensor([[-0.0965, -0.0569]])\n",
      "g_theta2 istensor([[-1.8931,  2.3728],\n",
      "        [-1.8932,  2.3731],\n",
      "        [-1.8932,  2.3729]])\n",
      "p21val is 0.197007181478219\n",
      "pf12val is 0.021000351834244\n",
      "chi_f12 is 7.726432174774862\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8931,  2.3729],\n",
      "        [-1.8931,  2.3734],\n",
      "        [-1.8932,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "89\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.269\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 114551.275\n",
      "expected info is tensor([[0.0098]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8935,  2.3731]])\n",
      "new data istensor([[-0.0619,  0.0067]])\n",
      "g_theta2 istensor([[-1.8931,  2.3729],\n",
      "        [-1.8931,  2.3734],\n",
      "        [-1.8932,  2.3731]])\n",
      "p21val is 0.497244404278955\n",
      "pf12val is 0.693244910997115\n",
      "chi_f12 is 0.732743870607014\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8936,  2.3730],\n",
      "        [-1.8935,  2.3724],\n",
      "        [-1.8935,  2.3733]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "90\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.272\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 115843.574\n",
      "expected info is tensor([[0.0096]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8934,  2.3731]])\n",
      "new data istensor([[-0.0491, -0.0235]])\n",
      "g_theta2 istensor([[-1.8936,  2.3730],\n",
      "        [-1.8935,  2.3724],\n",
      "        [-1.8935,  2.3733]])\n",
      "p21val is 0.014633191942511\n",
      "pf12val is 0.348400313248966\n",
      "chi_f12 is 2.108806269793887\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8933,  2.3734],\n",
      "        [-1.8934,  2.3740],\n",
      "        [-1.8936,  2.3732]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "91\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.196\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 117418.040\n",
      "expected info is tensor([[0.0095]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3729]])\n",
      "new data istensor([[-0.0796, -0.0192]])\n",
      "g_theta2 istensor([[-1.8933,  2.3734],\n",
      "        [-1.8934,  2.3740],\n",
      "        [-1.8936,  2.3732]])\n",
      "p21val is 0.018580285478945\n",
      "pf12val is 0.777886184599199\n",
      "chi_f12 is 0.502350115588908\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8934,  2.3735],\n",
      "        [-1.8933,  2.3735],\n",
      "        [-1.8933,  2.3731]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "92\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is -3.264\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 118948.764\n",
      "expected info is tensor([[0.0094]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3729]])\n",
      "new data istensor([[-0.0906, -0.0054]])\n",
      "g_theta2 istensor([[-1.8934,  2.3735],\n",
      "        [-1.8933,  2.3735],\n",
      "        [-1.8933,  2.3731]])\n",
      "p21val is 0.873679491873994\n",
      "pf12val is 0.670611506521914\n",
      "chi_f12 is 0.799130573099548\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8934,  2.3737],\n",
      "        [-1.8933,  2.3729],\n",
      "        [-1.8933,  2.3729]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "93\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.266\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 120460.943\n",
      "expected info is tensor([[0.0093]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8933,  2.3728]])\n",
      "new data istensor([[-0.0321,  0.0103]])\n",
      "g_theta2 istensor([[-1.8934,  2.3737],\n",
      "        [-1.8933,  2.3729],\n",
      "        [-1.8933,  2.3729]])\n",
      "p21val is 0.671312540701624\n",
      "pf12val is 0.086669637573403\n",
      "chi_f12 is 4.891303315058280\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8933,  2.3734],\n",
      "        [-1.8934,  2.3740],\n",
      "        [-1.8934,  2.3725]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "94\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.270\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n",
      "Loss design: 121898.755\n",
      "expected info is tensor([[0.0092]], grad_fn=<ReshapeAliasBackward0>)\n",
      "current sol istensor([[-1.8931,  2.3726]])\n",
      "new data istensor([[-0.0986,  0.0038]])\n",
      "g_theta2 istensor([[-1.8933,  2.3734],\n",
      "        [-1.8934,  2.3740],\n",
      "        [-1.8934,  2.3725]])\n",
      "p21val is 0.697322146732758\n",
      "pf12val is 0.377787850076848\n",
      "chi_f12 is 1.946844968202801\n",
      "p_val_ftarget is 0.0\n",
      "new 2 points\n",
      "tensor([[-1.8930,  2.3721],\n",
      "        [-1.8928,  2.3714],\n",
      "        [-1.8931,  2.3727]])\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "95\n",
      "START HYPERPARAMETERS optimization\n",
      "Using CUDA\n",
      "loss is -3.272\n",
      "END HYPERPARAMETERS optimization\n",
      "Using CUDA for conduct_design_opti()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     90\u001b[0m likelihood\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 93\u001b[0m x0_new,g_theta2, loss, pf1, Qf1, Qf12, data_fit, Q21 \u001b[38;5;241m=\u001b[39m \u001b[43mconduct_design_opti\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_theta1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magg_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_design\u001b[49m\u001b[43m,\u001b[49m\u001b[43miter_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnoise_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m cur_model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     96\u001b[0m cur_likelihood \u001b[38;5;241m=\u001b[39m likelihood\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mconduct_design_opti\u001b[0;34m(x0, loc_sample, f_target, g_theta1, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new, noise_value)\u001b[0m\n\u001b[1;32m     41\u001b[0m loss2, pf1, Qf1, Qf12, data_fit, Q21 \u001b[38;5;241m=\u001b[39m likelihood\u001b[38;5;241m.\u001b[39mget_ell(agg_data,f_target,x_d, g_theta1, model, likelihood, g_theta2, cov_noise1, cov_noise2)\n\u001b[1;32m     43\u001b[0m loss2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m*\u001b[39m loss2\n\u001b[0;32m---> 45\u001b[0m \u001b[43mloss2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#scheduler.step(loss2)\u001b[39;00m\n",
      "File \u001b[0;32m/lus/theta-fs0/software/thetagpu/conda/2022-07-01/mconda3/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lus/theta-fs0/software/thetagpu/conda/2022-07-01/mconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loc_sample = loc_sample0.clone()\n",
    "iter_hp = 50\n",
    "iter_design = 200\n",
    "iter_param = 200\n",
    "num_base_kernels = 2\n",
    "max_iter = 50\n",
    "\n",
    "\n",
    "f_target = f_target.reshape(2,1) \n",
    "tol_vector = 0.01 * torch.ones(f_target.shape)\n",
    "\n",
    "plot_freq = 1\n",
    "\n",
    "\n",
    " #np.random.random_sample((loc_size,2))\n",
    "#loc_sample = (loc_sample - loc_sample.mean())/loc_sample.std(dim=-2, keepdim=True)\n",
    "#train_x = (train_x - train_x.mean())/train_x.std(dim=-2, keepdim=True)\n",
    "\n",
    "#loc_sample = Tensor([[0.0, 0.1], [0.0, -0.1]]) #T\n",
    "# loc_x = (-1.5 + 2.)  * np.random.random_sample((loc_size,1)) +2.\n",
    "\n",
    "# # loc_y = (2. - 1.5)  * np.random.random_sample((loc_size,1)) - 1.5\n",
    "# # loc = np.concatenate((loc_x, loc_y), 1)\n",
    "print(loc_sample)\n",
    "\n",
    "\n",
    "g_theta2_vec = (Tensor(loc_sample).clone()).flatten()\n",
    "\n",
    "data_fit_vec = torch.empty((1,1))\n",
    "entropy_vec = torch.empty((1,1))\n",
    "loss_vec = torch.empty((1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "vec_x = x0.clone() #Tensor(np.array([0.0,0.0])) \n",
    "vec_x = vec_x.reshape(1,2)\n",
    "var_vec = torch.zeros([max_iter, 1])\n",
    "p21_vec = torch.empty((1,1))\n",
    "\n",
    "lr_new = .01\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    "show_TTRBox = False\n",
    "iter = 0    \n",
    "g_theta1 = x_train\n",
    "agg_data = y_train.flatten()\n",
    "patience = 0.0\n",
    "patience_f = 0.0\n",
    "patience_2 = 0.0\n",
    "checking_model = False\n",
    "model_double_check = False\n",
    "\n",
    "\n",
    "\n",
    "while(SUCCESS == False and FAILURE == False):\n",
    "    print(iter)\n",
    "    model_double_check = False\n",
    "    if (checking_model == False):\n",
    "        print('START HYPERPARAMETERS optimization')\n",
    "        if (iter == 0):\n",
    "            cur_model = None\n",
    "            cur_likelihood = None\n",
    "\n",
    "\n",
    "        loc_sample_old = loc_sample.clone()\n",
    "        x0_old = x0.clone()\n",
    "        model, likelihood = hyper_opti(g_theta1,agg_data,iter_hp,num_base_kernels,noise_value, current_model = cur_model, current_likelihood = cur_likelihood)\n",
    "\n",
    "        \n",
    "# Before this is hyper_opti\n",
    "\n",
    "        print('END HYPERPARAMETERS optimization')\n",
    "    \n",
    "   \n",
    "\n",
    " #     model = model.cpu()\n",
    "#     likelihood = likelihood.cpu()\n",
    "#     g_theta1 = g_theta1.cpu()\n",
    "#     agg_data = agg_data.cpu()\n",
    "        \n",
    "#     \"\"\"end for CPU\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "   \n",
    "    \n",
    "    x0_new,g_theta2, loss, pf1, Qf1, Qf12, data_fit, Q21 = conduct_design_opti(x0, loc_sample, f_target, g_theta1, agg_data, model, likelihood, iter_design,iter_param, lr_new,noise_value)\n",
    "  \n",
    "    cur_model = model\n",
    "    cur_likelihood = likelihood\n",
    "    \n",
    "  \n",
    "    lower_bound = torch.zeros(pf1.shape)\n",
    "    upper_bound = torch.zeros(pf1.shape)\n",
    "        \n",
    "    for i in range(pf1.shape[0]):\n",
    "        lower_bound[i] = pf1[i] -  torch.sqrt(Qf12[i,i])\n",
    "        upper_bound[i] = pf1[i] +  torch.sqrt(Qf12[i,i])\n",
    "\n",
    "    SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "    \n",
    "    \n",
    "    \"\"\"Put everything back to CPU here\"\"\"\n",
    "    model = model.cpu()\n",
    "    likelihood = likelihood.cpu()\n",
    "    g_theta1 = g_theta1.cpu()\n",
    "    agg_data = agg_data.cpu()\n",
    "    \n",
    "#     cov_noise1 = cov_noise1.cpu()\n",
    "#     cov_noise2 = cov_noise2.cpu()\n",
    "#     g_theta1 = g_theta1.cuda()\n",
    "    g_theta2 = g_theta2.cpu()\n",
    "#     agg_data = agg_data.cuda()\n",
    "#     x_d = x_d.cpu()\n",
    "    f_target = f_target.cpu()\n",
    "    \n",
    "    \n",
    "    x0_new, loss, pf1, Qf1, Qf12, data_fit, Q21 = x0_new.cpu(), loss.cpu(), pf1.cpu(), Qf1.cpu(),Qf12.cpu(),data_fit.cpu(),Q21.cpu()\n",
    "    \"\"\"End of putting everything back to CPU\"\"\"\n",
    "    \n",
    "    entropy = ( 0.5 * torch.log( torch.det(Qf1.evaluate()) / torch.det(Qf12.evaluate()) ) ).reshape(1,1)\n",
    "    \n",
    "    print('expected info is '+str(entropy))\n",
    "    \n",
    "    if not SUCCESS:\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        new_data = vfield_(g_theta2.detach())  \n",
    "        agg_data12 = torch.cat([agg_data, new_data.flatten()], 0)\n",
    "        g_theta12= torch.cat([g_theta1, g_theta2.detach()], 0)\n",
    "        new_data_x = vfield_(x0_new.detach() )  \n",
    "        print('current sol is'+str(x0_new.detach()))\n",
    "        print('new data is' + str(new_data_x))\n",
    "        print('g_theta2 is' + str(g_theta2.detach()))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            \n",
    "            if iter >= 0:\n",
    "                \n",
    "                \n",
    "                p21 = likelihood.get_p21(g_theta1, g_theta2.detach(), agg_data, model, noise_value)\n",
    "                \n",
    "#                 Q21 = Q21 + noise_value*torch.eye(Q21.shape[0])\n",
    "                chi_21 = (Q21).inv_quad(new_data.flatten() - p21.reshape(new_data.flatten().shape))\n",
    "                p_val = 1. - stats.chi2.cdf(chi_21, Q21.shape[0])\n",
    "                pf12 = likelihood.get_pf12(Q21,g_theta1, g_theta2.detach(), x0_new.detach(), new_data.flatten(), pf1, p21, model, noise_value)\n",
    "               \n",
    "                #Qf12 = Qf12 + \n",
    "                chi_f12 = (Qf12 + noise_value*torch.eye(Qf12.shape[0])).inv_quad(new_data_x.flatten() - pf12.reshape(new_data_x.flatten().shape))\n",
    "                p_val_f12 = 1. - stats.chi2.cdf(chi_f12, Qf12.shape[0])\n",
    "                print('p21val is %.15f' %p_val)\n",
    "                p21_vec = torch.cat([p21_vec, Tensor([p_val]).reshape(1,1)], 0)\n",
    "                print('pf12val is %.15f' %p_val_f12)\n",
    "                print('chi_f12 is %.15f' %chi_f12 )\n",
    "                \n",
    "                if (p_val < 0.01):# or p_val_f12 < 0.001:\n",
    "                    model_double_check = True\n",
    "                    checking_model = True\n",
    "                    patience = patience+1\n",
    "                    print('patience is %.3f' %patience)\n",
    "\n",
    "                if (model_double_check == True):\n",
    "                    #loc_sample = Tensor(high_minus_low  * np.random.random_sample((loc_sample.shape[0],2)) + vf.low)\n",
    "                    sum = torch.zeros(2, 2) #replace with num_tasks\n",
    "                    mean_2 = torch.mean(g_theta2.detach(), 0, True)\n",
    "                    for i in range(loc_size):\n",
    "                        #sum =sum + torch.matmul((g_theta2.detach()[i] -mean_2).t(), ( g_theta2.detach()[i] - mean_2 ) )# sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) #sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) # \n",
    "                        sum =sum + torch.matmul((g_theta2.detach()[i] -x0_old).t(), (g_theta2.detach()[i] - x0_old) ) #sum + torch.matmul((g_theta2.detach()[i] -\n",
    "                    emp_cov = 1./loc_size * sum #+ torch.eye(sum.shape[0]) * 1e-8\n",
    "\n",
    "                    dis_2sample = MultivariateNormal( loc = x0_old, covariance_matrix=emp_cov )\n",
    "                    #loc_size = 4\n",
    "                    loc_sample = dis_2sample.sample((loc_size,))\n",
    "\n",
    "                    loc_sample = loc_sample.reshape(loc_size, 2)\n",
    "                    loc_sample = torch.cat([loc_sample, x0_old],0)\n",
    "                    \n",
    "                    x0 = x0_old #Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low)\n",
    "                    if (patience >= 2):# or patience_2 >= 2 or patience_f >= 2):\n",
    "                        PATH = \".//model_Carlo/model_update/model_base_\"+str(iter)+\".pt\"\n",
    "                        torch.save(model, PATH)\n",
    "                        \n",
    "#                         print(entropy_vec.device()) torch.device() object is not callable error\n",
    "#                         print(entropy.device())\n",
    "                        \n",
    "                        entropy_vec = torch.cat([entropy_vec, entropy], 0)\n",
    "                        data_fit_vec = torch.cat([data_fit_vec, data_fit], 0)\n",
    "                        iter = iter + 1\n",
    "                        patience = 0\n",
    "#                         patience_2 = 0\n",
    "#                         patience_f = 0\n",
    "                        model_double_check = False\n",
    "                        checking_model = False\n",
    "                        num_base_kernels = num_base_kernels + 1\n",
    "                        print('adding complexity to model')\n",
    "                        print('num base is' + str(num_base_kernels))\n",
    "#     #                         \n",
    "                        loc_sample = loc_sample_old\n",
    "                        #x0 = x0_old\n",
    "                        agg_data = agg_data12.clone()\n",
    "                        g_theta1 = g_theta12.clone()\n",
    "                        vec_x = torch.cat([vec_x, x0_new.detach()])\n",
    "                        g_theta2_vec = torch.cat([g_theta2_vec, g_theta2.detach().flatten()], 0)\n",
    "                        print('acquiring 2, new size is' + str(g_theta1.shape[0]))\n",
    "                 \n",
    "                    #iter_hp = iter_hp + 10\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                else:\n",
    "                    PATH = \".//model_Carlo/model_goodmodel/model_base_\"+str(iter)+\".pt\"\n",
    "                    torch.save(model, PATH)\n",
    "                    vec_x = torch.cat([vec_x, x0_new.detach()])\n",
    "                    loss_vec = torch.cat([loss_vec, -loss])\n",
    "                    g_theta2_vec = torch.cat([g_theta2_vec, g_theta2.detach().flatten()], 0)\n",
    "                    entropy_vec = torch.cat([entropy_vec, entropy], 0)\n",
    "                    data_fit_vec = torch.cat([data_fit_vec, data_fit], 0)\n",
    "                    model_double_check = False\n",
    "                    iter = iter + 1\n",
    "                    patience = 0\n",
    "                    patience_2 = 0\n",
    "                    patience_f = 0\n",
    "                    checking_model = False\n",
    "                    if (entropy < 1e-4 * tol_vector[0,0]):\n",
    "                        FAILURE = True\n",
    "                    \n",
    "                    x0 = (x0_new.detach())# + torch.randn(x0_new.detach().size()) * .001)#/torch.norm(x0_new.detach())\n",
    "                    sum = torch.zeros(2, 2)\n",
    "                    mean_2 = torch.mean(g_theta2.detach(), 0, True)\n",
    "\n",
    "                    for i in range(loc_size):\n",
    "                        #sum =sum + torch.matmul((g_theta2.detach()[i] -mean_2).t(), ( g_theta2.detach()[i] - mean_2 ) )# sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) #sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) # \n",
    "                        sum =sum + torch.matmul((g_theta2.detach()[i] -x0_new.detach()).t(), (g_theta2.detach()[i] - x0_new.detach()) ) #sum + torch.matmul((g_theta2.detach()[i] -\n",
    "                    emp_cov = 1./loc_size * sum# + torch.eye(sum.shape[0]) * 1e-8\n",
    "\n",
    "                    dis_2sample = MultivariateNormal( loc = x0_new.detach(), covariance_matrix=emp_cov )\n",
    "                    #loc_size = 4\n",
    "                    loc_sample = dis_2sample.sample((loc_size,))\n",
    "\n",
    "                    loc_sample = loc_sample.reshape(loc_size, 2)\n",
    "                    #loc_sample = loc_sample#/torch.norm(loc_sample)\n",
    "                    #loc_sample = 2. *  (loc_sample - torch.min(loc_sample)) / (torch.max(loc_sample) - torch.min(loc_sample)) - 1.\n",
    "                    #loc_sample[0] = x0_new.detach() #+ torch.randn(x0_new.detach().size()) * .001 #g_theta2.detach() #loc_sample.reshape(loc_size, 2)\n",
    "                    #loc_sample = Tensor(high_minus_low  * np.random.random_sample((loc_size,2)) + vf.low)\n",
    "                    loc_sample = torch.cat([loc_sample, x0_new.detach()],0)\n",
    "                    for i in range(loc_sample.shape[0]):\n",
    "                        if loc_sample[i,0] < -3. or loc_sample[i,0] > 3. or loc_sample[i,1] < -3. or loc_sample[i,1] > 3.:\n",
    "                            print('samples escaped box')\n",
    "                            loc_sample[i] = Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low)\n",
    "                    \n",
    "                    \n",
    "#                     if p_val > 0.99 and p_val_f12 > 0.99:\n",
    "#                         num_base_kernels = max(num_base_kernels - 1, 3)\n",
    "                        #iter_hp = iter_hp - 10\n",
    "                    chi_f_target = (Qf12 ).inv_quad(f_target - pf1)\n",
    "                    p_val_f_target = 1. - stats.chi2.cdf(chi_f_target, Qf12.shape[0])\n",
    "                    print('p_val_ftarget is '+str(p_val_f_target))\n",
    "                    if (p_val_f_target > .95):\n",
    "                        print('acquiring target point becuse p_val_ftarget is '+str(p_val_f_target))\n",
    "                        agg_data = agg_data12.clone()\n",
    "                        g_theta1 = g_theta12.clone()\n",
    "        \n",
    "\n",
    "                        x0 = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .0001\n",
    "                        loc_sample[-1] = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .0001\n",
    "                        agg_data = torch.cat([agg_data12, new_data_x.flatten()], 0)\n",
    "                        g_theta1= torch.cat([g_theta12, x0_new.detach()], 0)\n",
    "                    else:\n",
    "#                         x0 = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .001\n",
    "#                         loc_sample[-1] = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .001\n",
    "#                         agg_data = torch.cat([agg_data12, new_data_x.flatten()], 0)\n",
    "#                         g_theta1= torch.cat([g_theta12, x0_new.detach()], 0)\n",
    "                       \n",
    "                        agg_data = agg_data12.clone()\n",
    "                        g_theta1 = g_theta12.clone()\n",
    "                        x0 = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .0001\n",
    "                        loc_sample[-1] = (x0_new.detach()) + torch.randn(x0_new.detach().size()) * .0001\n",
    "                        agg_data = torch.cat([agg_data12, new_data_x.flatten()], 0)\n",
    "                        g_theta1= torch.cat([g_theta12, x0_new.detach()], 0)\n",
    "                        \n",
    "                    if x0_new.detach()[0,0] < -3. or x0_new.detach()[0,0] > 3. or x0_new.detach()[0,1] < -3. or x0_new.detach()[0,1] > 3.:\n",
    "#                         x0 = Tensor(np.array([0.0,-1.0])) # 1./3. * Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "#                         x0 = x0.reshape(1,2) \n",
    "                        #x0 = Tensor(np.array([-2. , 2.]))\n",
    " # 1./3. * Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "                        x0 = Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "                        x0 = x0.reshape(1,2)\n",
    "                        #x0 = Tensor(high_minus_low  * np.random.random_sample((1,2)) + vf.low) #\n",
    "                 \n",
    "             #       loc_sample = (loc_sample - loc_sample.mean())/loc_sample.std(dim=-2, keepdim=True)\n",
    "                        loc_sample[-1] = x0 #(x0_new.detach()) \n",
    "                    print('new 2 points')\n",
    "                    print(loc_sample)\n",
    "                  \n",
    " #                    agg_data  = (agg_data  - agg_data.mean())/agg_data .std(dim=-1, keepdim=True)\n",
    "#                     g_theta1 = (g_theta1 - g_theta1.mean())/g_theta1.std(dim=-2, keepdim=True)\n",
    "        \n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "            \n",
    "            #clear_output(wait=False)\n",
    "           \n",
    "        print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "vec_x = torch.cat([vec_x, x0_new.detach()])\n",
    "g_theta2_vec = torch.cat([g_theta2_vec, g_theta2.detach().flatten()], 0)\n",
    "entropy_vec = torch.cat([entropy_vec, entropy], 0)\n",
    "data_fit_vec = torch.cat([data_fit_vec, data_fit], 0)\n",
    "PATH = \".//model_Carlo/model_goodmodel/model_base_\"+str(iter)+\".pt\"\n",
    "torch.save(model, PATH)\n",
    "print('current sol is'+str(x0_new.detach()))\n",
    "    \n",
    "print('Success is ' + str(SUCCESS) + ' and failure is ' + str(FAILURE)+' after '+ str(iter) + ' iterations')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultitaskGPModel' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/grand/datascience/tiany/python_venv/lib/python3.8/site-packages/gpytorch/module.py:433\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultitaskGPModel' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "File \u001b[0;32m/grand/datascience/tiany/python_venv/lib/python3.8/site-packages/gpytorch/module.py:435\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(name)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/grand/datascience/tiany/python_venv/lib/python3.8/site-packages/gpytorch/module.py:430\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/lus/theta-fs0/software/thetagpu/conda/2022-07-01/mconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultitaskGPModel' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target - 0.001)\n",
    "print(f_target + 0.001)\n",
    "print(pf1)\n",
    "print(num_base_kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting model validation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "#plt.rcParams[\"pdf.use14corefonts\"] = True\n",
    "data_fit_vec_plot = 0.5* data_fit_vec.detach()[1:]\n",
    "entropy_vec_plot = entropy_vec.detach()[1:]\n",
    "p21_vec_plot = p21_vec.detach()[1:]\n",
    "f, ax = plt.subplots(1, 1, figsize=(14, 14))\n",
    "#ax.plot(np.array(range(2,iter+2)), torch.log(entropy_vec_plot), '+-')\n",
    "#print(p21_vec_plot)\n",
    "ax.plot(p21_vec_plot,'s',color = 'blue', markersize=6)\n",
    "ax.axhline(.01,linestyle = '--',color = 'red', markersize=12, alpha = 1.0)\n",
    "ax.set_xlim(-0.3, p21_vec_plot.shape[0])\n",
    "ax.set_ylim(-0.3, 1.)\n",
    "#ax.set_yscale('log')\n",
    "plt.xticks(np.arange(0, iter+7, step=5.))\n",
    "ax.tick_params(labelsize='small', width=3)\n",
    "ax.set_xlabel('# of Model Checks')\n",
    "ax.set_ylabel('p-value')\n",
    "ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.05, 0.03), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(1.2,        #x start point\n",
    "             -0.25,                      #y start point\n",
    "             0,       #change in x \n",
    "             0.2,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black')             #arrow edge color\n",
    "\n",
    "ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.02, 0.4), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(0.1,        #x start point\n",
    "             0.23,                      #y start point\n",
    "             0,       #change in x \n",
    "             -0.16,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black') \n",
    "\n",
    "\n",
    "############################\n",
    "ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.26, 0.34), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(6.2,        #x start point\n",
    "             0.14,                      #y start point\n",
    "             0,       #change in x \n",
    "             -0.07,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black') \n",
    "\n",
    "\n",
    "\n",
    "ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.29, 0.03), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(7.2,        #x start point\n",
    "             -0.25,                      #y start point\n",
    "             0,       #change in x \n",
    "             0.2,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black')             #arrow edge color\n",
    "\n",
    "############################\n",
    "ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.57, 0.4), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(14.15,        #x start point\n",
    "             0.23,                      #y start point\n",
    "             0,       #change in x \n",
    "             -0.16,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black') \n",
    "################################\n",
    "\n",
    "\n",
    "############################\n",
    "ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.69, 0.4), xycoords='axes fraction', \n",
    "            fontsize=9*1.5, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white'))\n",
    "ax.arrow(17.18,        #x start point\n",
    "             0.23,                      #y start point\n",
    "             0,       #change in x \n",
    "             -0.16,                      #change in y\n",
    "             head_width=0.2,         #arrow head width\n",
    "             head_length=0.06,        #arrow head length\n",
    "             width=0.1,              #arrow stem width\n",
    "             fc='black',             #arrow fill color\n",
    "             ec='black') \n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "# ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.32, 0.03), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(10.25,        #x start point\n",
    "#              -0.25,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              0.2,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black')             #arrow edge color\n",
    "\n",
    "# ############################\n",
    "\n",
    "# ############################\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.33, 0.34), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(11.25,        #x start point\n",
    "#              0.14,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.07,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# #################################################\n",
    "\n",
    "# ################################\n",
    "\n",
    "\n",
    "# ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.38, 0.1), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(12.25,        #x start point\n",
    "#              -0.15,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              0.1,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black')             #arrow edge color\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.38, 0.4), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(13.25,        #x start point\n",
    "#              0.23,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.16,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# ################################\n",
    "\n",
    "\n",
    "# ax.annotate('Update model', xy=(0.55, 0.2), xytext=(0.55, 0.03), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(18.25,        #x start point\n",
    "#              -0.25,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              0.2,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black')  \n",
    "# ################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.49, 0.4), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(17.25,        #x start point\n",
    "#              0.23,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.16,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# ################################\n",
    "\n",
    "# ################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.55, 0.43), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(19.25,        #x start point\n",
    "#              0.26,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.19,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# ################################\n",
    "\n",
    "# ax.annotate('Restart', xy=(0.55, 0.2), xytext=(0.94, 0.43), xycoords='axes fraction', \n",
    "#             fontsize=9*1.5, ha='center', va='bottom',\n",
    "#             bbox=dict(boxstyle='square', fc='white'))\n",
    "# ax.arrow(33.25,        #x start point\n",
    "#              0.26,                      #y start point\n",
    "#              0,       #change in x \n",
    "#              -0.19,                      #change in y\n",
    "#              head_width=0.2,         #arrow head width\n",
    "#              head_length=0.06,        #arrow head length\n",
    "#              width=0.1,              #arrow stem width\n",
    "#              fc='black',             #arrow fill color\n",
    "#              ec='black') \n",
    "# ################################\n",
    "\n",
    "\n",
    "# ################################\n",
    "\n",
    "ax.annotate('Threshold Line ($y = 0.01$)', xy=(1.0,0.01), xytext=(6,0), color='red', \n",
    "                xycoords = ax.get_yaxis_transform(), textcoords=\"offset points\",\n",
    "                size=14, va=\"center\")\n",
    "\n",
    "\n",
    "#ax.legend(['p-value'], loc = 'upper left', fontsize = 30)\n",
    "plt.savefig('figures_Carlo/qvalue_base.pdf',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting expected value and data fit term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "data_fit_vec_plot = 0.5* data_fit_vec.detach()[1:]\n",
    "entropy_vec_plot = entropy_vec.detach()[1:]\n",
    "f, (ax1,ax2) = plt.subplots(1, 2, figsize=(18, 8), tight_layout=True)\n",
    "\n",
    "ax1.plot(np.array(range(1,iter+2)), (entropy_vec_plot), '--o', color = 'blue', markersize=12)\n",
    "#ax1.set_yscale('log')\n",
    "# ax.plot(np.array(data_fit_vec_plot), (entropy_vec_plot), 'o')\n",
    "#ax1.set_yscale('log')\n",
    "\n",
    "ax2.plot(np.array(range(1,iter+2)), data_fit_vec_plot, '--o', color = 'red', markersize=12)\n",
    "#ax2.set_ylim(-10, 600)\n",
    "ax1.set_xlabel('Iteration #', size=32)\n",
    "ax2.set_xlabel('Iteration #', size=32)\n",
    "ax1.set_ylabel('Expected Information', size = 32)\n",
    "ax2.set_ylabel('Log-Gaussian Term', size = 32)\n",
    "ax1.set_xticks(np.arange(0, iter+3, step=3.))\n",
    "ax2.set_xticks(np.arange(0, iter+3, step=3.))\n",
    "plt.savefig('figures_Carlo/exp_info/expectedinfo_vs_datafit_2_base.pdf',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving all data needed for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data_plots/vec_x_success_base.txt',vec_x.detach().numpy())\n",
    "np.savetxt('data_plots/g_theta2_success_base.txt', g_theta2.detach().numpy())\n",
    "np.savetxt('data_plots/g_theta1_success_base.txt', g_theta1.detach().numpy())\n",
    "np.savetxt('data_plots/x_train_ini_success_base.txt', x_train.detach().numpy())\n",
    "np.savetxt('data_plots/y_train_ini_success_base.txt', y_train.detach().numpy())\n",
    "np.savetxt('data_plots/entropy_vec_success_base.txt', entropy_vec_plot.detach().numpy())\n",
    "np.savetxt('data_plots/datafit_success_base.txt', data_fit_vec_plot.detach().numpy())\n",
    "np.savetxt('data_plots/p21_vec_success_base.txt',p21_vec_plot.detach().numpy())\n",
    "np.savetxt('data_plots/loss_success_base.txt',loss.detach().numpy())\n",
    "np.savetxt('data_plots/pf1_success_base.txt',pf1.detach().numpy())\n",
    "np.savetxt('data_plots/Qf1_success_base.txt',Qf1.evaluate().detach().numpy())\n",
    "np.savetxt('data_plots/Qf12_success_base.txt', Qf12.evaluate().detach().numpy())\n",
    "np.savetxt( 'data_plots/Q21_success_base.txt', Q21.evaluate().detach().numpy())\n",
    "#np.savetxt('data_plots/iter_success.txt', iter+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = g_theta2_vec.reshape(math.ceil(g_theta2_vec.shape[0]/2),2)\n",
    "torch.save(v2, 'data_plots/v2_success_base.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "ax.set_xlim(-3.1, 3.2)\n",
    "ax.set_ylim(-3.1, 3.2)\n",
    "#ax.scatter(g_theta1[:, 0].detach(),g_theta1[:, 1].detach(), c=\"b\", alpha=0.8)\n",
    "ax.plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'blue',markersize=15, alpha = 0.2)\n",
    "ax.plot(vec_x[-1,0], vec_x[-1,1],'v', color = 'red',markersize=15)\n",
    "ax.plot(0.8731, 0.5664,'gd', color = 'green',markersize=15)\n",
    "ax.set_title('Final TAD configuration', fontsize = 40)\n",
    "ax.set_xlabel('$d_1$')\n",
    "ax.set_ylabel('$d_2$')\n",
    "ax.legend(['1-points', 'TAD solution', 'Target'])\n",
    "plt.savefig('figures_Carlo/strategies/tad_sol_all_2_base.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec_x = vec_x.detach()\n",
    "#v2 = g_theta2_vec.reshape(math.ceil(g_theta2_vec.shape[0]/2), 2)\n",
    "ii = 0\n",
    "low = -3.2\n",
    "high = 3.2\n",
    "########################\n",
    "f, ax = plt.subplots(1, 1, figsize=(14, 14))\n",
    "ax.plot(0.8731, 0.5664,'d', color = 'green',markersize=15)\n",
    "ax.plot(vec_x[ii,0], vec_x[ii,1],'v', color = 'red',markersize=15)\n",
    "ax.plot(x_train.detach()[:,0], x_train.detach()[:,1], 's', color = 'black', markersize=15, alpha = 0.2)\n",
    "ax.plot(v2.detach()[ii:ii+loc_size+1,0], v2.detach()[ii:ii+loc_size+1,1], 'o', color = 'blue', markersize=15)\n",
    "ax.set_xlabel('$d_1$')\n",
    "ax.set_ylabel('$d_2$')\n",
    "ax.set_title('Initial Configuration', fontsize = 40)\n",
    "ax.legend(['Target', 'Initial Target Candidate', 'Initial 1-sample','Initial 2-sample'])\n",
    "\n",
    "ax.set_xlim(low, high)\n",
    "ax.set_ylim(low, high)\n",
    "plt.savefig('figures_Carlo/evol_solTAD/evol_sol_ini_2_base.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_x = vec_x.detach()\n",
    "v2 = g_theta2_vec.reshape(math.ceil(g_theta2_vec.shape[0]/2), 2)\n",
    "\n",
    "low = -3.2\n",
    "high = 3.2\n",
    "#for iter_plt in range(1,iter):\n",
    "iter_plt = 13\n",
    "ii = 3 + (iter_plt - 1) * (loc_size + 1)\n",
    "#######################\n",
    "\n",
    " \n",
    "###########\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(14,14))\n",
    "\n",
    "#ax.plot(x_train.detach()[:,0], x_train.detach()[:,1], 'bv', markersize=8)\n",
    "for i in range(1, iter_plt):\n",
    "    ax.plot(vec_x[i-1:i,0], vec_x[i-1:i,1],'v', color = 'red', markersize=15, alpha=0.2, label = '_nolegend_')\n",
    "    \n",
    "ax.plot(vec_x[0:iter_plt,0], vec_x[0:iter_plt,1],'v', color = 'red', markersize=15, linewidth=15, alpha= 0.2)\n",
    "#ax.plot(g_theta1.detach()[:,0], g_theta.detach()[:,1], 'bv', markersize=8)\n",
    "ax.plot(v2.detach()[0:ii,0], v2.detach()[0:ii,1], 's', color = 'blue', markersize=15,alpha=0.2)\n",
    "ax.plot(x_train.detach()[:,0], x_train.detach()[:,1], 's', color = 'black', markersize=15, alpha = 0.2)\n",
    "ax.plot(v2.detach()[ii:ii+loc_size+1,0], v2.detach()[ii:ii+loc_size+1,1], 'o',color = 'blue' , markersize=15)\n",
    "ax.plot(0.8731, 0.5664,'gd',markersize=15)\n",
    "ax.plot(vec_x[iter_plt,0], vec_x[iter_plt,1],'v', color = 'red',markersize=15)\n",
    "ax.set_xlabel('$d_1$')\n",
    "ax.set_ylabel('$d_2$')\n",
    "#ax.set_title('Iteration '+str(iter_plt), fontsize = 40)\n",
    "ax.set_title('Final Configuration')\n",
    "ax.legend([ 'Previous Target Candidates', 'Previous 2-samples', 'Initial 1-sample','Current 2-sample', 'Target', 'Current Target Candidate'], fontsize = 30)\n",
    "\n",
    "ax.set_xlim(low, high)\n",
    "ax.set_ylim(low, high)\n",
    "plt.savefig('figures_Carlo/evol_solTAD/evol_sol_base'+str(iter_plt)+'_final.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta2_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_design_pll(x0,f_target, g_theta1, agg_data, model, likelihood, training_design_iter, training_param_iter, lr_new,noise_value):\n",
    "\n",
    "    #g_theta2 = nn.Parameter(Tensor(loc_sample))\n",
    "\n",
    "    x_d= nn.Parameter(Tensor(x0))\n",
    "    \n",
    "    optimizer = torch.optim.Adam([{'params': x_d, 'lr': 0.001}])\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    \n",
    "    for ii in range( training_param_iter ):\n",
    "#         x_d = torch.cat([x_d_0, x_d_1]).reshape(1,2)\n",
    "#         g_theta2 = torch.cat([g_theta20, g_theta21],1)\n",
    "        optimizer.zero_grad()\n",
    "        #print(g_theta)\n",
    "        loss2,lower_bound, upper_bound = likelihood.get_pll(f_target,x_d, g_theta1, agg_data, model, likelihood, noise_value)\n",
    "        loss2 = -1. * loss2\n",
    "        \n",
    "        loss2.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    loss2,lower_bound, upper_bound = likelihood.get_pll(f_target,x_d, g_theta1, agg_data, model, likelihood ,noise_value)\n",
    "    #loss2 = -1. * loss2\n",
    "    print('Loss design: %.3f' % ( loss2))\n",
    "   # print(optimizer.state_dict())\n",
    "    print(x_d)\n",
    "    return x_d, lower_bound, upper_bound\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(vf.low, vf.high, 15)\n",
    "y_plot = np.linspace(vf.low, vf.high, 15)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat = torch.zeros(n * n, 2)\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "\n",
    "g_theta_grid = x_concat\n",
    "agg_data1_grid = vfield_(g_theta_grid)\n",
    "agg_data1_grid = agg_data1_grid.flatten()\n",
    "\n",
    "\n",
    "x0 = Tensor(np.array([-2.,2.])) \n",
    "x0 = x0.reshape(1,2)\n",
    "x00 = x0 \n",
    "vec_x_grid = Tensor(np.array([0.0,0.0])) \n",
    "vec_x_grid = vec_x_grid.reshape(1,2)\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    " \n",
    "tol = 0.009 \n",
    "print('START HYPERPARAMETERS optimization')\n",
    "model_grid, likelihood_grid = hyper_opti(g_theta_grid,agg_data1_grid,iter_hp,num_base_kernels,noise_value)\n",
    "\n",
    "print('END HYPERPARAMETERS optimization')\n",
    "model_grid.eval()\n",
    "likelihood_grid.eval()\n",
    "x0_new_grid,lower_bound, upper_bound = conduct_design_pll(x0,f_target, g_theta_grid, agg_data1_grid, model_grid, likelihood_grid, iter_design, iter_param, lr_new,noise_value)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target-tol_vector)\n",
    "print(f_target+tol_vector)\n",
    "#loc_sample = np.random.random_sample((loc_size_rdn,2))\n",
    "\n",
    "\n",
    "SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(x0_new_grid)\n",
    "print(SUCCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_grid = x0_new.detach()\n",
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "ax.plot(x_concat[:,0],x_concat[:,1], 's', color = 'blue', markersize=15, alpha = 0.2)\n",
    "ax.plot(x0_new_grid.detach()[0,0], x0_new_grid.detach()[0,1],'v',color = 'red',markersize=15)\n",
    "ax.plot(0.8731, 0.5664,'d', color = 'green',markersize=15)\n",
    "\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.set_xlabel('$d_1$')\n",
    "ax.set_ylabel('$d_2$')\n",
    "ax.set_title('Grid Solution', fontsize = 40)\n",
    "\n",
    "plt.savefig('figures_Carlo/strategies/grid_sol_2_base.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_hp = 30\n",
    "# iter_design = 40 \n",
    "# iter_param = 50\n",
    "# num_base_kernels = 3\n",
    "\n",
    "# f_target = Tensor(vf.tgt_vec) \n",
    "# f_target = f_target.reshape(f_target.shape[0],1) \n",
    "# tol_vector = 0.005 * torch.ones(f_target.shape)\n",
    "\n",
    "\n",
    "loc_size_rdn = math.ceil(g_theta1.shape[0]) #(iter)*(loc_size+1) + sample_size\n",
    "\n",
    "loc_sample = high_minus_low  * np.random.random_sample((loc_size_rdn,2)) + vf.low #np.random.random_sample((loc_size_rdn,2))\n",
    "g_theta_ = (Tensor(loc_sample).clone())\n",
    "agg_data1 = vfield_(g_theta_)\n",
    "agg_data1 = agg_data1.flatten()\n",
    "\n",
    "\n",
    "x0 = Tensor(np.array([-2.0,2.0])) \n",
    "x0 = x0.reshape(1,2)\n",
    "x00 = x0 \n",
    "vec_x_rdn = Tensor(np.array([0.,0.])) \n",
    "vec_x_rdn = vec_x_rdn.reshape(1,2)\n",
    "\n",
    "lr_new = 1.\n",
    "\n",
    "\n",
    "SUCCESS = False \n",
    "FAILURE = False \n",
    " \n",
    "tol = 0.009 \n",
    "print('START HYPERPARAMETERS optimization')\n",
    "\n",
    "model_rdn, likelihood_rdn = hyper_opti(g_theta_,agg_data1,iter_hp,num_base_kernels,noise_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('END HYPERPARAMETERS optimization')\n",
    "model_rdn.eval()\n",
    "likelihood_rdn.eval()\n",
    "x0_new_rdn,lower_bound, upper_bound = conduct_design_pll(x0,f_target, g_theta_, agg_data1, model_rdn, likelihood_rdn, iter_design, iter_param, lr_new, noise_value)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(f_target-tol_vector)\n",
    "print(f_target+tol_vector)\n",
    "loc_sample = np.random.random_sample((loc_size_rdn,2))\n",
    "\n",
    "\n",
    "SUCCESS = stopping_criteria(tol_vector, f_target, lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(x0_new_rdn)\n",
    "print(SUCCESS)\n",
    "sol_rdn = x0_new_rdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data_plots/sol_rdn_success_base.txt', sol_rdn.detach().numpy())\n",
    "np.savetxt('data_plots/sol_grid_success_base.txt', x0_new_grid.detach().numpy())\n",
    "np.savetxt('data_plots/g_theta_rdn_success_base.txt', g_theta_.detach().numpy())\n",
    "#np.savetxt('data_plots/g_theta_grid_success.txt', x_concat.detach().numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "\n",
    "ax.plot(g_theta_[:,0].detach(),g_theta_[:,1].detach(), 's', color = 'blue',markersize=15, alpha = 0.2)\n",
    "ax.plot(sol_rdn.detach()[0,0], sol_rdn.detach()[0,1],'v', color = 'red',markersize=15)\n",
    "ax.plot(0.8731, 0.5664,'d', color = 'green',markersize=15)\n",
    "\n",
    "ax.set_xlim(-3.1, 3.1)\n",
    "ax.set_ylim(-3.1, 3.1)\n",
    "ax.set_xlabel('$d_1$', fontsize = 32)\n",
    "ax.set_ylabel('$d_2$', fontsize = 32)\n",
    "ax.set_title('Uniformly Random Solution', fontsize = 40)\n",
    "\n",
    "plt.savefig('figures_Carlo/strategies/rdn_sol_2_base.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualizing Means and Variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker\n",
    "class OOMFormatter(matplotlib.ticker.ScalarFormatter):\n",
    "    def __init__(self, order=0, fformat=\"%1.1f\", offset=True, mathText=True):\n",
    "        self.oom = order\n",
    "        self.fformat = fformat\n",
    "        matplotlib.ticker.ScalarFormatter.__init__(self,useOffset=offset,useMathText=mathText)\n",
    "    def _set_order_of_magnitude(self):\n",
    "        self.orderOfMagnitude = self.oom\n",
    "    def _set_format(self, vmin=None, vmax=None):\n",
    "        self.format = self.fformat\n",
    "        if self._useMathText:\n",
    "             self.format = r'$\\mathdefault{%s}$' % self.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_target = vf.tgt_vec\n",
    "f_target = f_target.reshape(f_target.shape[0],1)\n",
    "vf.tgt_loc = vf.tgt_loc.reshape(2,1)\n",
    "#x0 = Tensor(np.array([0.1937, 0.1257]))\n",
    "#x0 = Tensor(np.array([0.1885, 0.1038]))\n",
    "x_plot = np.linspace(-3.5, 3.5, 100)\n",
    "y_plot = np.linspace(-3.5, 3.5, 100)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat_ = torch.zeros(n * n, 2)\n",
    "\n",
    "# n_sample = x_concat_.shape[0]\n",
    "num_tasks = 2\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "    \n",
    "\n",
    "tgt_plot = vfield_(x_concat_)\n",
    "\n",
    "\n",
    "\n",
    "v_1 = tgt_plot[:,0].reshape(n,n)\n",
    "v_2 = tgt_plot[:,1].reshape(n,n)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "likelihood.eval()\n",
    "\n",
    "#noise = torch.eye(2 * g_theta1.detach().shape[0]) * noise_value\n",
    "#print(x_concat_)\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(True):\n",
    "    pred = GPprediction(model)\n",
    "    pr_mean, cov = pred.GPpred(g_theta1.detach(), agg_data, x_concat_, noise_value)\n",
    "    #pr = (model(g_theta1.detach())) # likelihood(model(x_concat_), noise = torch.ones(x_concat_.shape) * noise_value)#\n",
    "    pr_mean = pr_mean.reshape(x_concat_.shape[0], num_tasks)\n",
    "    mean_v_1 = pr_mean[:,0].reshape(n,n)\n",
    "    mean_v_2 = pr_mean[:,1].reshape(n,n)\n",
    "    pred_var = cov.diag().reshape(num_tasks, x_concat_.shape[0]).T\n",
    "    \n",
    "    var_v_1 = pred_var[:,0].reshape(n,n)\n",
    "    var_v_2 = pred_var[:,1].reshape(n,n)\n",
    "#     AA = pr.covariance_matrix.mean(axis=0).reshape(num_tasks, x_concat_.shape[0]).T #.diag() #.reshape(num_tasks, num_tasks * g_theta1.shape[0]).T\n",
    "\n",
    "# #     print(pr.covariance_matrix.mean(axis=0))\n",
    "# #     print(AA)\n",
    "# #     print(pr.variance)\n",
    "# #     print((pr.covariance_matrix))\n",
    "# #     K = model.covar_module\n",
    "#     print((cov.diag()))\n",
    "#     print(pr_mean)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 2, figsize = (28, 24), tight_layout=True)\n",
    "diff_mean_v1= torch.abs(v_1 - mean_v_1.detach())#/torch.abs(v_1)\n",
    "cs10 = ax1[0].contourf(xv_plot, yv_plot,diff_mean_v1 ,np.linspace(0, 1.1, 100), cmap = 'jet')\n",
    "ax1[0].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "ax1[0].plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "ax1[0].set_title('$|v_1 - \\mu(v_1)|$', fontsize = 40)\n",
    "cbar10 = fig.colorbar(cs10, ax = ax1[0],format=OOMFormatter(0, mathText=False));\n",
    "\n",
    "ax1[0].set_xlabel('$d_1$')\n",
    "ax1[0].set_ylabel('$d_2$')\n",
    "diff_mean_v1 = torch.abs(v_1 - mean_v_1.detach())/torch.sqrt(var_v_1)\n",
    "#print(var_v_1)\n",
    "cs11 = ax1[1].contourf(xv_plot, yv_plot,diff_mean_v1 ,np.linspace(diff_mean_v1.min(), diff_mean_v1.max(), 100), cmap = 'jet')\n",
    "ax1[1].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "ax1[1].plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "ax1[1].set_title('$|v_1 - \\mu(v_1)|/\\sigma(v_1)$', fontsize = 40)\n",
    "# ax1[0].set_aspect('equal')\n",
    "# ax1[1].set_aspect('equal')\n",
    "cbar11 = fig.colorbar(cs11, ax = ax1[1],format=OOMFormatter(0, mathText=False));\n",
    "ax1[1].set_xlabel('$d_1$')\n",
    "ax1[1].set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "diff_mean_v2= torch.abs(v_2 - mean_v_2.detach())\n",
    "cs20 = ax2[0].contourf(xv_plot, yv_plot, diff_mean_v2,np.linspace(0, 1.1, 100), cmap = 'jet')\n",
    "ax2[0].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "ax2[0].plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "ax2[0].set_title('$|v_2 - \\mu(v_2)|$', fontsize = 40)\n",
    "cbar20 = fig.colorbar(cs20, ax = ax2[0],format=OOMFormatter(0, mathText=False));\n",
    "ax2[0].set_xlabel('$d_1$')\n",
    "ax2[0].set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "diff_mean_v2= torch.abs(v_2 - mean_v_2.detach())/torch.sqrt(var_v_2)\n",
    "cs21 = ax2[1].contourf(xv_plot, yv_plot, diff_mean_v2,np.linspace(diff_mean_v2.min(), diff_mean_v2.max(), 100), cmap = 'jet')\n",
    "ax2[1].plot(g_theta1[:, 0].detach(),g_theta1[:, 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "ax2[1].plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "ax2[1].set_title('$|v_2 - \\mu(v_2)|/\\sigma(v_2)$', fontsize = 40)\n",
    "cbar21 = fig.colorbar(cs21, ax = ax2[1],format=OOMFormatter(0, mathText=False));\n",
    "ax2[1].set_xlabel('$d_1$')\n",
    "ax2[1].set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "# ax2[0].set_aspect('equal')\n",
    "# ax2[1].set_aspect('equal')\n",
    "\n",
    "plt.savefig('figures_Carlo/mean_var/mean_final_2.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_target = vf.tgt_vec\n",
    "f_target = f_target.reshape(f_target.shape[0],1)\n",
    "vf.tgt_loc = vf.tgt_loc.reshape(2,1)\n",
    "#x0 = Tensor(np.array([0.1937, 0.1257]))\n",
    "#x0 = Tensor(np.array([0.1885, 0.1038]))\n",
    "x_plot = np.linspace(-3.5, 3.5, 100)\n",
    "y_plot = np.linspace(-3.5, 3.5, 100)\n",
    "xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "n = x_plot.shape[0]\n",
    "x_concat_ = torch.zeros(n * n, 2)\n",
    "\n",
    "# n_sample = x_concat_.shape[0]\n",
    "num_tasks = 2\n",
    "i = 0\n",
    "k = 0\n",
    "while i < n*n:\n",
    "    x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "    x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "    k = k+1\n",
    "    i = i+n\n",
    "    \n",
    "\n",
    "tgt_plot = vfield_(x_concat_)\n",
    "\n",
    "\n",
    "\n",
    "v_1 = tgt_plot[:,0].reshape(n,n)\n",
    "v_2 = tgt_plot[:,1].reshape(n,n)\n",
    "plot = [1, 6, 10, iter+1]\n",
    "\n",
    "for ii in plot:\n",
    "    try:\n",
    "        \n",
    "        PATH = \".//model_Carlo/model_goodmodel/model_base_\"+str(ii - 1)+\".pt\"\n",
    "        model_16 = torch.load(PATH)\n",
    "    except:\n",
    "        PATH = \".//model_Carlo/model_update/model_base_\"+str(ii - 1)+\".pt\"\n",
    "        model_16 = torch.load(PATH)\n",
    "        \n",
    "    #model_16 = torch.load(PATH)\n",
    "    model_16.eval()\n",
    "\n",
    "    likelihood.eval()\n",
    "\n",
    "    #noise = torch.eye(2 * g_theta1.detach().shape[0]) * noise_value\n",
    "    #print(x_concat_)\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var(False):\n",
    "        pred = GPprediction(model_16)\n",
    "        pr_mean, cov = pred.GPpred(g_theta1.detach(), agg_data, x_concat_, noise_value)\n",
    "        #pr = (model(g_theta1.detach())) # likelihood(model(x_concat_), noise = torch.ones(x_concat_.shape) * noise_value)#\n",
    "        pr_mean = pr_mean.reshape(x_concat_.shape[0], num_tasks)\n",
    "        mean_v_1 = pr_mean[:,0].reshape(n,n)\n",
    "        mean_v_2 = pr_mean[:,1].reshape(n,n)\n",
    "        pred_var = cov.diag().reshape(num_tasks, x_concat_.shape[0]).T\n",
    "\n",
    "        var_v_1 = pred_var[:,0].reshape(n,n)\n",
    "        var_v_2 = pred_var[:,1].reshape(n,n)\n",
    "    #     AA = pr.covariance_matrix.mean(axis=0).reshape(num_tasks, x_concat_.shape[0]).T #.diag() #.reshape(num_tasks, num_tasks * g_theta1.shape[0]).T\n",
    "\n",
    "    # #     print(pr.covariance_matrix.mean(axis=0))\n",
    "    # #     print(AA)\n",
    "    # #     print(pr.variance)\n",
    "    # #     print((pr.covariance_matrix))\n",
    "    # #     K = model.covar_module\n",
    "    #     print((cov.diag()))\n",
    "    #     print(pr_mean)\n",
    "\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (28, 12), tight_layout=True)\n",
    "    diff_mean_v1= torch.abs(v_1 - mean_v_1.detach())#/torch.abs(v_1)\n",
    "    minn = torch.min(var_v_1.detach().min(), var_v_2.detach().min())\n",
    "    maxx = torch.min(var_v_1.detach().max(), var_v_2.detach().max())\n",
    "\n",
    "    cs11 = ax1.contourf(xv_plot, yv_plot, var_v_1.detach(), np.linspace(0.0,1.1, 100), cmap = 'jet')\n",
    "    ax1.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "    \n",
    "    ax1.plot(g_theta1[0:(4 + (ii - 1)* 3), 0].detach(),g_theta1[0:(4 + (ii - 1)* 3), 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "  \n",
    "    ax1.set_title('$\\sigma^2(v_1)$ (Iteration '+str(ii)+')', fontsize = 40)\n",
    "    # ax1[0].set_aspect('equal')\n",
    "    # ax1[1].set_aspect('equal')\n",
    "    cbar11 = fig.colorbar(cs11, ax = ax1,format=OOMFormatter(-0, mathText=False));\n",
    "    ax1.set_xlabel('$d_1$')\n",
    "    ax1.set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    cs21 = ax2.contourf(xv_plot, yv_plot, var_v_2.detach(), np.linspace(0.0, 1.1, 100), cmap = 'jet')\n",
    "    ax2.plot(g_theta1[0:(4 + (ii - 1)* 3), 0].detach(),g_theta1[0:(4 + (ii - 1)* 3), 1].detach() , 'o', color = 'black',markersize=12, alpha = 1.0)\n",
    "    ax2.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "    ax2.set_title('$\\sigma^2(v_2)$ (Iteration '+str(ii)+')', fontsize = 40)\n",
    "    cbar21 = fig.colorbar(cs21, ax = ax2,format=OOMFormatter(-0, mathText=False));\n",
    "    ax2.set_xlabel('$d_1$')\n",
    "    ax2.set_ylabel('$d_2$')\n",
    "\n",
    "\n",
    "    # ax2[0].set_aspect('equal')\n",
    "    # ax2[1].set_aspect('equal')\n",
    "\n",
    "    plt.savefig('figures_Carlo/mean_var/var_iter_base'+str(ii)+'.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_plot = np.linspace(-3., 3., 30)\n",
    "# y_plot = np.linspace(-3., 3., 30)\n",
    "# xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "# n = x_plot.shape[0]\n",
    "# x_concat_ = torch.zeros(n * n, 2)\n",
    "# training_param_iter = 200\n",
    "\n",
    "# # n_sample = x_concat_.shape[0]\n",
    "# num_tasks = 2\n",
    "# i = 0\n",
    "# k = 0\n",
    "# while i < n*n:\n",
    "#     x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "#     x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "#     k = k+1\n",
    "#     i = i+n\n",
    "\n",
    "# # #dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .01 * torch.eye(2) )\n",
    "# #                     #loc_size = 4\n",
    "# # loc_sample = 1./3. * Tensor(high_minus_low  * np.random.random_sample((3,2)) + vf.low) # #dis_2sample.sample((2 + 1,))\n",
    "# # loc_sample0 = loc_sample.reshape(2 + 1, 2)\n",
    "# # g2 = loc_sample0 #Tensor(loc_sample) #.detach()\n",
    "# likelihood.eval()\n",
    "# model.eval()\n",
    "# z = torch.zeros(n*n, 1)\n",
    "# for ii in range(n*n):\n",
    "#     print(ii)\n",
    "#     x0 = x_concat_[ii,:].reshape(1,2)\n",
    "#     dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .001 * torch.eye(2) )\n",
    "#                     #loc_size = 4\n",
    "#     loc_sample = dis_2sample.sample((2 + 1,))\n",
    "#     loc_sample0 = loc_sample.reshape(2 + 1, 2)\n",
    "#     g2 = loc_sample0 #Tensor(loc_sample) #.detach()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     x_d, g_theta2, loss2, pf1, Qf1, Qf12, data_fit, Q21 = conduct_2opt(agg_data,f_target,x0, g_theta1, model, likelihood, noise_value, g2, training_param_iter)\n",
    "#     z[ii] = loss2\n",
    "# z = z.reshape(n,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_theta1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_plot = np.linspace(-3., 3., 30)\n",
    "# y_plot = np.linspace(-3., 3., 30)\n",
    "# xv_plot, yv_plot = np.meshgrid(x_plot, y_plot)\n",
    "# n = x_plot.shape[0]\n",
    "# x_concat_ = torch.zeros(n * n, 2)\n",
    "# training_param_iter = 200\n",
    "\n",
    "# # n_sample = x_concat_.shape[0]\n",
    "# num_tasks = 2\n",
    "# i = 0\n",
    "# k = 0\n",
    "# while i < n*n:\n",
    "#     x_concat_[i:i+n,0] = Tensor(xv_plot[:,k])\n",
    "#     x_concat_[i:i+n,1] = Tensor(y_plot)\n",
    "#     k = k+1\n",
    "#     i = i+n\n",
    "\n",
    "# #dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .01 * torch.eye(2) )\n",
    "#                     #loc_size = 4\n",
    "# loc_sample = 1./3. * Tensor(high_minus_low  * np.random.random_sample((3,2)) + vf.low) # #dis_2sample.sample((2 + 1,))\n",
    "# loc_sample0 = loc_sample.reshape(2 + 1, 2)\n",
    "# g2 = g_theta2.detach() #loc_sample0 #Tensor(loc_sample) #.detach()\n",
    "# likelihood.eval()\n",
    "# model.eval()\n",
    "# plot = [1, 7, 17, 26]\n",
    "# zz = torch.zeros(n*n, 4)\n",
    "# kk = 0\n",
    "# for jj in plot:\n",
    "#     try:\n",
    "        \n",
    "#         PATH = \".//model_Carlo/model_goodmodel/model_\"+str(jj - 1)+\".pt\"\n",
    "#         model_16 = torch.load(PATH)\n",
    "#     except:\n",
    "#         PATH = \".//model_Carlo/model_update/model_\"+str(jj - 1)+\".pt\"\n",
    "#         model_16 = torch.load(PATH)\n",
    "#    # model_16 = torch.load(PATH)\n",
    "#     model_16.eval()\n",
    "\n",
    "#     likelihood.eval()\n",
    "#     g2 = v2.detach()[jj - 1 +loc_size+1 : jj - 1 +loc_size+1 +loc_size+1]\n",
    "#     g_theta1_cur = g_theta1[0:(4 + (jj - 1)* 3)]\n",
    "#     agg_data_cur = agg_data[0:2 * (4 + (jj - 1)* 3)]\n",
    "#     print(agg_data_cur.shape)\n",
    "#     for ii in range(n*n):\n",
    "#         print(ii)\n",
    "#         x0 = x_concat_[ii,:].reshape(1,2)\n",
    "#     #     dis_2sample = MultivariateNormal( loc = x0, covariance_matrix= .001 * torch.eye(2) )\n",
    "#     #                     #loc_size = 4\n",
    "#     #     loc_sample = dis_2sample.sample((2 + 1,))\n",
    "#     #     loc_sample0 = loc_sample.reshape(2 + 1, 2)\n",
    "#         #g2 = loc_sample0 #Tensor(loc_sample) #.detach()\n",
    "\n",
    "\n",
    "        \n",
    "#         loss2_, pf1_, Qf1_, Qf12_, data_fit_, Q21_ = likelihood.get_ell(agg_data_cur,f_target,x0, g_theta1_cur, model_16, likelihood, noise_value, g2)\n",
    "#         zz[ii, kk] = loss2_\n",
    "#     kk = kk+1\n",
    "# zz = zz.reshape(n,n, 4)\n",
    "# torch.save(zz.detach(), 'data_plots/zz_success.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot = [1, 5, 10, 20]\n",
    "\n",
    "# for jj in range(4):\n",
    "#     fig, ax = plt.subplots(figsize = (16,14))\n",
    "#     #\n",
    "#     cs = ax.contour(xv_plot, yv_plot,  zz[:,:,jj].detach(), np.linspace( zz[:,:,jj].detach().numpy().min(), zz[:,:,jj].detach().numpy().max(), 1000), cmap = 'jet')\n",
    "#     cbar = fig.colorbar(cs, ax = ax,format=OOMFormatter(0, mathText=False));\n",
    "#     ax.plot(vf.tgt_loc[0],vf.tgt_loc[1], 'o', color = 'magenta', markersize=12)\n",
    "#     kk = plot[jj]\n",
    "#     if kk < plot[3]:\n",
    "#         ax.plot(vec_x[kk,0], vec_x[kk,1],'o', color = 'black',markersize=12)\n",
    "#     if kk == plot[3]:\n",
    "#         ax.plot(vec_x[- 1,0], vec_x[- 1,1],'o', color = 'black',markersize=12)\n",
    "#     ax.set_title('TAD Acquisition Function (Iteration '+str(kk)+')', fontsize = 40)\n",
    "#     ax.set_xlabel('$d_1$')\n",
    "#     ax.set_ylabel('$d_2$')\n",
    "    \n",
    "#     plt.savefig('figures_Carlo/tad_obj'+str(kk)+'.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p21_vec_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_venv",
   "language": "python",
   "name": "python_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
